{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae2f6bc",
   "metadata": {},
   "source": [
    "### This tutorial is currently non-operational. When non-legacy code is operational, these tutorials are to be adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec62088",
   "metadata": {},
   "source": [
    "I've split the Notebook in two sections. Thompson Sampling and Results Analysis. \n",
    "\n",
    "The files provided for the input are accessible with:\n",
    "```\n",
    "../examples/docking_scores/{file_name}\n",
    "../examples/input_files/{file_name}\n",
    "```\n",
    "\n",
    "output files should always be placed in (this ensures any file created is not uploaded to the GitHub repo accidently):\n",
    "```\n",
    "./tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a64ff4",
   "metadata": {},
   "source": [
    "I've tried going through the notebook using the data provided, but encountered issues as legacy code seems to be used to run these scripts. I've had a look, but as I don't know the changes from Legacy to Current, I'm unable to fix these issues. \n",
    "\n",
    "I've added comments in *italics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5feb3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bbcc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TACTICS Imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "notebook_dir = Path.cwd()\n",
    "src_path = notebook_dir.parent / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "from TACTICS.thompson_sampling import ThompsonSampler\n",
    "from TACTICS.thompson_sampling.config import ThompsonSamplingConfig\n",
    "from TACTICS.thompson_sampling.strategies.config import RouletteWheelConfig\n",
    "from TACTICS.thompson_sampling.warmup.config import StratifiedWarmupConfig\n",
    "from TACTICS.thompson_sampling.core.evaluator_config import LookupEvaluatorConfig\n",
    "from TACTICS.thompson_sampling.presets import get_preset\n",
    "from TACTICS.thompson_sampling.main import run_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c90d0",
   "metadata": {},
   "source": [
    "# TACTICS Fundamentals:\n",
    "The module consists of the a Unified Thompson Sampler that takes as input different configurations. To set up different configurations we can change the parameters of the `ThompsonSamplingConfig`. Every run consists of a configuration input into the `ThompsonSampler` class.\n",
    "\n",
    "### Configurations \n",
    "These are also used for different search and warm up strategies. These are set up using `pydantic` and provide a clear concise way to trouble shoot any issues with parameters that might be input. `pydantic` checks the user's input for each parameter and provides code hints (parameter ranges, types etc.). If the user enters a parameter that is not correct then it automatically provides an error message letting the user know where this is an issue. Its easy to keep track of different runs since the configurations.\n",
    "\n",
    "### Presets \n",
    "These are pre-configured TS configurations for specific use cases, the user would not need to define the parameters for a given search strategy or warm-up, this would all be defined with default parameters. All that would be required by the user would be the input files (reagents, reaction SMARTS and evaluator type). For example, the fast exploration configuration uses the Epsilon Greedy configuration with high $\\epsilon$ value for fast exploration.\n",
    "\n",
    "#### Wrapper Functions\n",
    "The package comes with a `run_TS` wrapper function that can be used with existing presets. This allows the user to just input the reaction SMARTS and the input files and the wrapper function will run both the warm-up and search cycles and return a a `polars` data frame of the compiled results. It will also return statistics on the search efficiency as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7848a5f",
   "metadata": {},
   "source": [
    "## Out of the Box Demonstration with Presets and Wrapper Function\n",
    "Here I am using the `run_ts` wrapper function that allows the user to user a preset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c1dc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset_config = get_preset(\n",
    "    \"fast_exploration\",  # Good for LookupEvaluator (processes=1, batch_size=1)\n",
    "    reaction_smarts=\"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    reagent_file_list=[\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    evaluator_config=LookupEvaluatorConfig(\n",
    "        ref_filename=\"../examples/docking_scores/product_scores.csv\",\n",
    "        ref_colname=\"Scores\"\n",
    "    ),\n",
    "    mode=\"minimize\",      # For docking scores\n",
    "    num_iterations=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac912d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:08:04,990 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:194 5.00e+05 possible products\n",
      "2025-11-03:12:08:04,991 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/main.py:100 Starting warmup phase...\n",
      "2025-11-03:12:08:04,991 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:292 Warmup strategy: StratifiedWarmup, num_trials=3, expected_evaluations=11922\n",
      "2025-11-03:12:08:05,197 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:305 Generated 11918 warmup combinations\n",
      "2025-11-03:12:08:07,714 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:330 Warmup score stats: cnt=11918, mean=-10.7050, std=1.6619, min=-16.3356, max=10.0000\n",
      "2025-11-03:12:08:07,735 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:361 Top score found during warmup: -16.336\n",
      "2025-11-03:12:08:07,742 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/main.py:104 Starting search phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ed18448eee43589ee3ed77b884d5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Search:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:08:07,747 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 0: Best score = -11.388\n",
      "2025-11-03:12:08:07,824 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 100: Best score = -17.016\n",
      "2025-11-03:12:08:07,888 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 200: Best score = -17.016\n",
      "2025-11-03:12:08:07,952 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 300: Best score = -17.016\n",
      "2025-11-03:12:08:08,16 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 400: Best score = -17.016\n",
      "2025-11-03:12:08:08,82 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 500: Best score = -17.016\n",
      "2025-11-03:12:08:08,144 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 600: Best score = -17.016\n",
      "2025-11-03:12:08:08,208 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 700: Best score = -17.016\n",
      "2025-11-03:12:08:08,273 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 800: Best score = -17.248\n",
      "2025-11-03:12:08:08,338 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 900: Best score = -17.248\n",
      "2025-11-03:12:08:08,403 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1000: Best score = -17.248\n",
      "2025-11-03:12:08:08,469 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1100: Best score = -17.248\n",
      "2025-11-03:12:08:08,531 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1200: Best score = -17.248\n",
      "2025-11-03:12:08:08,596 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1300: Best score = -17.248\n",
      "2025-11-03:12:08:08,660 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1400: Best score = -17.248\n",
      "2025-11-03:12:08:08,723 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1500: Best score = -17.248\n",
      "2025-11-03:12:08:08,787 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1600: Best score = -17.248\n",
      "2025-11-03:12:08:08,850 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1700: Best score = -17.248\n",
      "2025-11-03:12:08:08,912 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1800: Best score = -17.248\n",
      "2025-11-03:12:08:08,977 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1900: Best score = -17.248\n",
      "2025-11-03:12:08:09,41 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2000: Best score = -17.248\n",
      "2025-11-03:12:08:09,105 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2100: Best score = -17.248\n",
      "2025-11-03:12:08:09,170 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2200: Best score = -17.248\n",
      "2025-11-03:12:08:09,232 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2300: Best score = -17.248\n",
      "2025-11-03:12:08:09,296 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2400: Best score = -17.248\n",
      "2025-11-03:12:08:09,360 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2500: Best score = -17.248\n",
      "2025-11-03:12:08:09,422 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2600: Best score = -17.248\n",
      "2025-11-03:12:08:09,486 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2700: Best score = -17.248\n",
      "2025-11-03:12:08:09,549 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2800: Best score = -17.248\n",
      "2025-11-03:12:08:09,613 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2900: Best score = -17.248\n",
      "2025-11-03:12:08:09,677 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3000: Best score = -17.829\n",
      "2025-11-03:12:08:09,741 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3100: Best score = -17.829\n",
      "2025-11-03:12:08:09,806 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3200: Best score = -17.829\n",
      "2025-11-03:12:08:09,870 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3300: Best score = -17.829\n",
      "2025-11-03:12:08:09,933 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3400: Best score = -17.829\n",
      "2025-11-03:12:08:09,997 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3500: Best score = -17.829\n",
      "2025-11-03:12:08:10,60 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3600: Best score = -17.829\n",
      "2025-11-03:12:08:10,127 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3700: Best score = -17.829\n",
      "2025-11-03:12:08:10,191 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3800: Best score = -17.829\n",
      "2025-11-03:12:08:10,252 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3900: Best score = -17.829\n",
      "2025-11-03:12:08:10,316 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4000: Best score = -17.829\n",
      "2025-11-03:12:08:10,381 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4100: Best score = -17.829\n",
      "2025-11-03:12:08:10,443 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4200: Best score = -17.829\n",
      "2025-11-03:12:08:10,506 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4300: Best score = -17.829\n",
      "2025-11-03:12:08:10,572 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4400: Best score = -17.829\n",
      "2025-11-03:12:08:10,635 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4500: Best score = -17.829\n",
      "2025-11-03:12:08:10,700 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4600: Best score = -17.829\n",
      "2025-11-03:12:08:10,762 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4700: Best score = -17.829\n",
      "2025-11-03:12:08:10,826 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4800: Best score = -17.829\n",
      "2025-11-03:12:08:10,892 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4900: Best score = -17.829\n",
      "2025-11-03:12:08:10,960 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/main.py:111 16918 evaluations | 3.385% of total\n",
      "2025-11-03:12:08:10,968 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/main.py:117 Saved results to: results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 results (lowest scores):\n",
      "shape: (10, 3)\n",
      "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
      "│ score      ┆ SMILES                          ┆ Name            │\n",
      "│ ---        ┆ ---                             ┆ ---             │\n",
      "│ f64        ┆ str                             ┆ str             │\n",
      "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
      "│ -13.757272 ┆ CO[C@H]1CC[C@H](C(=O)N2CCCC[C@… ┆ CA7_AA45_AA61   │\n",
      "│ -12.07653  ┆ C#Cc1cccc(C(=O)N2CCC(CC(=O)N3C… ┆ CA72_AA31_AA35  │\n",
      "│ -12.419353 ┆ NC(=O)CC1CCN(C(=O)[C@@H](Cc2cc… ┆ CA128_AA9_AA31  │\n",
      "│ -12.388694 ┆ CN(CC(=O)N[C@H](Cc1ccccn1)C(N)… ┆ CA117_AA41_AA9  │\n",
      "│ -10.953067 ┆ CCCCC[C@H](NC(=O)c1cc2ccccc2[n… ┆ CA122_AA42_AA21 │\n",
      "│ -12.194119 ┆ CC(C)(C)Oc1ccc(C[C@H](NC(=O)C(… ┆ CA122_AA43_AA60 │\n",
      "│ -12.377135 ┆ Cc1cn(CC(=O)N2CSC[C@H]2C(=O)N[… ┆ CA106_AA24_AA61 │\n",
      "│ -12.364277 ┆ CC(C)(C)OC[C@H](NC(=O)c1cc2scc… ┆ CA11_AA47_AA13  │\n",
      "│ -13.171955 ┆ CC(C)(C)OC[C@H](NC(=O)[C@@H](C… ┆ CA55_AA28_AA47  │\n",
      "│ -12.019651 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA26_AA24_AA61  │\n",
      "└────────────┴─────────────────────────────────┴─────────────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score</th><th>SMILES</th><th>Name</th></tr><tr><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>-17.828762</td><td>&quot;CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC…</td><td>&quot;CA99_AA28_AA61&quot;</td></tr><tr><td>-17.288765</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA124_AA28_AA61&quot;</td></tr><tr><td>-17.248438</td><td>&quot;COc1cc(C(=O)N[C@H](CC2CCCCC2)C…</td><td>&quot;CA95_AA28_AA61&quot;</td></tr><tr><td>-17.240562</td><td>&quot;CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC…</td><td>&quot;CA116_AA28_AA61&quot;</td></tr><tr><td>-17.236963</td><td>&quot;CC(C)c1ccc(C(=O)N[C@H](CC2CCCC…</td><td>&quot;CA30_AA28_AA61&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-15.915207</td><td>&quot;C[C@H](NC(=O)c1ccc[nH]1)C(=O)N…</td><td>&quot;CA128_AA46_AA23&quot;</td></tr><tr><td>-15.910948</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA84_AA32_AA61&quot;</td></tr><tr><td>-15.901495</td><td>&quot;CC1(C)Oc2ccc(C[C@H](NC(=O)CNC(…</td><td>&quot;CA0_AA22_AA0&quot;</td></tr><tr><td>-15.889789</td><td>&quot;C#Cc1cccc(C(=O)NCC(=O)Nc2cc3cc…</td><td>&quot;CA72_AA22_AA12&quot;</td></tr><tr><td>-15.882493</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA67_AA32_AA61&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 3)\n",
       "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
       "│ score      ┆ SMILES                          ┆ Name            │\n",
       "│ ---        ┆ ---                             ┆ ---             │\n",
       "│ f64        ┆ str                             ┆ str             │\n",
       "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
       "│ -17.828762 ┆ CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC… ┆ CA99_AA28_AA61  │\n",
       "│ -17.288765 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA124_AA28_AA61 │\n",
       "│ -17.248438 ┆ COc1cc(C(=O)N[C@H](CC2CCCCC2)C… ┆ CA95_AA28_AA61  │\n",
       "│ -17.240562 ┆ CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC… ┆ CA116_AA28_AA61 │\n",
       "│ -17.236963 ┆ CC(C)c1ccc(C(=O)N[C@H](CC2CCCC… ┆ CA30_AA28_AA61  │\n",
       "│ …          ┆ …                               ┆ …               │\n",
       "│ -15.915207 ┆ C[C@H](NC(=O)c1ccc[nH]1)C(=O)N… ┆ CA128_AA46_AA23 │\n",
       "│ -15.910948 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA84_AA32_AA61  │\n",
       "│ -15.901495 ┆ CC1(C)Oc2ccc(C[C@H](NC(=O)CNC(… ┆ CA0_AA22_AA0    │\n",
       "│ -15.889789 ┆ C#Cc1cccc(C(=O)NCC(=O)Nc2cc3cc… ┆ CA72_AA22_AA12  │\n",
       "│ -15.882493 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA67_AA32_AA61  │\n",
       "└────────────┴─────────────────────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gives the search results without the warm-up phase\n",
    "results_df = run_ts(preset_config)\n",
    "# If the user wants to see the warm-up results as well, they can use the `include_warmup` argument\n",
    "# results_df = run_ts(preset_config, include_warmup=True)\n",
    "## Demonstrate Thompson Sampling with Nested Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1003b6",
   "metadata": {},
   "source": [
    "## Demonstrate Thompson Sampling with Nested Configuration\n",
    "This is a \"Do it yourself\" set up, where the user has a lot more control over the parameters that are used to run the Thompson sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d020832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU choose every single component and parameter\n",
    "config = ThompsonSamplingConfig(\n",
    "    reaction_smarts=\"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    reagent_file_list= [\"/Users/aakankschitnandkeolyar/Desktop/TACTICS/examples/input_files/acids.smi\",\n",
    "     \"/Users/aakankschitnandkeolyar/Desktop/TACTICS/examples/input_files/coupled_aa_sub.smi\"],\n",
    "    num_ts_iterations=5000,\n",
    "    num_warmup_trials=10,\n",
    "    \n",
    "    # Manually configure strategy\n",
    "    strategy_config=RouletteWheelConfig(\n",
    "        mode=\"minimize\",\n",
    "        alpha=0.15,          # You control this\n",
    "        beta=0.12,           # You control this\n",
    "        scaling=2.0,         # You control this\n",
    "        alpha_increment=0.02,\n",
    "        beta_increment=0.003,\n",
    "        efficiency_threshold=0.2\n",
    "    ),\n",
    "    \n",
    "    # Manually configure warmup\n",
    "    warmup_config=StratifiedWarmupConfig(),\n",
    "    \n",
    "    # Manually configure evaluator\n",
    "    evaluator_config=LookupEvaluatorConfig(\n",
    "        ref_filename=\"/Users/aakankschitnandkeolyar/Desktop/TACTICS/examples/docking_scores/product_scores.csv\",\n",
    "        ref_colname=\"Scores\"\n",
    "    ),\n",
    "    \n",
    "    # Manually configure performance\n",
    "    batch_size=1,\n",
    "    processes=1,\n",
    "    min_cpds_per_core=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c32a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:11:11:14,981 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:194 5.00e+05 possible products\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler initialized with 5.00e+05 possible products\n"
     ]
    }
   ],
   "source": [
    "sampler = ThompsonSampler.from_config(config)\n",
    "\n",
    "# IMPORTANT: Set the reaction (required step)\n",
    "sampler.set_reaction(config.reaction_smarts)\n",
    "print(f\"Sampler initialized with {sampler.get_num_prods():.2e} possible products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af724c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:11:11:17,54 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:292 Warmup strategy: StratifiedWarmup, num_trials=10, expected_evaluations=39740\n",
      "2025-11-03:11:11:17,181 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:305 Generated 39659 warmup combinations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting warmup phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:11:11:22,717 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:330 Warmup score stats: cnt=39659, mean=-10.7096, std=1.6255, min=-17.0156, max=4.4986\n",
      "2025-11-03:11:11:22,764 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:361 Top score found during warmup: -17.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup complete: 39659 compounds evaluated\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting warmup phase...\")\n",
    "warmup_results = sampler.warm_up(num_warmup_trials=config.num_warmup_trials)\n",
    "print(f\"Warmup complete: {len(warmup_results)} compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d144531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Thompson Sampling search (5000 iterations)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25307f310ba3463aa8b1deebd0e78972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Search:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:11:11:29,256 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 0: Best score = -13.836\n",
      "2025-11-03:11:11:29,319 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 100: Best score = -17.016\n",
      "2025-11-03:11:11:29,376 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 200: Best score = -17.016\n",
      "2025-11-03:11:11:29,426 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 300: Best score = -17.016\n",
      "2025-11-03:11:11:29,476 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 400: Best score = -17.016\n",
      "2025-11-03:11:11:29,526 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 500: Best score = -17.016\n",
      "2025-11-03:11:11:29,576 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 600: Best score = -17.248\n",
      "2025-11-03:11:11:29,625 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 700: Best score = -17.248\n",
      "2025-11-03:11:11:29,674 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 800: Best score = -17.248\n",
      "2025-11-03:11:11:29,723 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 900: Best score = -17.248\n",
      "2025-11-03:11:11:29,773 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1000: Best score = -17.248\n",
      "2025-11-03:11:11:29,827 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1100: Best score = -17.248\n",
      "2025-11-03:11:11:29,877 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1200: Best score = -17.829\n",
      "2025-11-03:11:11:29,929 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1300: Best score = -17.829\n",
      "2025-11-03:11:11:29,981 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1400: Best score = -17.829\n",
      "2025-11-03:11:11:30,30 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1500: Best score = -17.829\n",
      "2025-11-03:11:11:30,80 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1600: Best score = -17.829\n",
      "2025-11-03:11:11:30,128 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1700: Best score = -17.829\n",
      "2025-11-03:11:11:30,178 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1800: Best score = -17.829\n",
      "2025-11-03:11:11:30,225 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1900: Best score = -17.829\n",
      "2025-11-03:11:11:30,276 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2000: Best score = -17.829\n",
      "2025-11-03:11:11:30,325 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2100: Best score = -17.829\n",
      "2025-11-03:11:11:30,376 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2200: Best score = -17.829\n",
      "2025-11-03:11:11:30,424 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2300: Best score = -17.829\n",
      "2025-11-03:11:11:30,474 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2400: Best score = -17.829\n",
      "2025-11-03:11:11:30,523 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2500: Best score = -17.829\n",
      "2025-11-03:11:11:30,574 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2600: Best score = -17.829\n",
      "2025-11-03:11:11:30,623 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2700: Best score = -17.829\n",
      "2025-11-03:11:11:30,674 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2800: Best score = -17.829\n",
      "2025-11-03:11:11:30,724 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2900: Best score = -17.829\n",
      "2025-11-03:11:11:30,773 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3000: Best score = -17.829\n",
      "2025-11-03:11:11:30,822 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3100: Best score = -17.829\n",
      "2025-11-03:11:11:30,872 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3200: Best score = -17.829\n",
      "2025-11-03:11:11:30,920 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3300: Best score = -17.829\n",
      "2025-11-03:11:11:30,974 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3400: Best score = -17.829\n",
      "2025-11-03:11:11:31,24 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3500: Best score = -17.829\n",
      "2025-11-03:11:11:31,74 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3600: Best score = -17.829\n",
      "2025-11-03:11:11:31,123 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3700: Best score = -17.829\n",
      "2025-11-03:11:11:31,173 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3800: Best score = -17.829\n",
      "2025-11-03:11:11:31,222 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3900: Best score = -17.829\n",
      "2025-11-03:11:11:31,272 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4000: Best score = -17.829\n",
      "2025-11-03:11:11:31,322 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4100: Best score = -17.829\n",
      "2025-11-03:11:11:31,371 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4200: Best score = -17.829\n",
      "2025-11-03:11:11:31,423 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4300: Best score = -17.829\n",
      "2025-11-03:11:11:31,484 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4400: Best score = -17.829\n",
      "2025-11-03:11:11:31,535 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4500: Best score = -17.829\n",
      "2025-11-03:11:11:31,585 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4600: Best score = -17.829\n",
      "2025-11-03:11:11:31,636 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4700: Best score = -17.829\n",
      "2025-11-03:11:11:31,688 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4800: Best score = -17.829\n",
      "2025-11-03:11:11:31,736 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4900: Best score = -17.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search complete: 5000 total compounds evaluated\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting Thompson Sampling search ({config.num_ts_iterations} iterations)...\")\n",
    "search_results = sampler.search(num_cycles=config.num_ts_iterations)\n",
    "print(f\"Search complete: {len(search_results)} total compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcfc7a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (44_659, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score</th><th>SMILES</th><th>Name</th></tr><tr><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>-10.461056</td><td>&quot;CC(C)(C)Oc1ccc(C[C@H](NC(=O)C2…</td><td>&quot;CA0_AA13_AA60&quot;</td></tr><tr><td>-11.083033</td><td>&quot;CCCCC[C@H](NC(=O)[C@H](C)N(C)C…</td><td>&quot;CA0_AA20_AA42&quot;</td></tr><tr><td>-11.299453</td><td>&quot;NC(=O)[C@@H]1CCCN1C(=O)[C@H](C…</td><td>&quot;CA0_AA55_AA48&quot;</td></tr><tr><td>-11.633983</td><td>&quot;NC(=O)[C@@H](Cc1ccccn1)NC(=O)[…</td><td>&quot;CA0_AA9_AA9&quot;</td></tr><tr><td>-11.129601</td><td>&quot;NC(=O)c1cc2ccccc2cc1NC(=O)CN1C…</td><td>&quot;CA0_AA29_AA12&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-13.693502</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA21_AA61_AA48&quot;</td></tr><tr><td>-12.478289</td><td>&quot;NC(=O)[C@H]1CC[C@H](CNC(=O)[C@…</td><td>&quot;CA117_AA45_AA17&quot;</td></tr><tr><td>-14.696342</td><td>&quot;CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@…</td><td>&quot;CA128_AA9_AA0&quot;</td></tr><tr><td>-14.273651</td><td>&quot;NC(=O)[C@@H]1C[C@H](F)CN1C(=O)…</td><td>&quot;CA11_AA23_AA35&quot;</td></tr><tr><td>-13.070341</td><td>&quot;NC(=O)CC1CCN(C(=O)[C@@H](CC2CC…</td><td>&quot;CA93_AA28_AA31&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (44_659, 3)\n",
       "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
       "│ score      ┆ SMILES                          ┆ Name            │\n",
       "│ ---        ┆ ---                             ┆ ---             │\n",
       "│ f64        ┆ str                             ┆ str             │\n",
       "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
       "│ -10.461056 ┆ CC(C)(C)Oc1ccc(C[C@H](NC(=O)C2… ┆ CA0_AA13_AA60   │\n",
       "│ -11.083033 ┆ CCCCC[C@H](NC(=O)[C@H](C)N(C)C… ┆ CA0_AA20_AA42   │\n",
       "│ -11.299453 ┆ NC(=O)[C@@H]1CCCN1C(=O)[C@H](C… ┆ CA0_AA55_AA48   │\n",
       "│ -11.633983 ┆ NC(=O)[C@@H](Cc1ccccn1)NC(=O)[… ┆ CA0_AA9_AA9     │\n",
       "│ -11.129601 ┆ NC(=O)c1cc2ccccc2cc1NC(=O)CN1C… ┆ CA0_AA29_AA12   │\n",
       "│ …          ┆ …                               ┆ …               │\n",
       "│ -13.693502 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA21_AA61_AA48  │\n",
       "│ -12.478289 ┆ NC(=O)[C@H]1CC[C@H](CNC(=O)[C@… ┆ CA117_AA45_AA17 │\n",
       "│ -14.696342 ┆ CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@… ┆ CA128_AA9_AA0   │\n",
       "│ -14.273651 ┆ NC(=O)[C@@H]1C[C@H](F)CN1C(=O)… ┆ CA11_AA23_AA35  │\n",
       "│ -13.070341 ┆ NC(=O)CC1CCN(C(=O)[C@@H](CC2CC… ┆ CA93_AA28_AA31  │\n",
       "└────────────┴─────────────────────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.concat([warmup_results,search_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a16b833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 compounds found:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score</th><th>SMILES</th><th>Name</th></tr><tr><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>-17.828762</td><td>&quot;CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC…</td><td>&quot;CA99_AA28_AA61&quot;</td></tr><tr><td>-17.288765</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA124_AA28_AA61&quot;</td></tr><tr><td>-17.248438</td><td>&quot;COc1cc(C(=O)N[C@H](CC2CCCCC2)C…</td><td>&quot;CA95_AA28_AA61&quot;</td></tr><tr><td>-17.240562</td><td>&quot;CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC…</td><td>&quot;CA116_AA28_AA61&quot;</td></tr><tr><td>-17.236963</td><td>&quot;CC(C)c1ccc(C(=O)N[C@H](CC2CCCC…</td><td>&quot;CA30_AA28_AA61&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-15.934307</td><td>&quot;NC(=O)[C@@H]1CC2(CC2)CN1C(=O)[…</td><td>&quot;CA8_AA23_AA32&quot;</td></tr><tr><td>-15.927516</td><td>&quot;CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@…</td><td>&quot;CA128_AA28_AA0&quot;</td></tr><tr><td>-15.926538</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA92_AA45_AA61&quot;</td></tr><tr><td>-15.926527</td><td>&quot;CN(C[C@H]1CC[C@H](C(N)=O)CC1)C…</td><td>&quot;CA11_AA23_AA1&quot;</td></tr><tr><td>-15.92254</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA64_AA32_AA61&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 3)\n",
       "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
       "│ score      ┆ SMILES                          ┆ Name            │\n",
       "│ ---        ┆ ---                             ┆ ---             │\n",
       "│ f64        ┆ str                             ┆ str             │\n",
       "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
       "│ -17.828762 ┆ CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC… ┆ CA99_AA28_AA61  │\n",
       "│ -17.288765 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA124_AA28_AA61 │\n",
       "│ -17.248438 ┆ COc1cc(C(=O)N[C@H](CC2CCCCC2)C… ┆ CA95_AA28_AA61  │\n",
       "│ -17.240562 ┆ CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC… ┆ CA116_AA28_AA61 │\n",
       "│ -17.236963 ┆ CC(C)c1ccc(C(=O)N[C@H](CC2CCCC… ┆ CA30_AA28_AA61  │\n",
       "│ …          ┆ …                               ┆ …               │\n",
       "│ -15.934307 ┆ NC(=O)[C@@H]1CC2(CC2)CN1C(=O)[… ┆ CA8_AA23_AA32   │\n",
       "│ -15.927516 ┆ CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@… ┆ CA128_AA28_AA0  │\n",
       "│ -15.926538 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA92_AA45_AA61  │\n",
       "│ -15.926527 ┆ CN(C[C@H]1CC[C@H](C(N)=O)CC1)C… ┆ CA11_AA23_AA1   │\n",
       "│ -15.92254  ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA64_AA32_AA61  │\n",
       "└────────────┴─────────────────────────────────┴─────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine warmup and search results\n",
    "all_results = pl.concat([warmup_results,search_results])\n",
    "\n",
    "# Display top 100 compounds (lowest scores = best for docking)\n",
    "top_100 = all_results.sort(\"score\").head(100)\n",
    "print(\"\\nTop 100 compounds found:\")\n",
    "display(top_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd77f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "top_100.write_csv(\"./tmp/ts_results.csv\", index=False)\n",
    "print(\"Results saved to ./tmp/ts_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Sampler\n",
    "# Mainly to be used if you want to deploy multi-processing\n",
    "sampler.close()\n",
    "print(\"Sampler closed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ed03f",
   "metadata": {},
   "source": [
    "## Demonstration with a Preset\n",
    "This is an easier method to run TS fast with a set of default parameters. But we are not going to use the wrapper function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70923f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:11:01,503 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:194 5.00e+05 possible products\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler initialized with 5.00e+05 possible products\n"
     ]
    }
   ],
   "source": [
    "sampler_preset = ThompsonSampler.from_config(preset_config)\n",
    "\n",
    "# IMPORTANT: Set the reaction (required step)\n",
    "sampler_preset.set_reaction(preset_config.reaction_smarts)\n",
    "print(f\"Sampler initialized with {sampler_preset.get_num_prods():.2e} possible products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df83c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:11:04,699 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:292 Warmup strategy: StratifiedWarmup, num_trials=3, expected_evaluations=11922\n",
      "2025-11-03:12:11:04,781 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:305 Generated 11906 warmup combinations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting warmup phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:11:07,273 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:330 Warmup score stats: cnt=11906, mean=-10.7135, std=1.6318, min=-16.8092, max=7.0512\n",
      "2025-11-03:12:11:07,294 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:361 Top score found during warmup: -16.809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup complete: 11906 compounds evaluated\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting warmup phase...\")\n",
    "warmup_results_preset = sampler_preset.warm_up(num_warmup_trials=preset_config.num_warmup_trials)\n",
    "print(f\"Warmup complete: {len(warmup_results_preset)} compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b893ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Thompson Sampling search (5000 iterations)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e471d8eaee4f428cb4da7eecfd6e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Search:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:11:09,683 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 0: Best score = -13.984\n",
      "2025-11-03:12:11:09,754 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 100: Best score = -17.016\n",
      "2025-11-03:12:11:09,818 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 200: Best score = -17.248\n",
      "2025-11-03:12:11:09,884 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 300: Best score = -17.248\n",
      "2025-11-03:12:11:09,947 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 400: Best score = -17.248\n",
      "2025-11-03:12:11:10,11 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 500: Best score = -17.248\n",
      "2025-11-03:12:11:10,84 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 600: Best score = -17.248\n",
      "2025-11-03:12:11:10,151 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 700: Best score = -17.248\n",
      "2025-11-03:12:11:10,217 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 800: Best score = -17.248\n",
      "2025-11-03:12:11:10,283 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 900: Best score = -17.248\n",
      "2025-11-03:12:11:10,348 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1000: Best score = -17.248\n",
      "2025-11-03:12:11:10,415 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1100: Best score = -17.248\n",
      "2025-11-03:12:11:10,483 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1200: Best score = -17.248\n",
      "2025-11-03:12:11:10,553 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1300: Best score = -17.248\n",
      "2025-11-03:12:11:10,623 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1400: Best score = -17.248\n",
      "2025-11-03:12:11:10,691 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1500: Best score = -17.248\n",
      "2025-11-03:12:11:10,757 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1600: Best score = -17.248\n",
      "2025-11-03:12:11:10,821 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1700: Best score = -17.248\n",
      "2025-11-03:12:11:10,884 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1800: Best score = -17.248\n",
      "2025-11-03:12:11:10,948 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1900: Best score = -17.248\n",
      "2025-11-03:12:11:11,16 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2000: Best score = -17.248\n",
      "2025-11-03:12:11:11,79 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2100: Best score = -17.248\n",
      "2025-11-03:12:11:11,144 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2200: Best score = -17.248\n",
      "2025-11-03:12:11:11,209 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2300: Best score = -17.248\n",
      "2025-11-03:12:11:11,270 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2400: Best score = -17.829\n",
      "2025-11-03:12:11:11,333 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2500: Best score = -17.829\n",
      "2025-11-03:12:11:11,395 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2600: Best score = -17.829\n",
      "2025-11-03:12:11:11,460 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2700: Best score = -17.829\n",
      "2025-11-03:12:11:11,523 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2800: Best score = -17.829\n",
      "2025-11-03:12:11:11,587 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2900: Best score = -17.829\n",
      "2025-11-03:12:11:11,651 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3000: Best score = -17.829\n",
      "2025-11-03:12:11:11,715 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3100: Best score = -17.829\n",
      "2025-11-03:12:11:11,778 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3200: Best score = -17.829\n",
      "2025-11-03:12:11:11,842 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3300: Best score = -17.829\n",
      "2025-11-03:12:11:11,903 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3400: Best score = -17.829\n",
      "2025-11-03:12:11:11,966 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3500: Best score = -17.829\n",
      "2025-11-03:12:11:12,30 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3600: Best score = -17.829\n",
      "2025-11-03:12:11:12,91 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3700: Best score = -17.829\n",
      "2025-11-03:12:11:12,156 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3800: Best score = -17.829\n",
      "2025-11-03:12:11:12,221 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3900: Best score = -17.829\n",
      "2025-11-03:12:11:12,283 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4000: Best score = -17.829\n",
      "2025-11-03:12:11:12,345 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4100: Best score = -17.829\n",
      "2025-11-03:12:11:12,405 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4200: Best score = -17.829\n",
      "2025-11-03:12:11:12,468 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4300: Best score = -17.829\n",
      "2025-11-03:12:11:12,531 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4400: Best score = -17.829\n",
      "2025-11-03:12:11:12,592 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4500: Best score = -17.829\n",
      "2025-11-03:12:11:12,655 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4600: Best score = -17.829\n",
      "2025-11-03:12:11:12,720 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4700: Best score = -17.829\n",
      "2025-11-03:12:11:12,781 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4800: Best score = -17.829\n",
      "2025-11-03:12:11:12,845 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4900: Best score = -17.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search complete: 5000 total compounds evaluated\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting Thompson Sampling search ({config.num_ts_iterations} iterations)...\")\n",
    "search_results_preset = sampler_preset.search(num_cycles=preset_config.num_ts_iterations)\n",
    "print(f\"Search complete: {len(search_results_preset)} total compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be32e265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 compounds found:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score</th><th>SMILES</th><th>Name</th></tr><tr><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>-17.828762</td><td>&quot;CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC…</td><td>&quot;CA99_AA28_AA61&quot;</td></tr><tr><td>-17.288765</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA124_AA28_AA61&quot;</td></tr><tr><td>-17.248438</td><td>&quot;COc1cc(C(=O)N[C@H](CC2CCCCC2)C…</td><td>&quot;CA95_AA28_AA61&quot;</td></tr><tr><td>-17.240562</td><td>&quot;CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC…</td><td>&quot;CA116_AA28_AA61&quot;</td></tr><tr><td>-17.236963</td><td>&quot;CC(C)c1ccc(C(=O)N[C@H](CC2CCCC…</td><td>&quot;CA30_AA28_AA61&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-15.926538</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA92_AA45_AA61&quot;</td></tr><tr><td>-15.92254</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA64_AA32_AA61&quot;</td></tr><tr><td>-15.910948</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA84_AA32_AA61&quot;</td></tr><tr><td>-15.901495</td><td>&quot;CC1(C)Oc2ccc(C[C@H](NC(=O)CNC(…</td><td>&quot;CA0_AA22_AA0&quot;</td></tr><tr><td>-15.901007</td><td>&quot;CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@…</td><td>&quot;CA115_AA28_AA0&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 3)\n",
       "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
       "│ score      ┆ SMILES                          ┆ Name            │\n",
       "│ ---        ┆ ---                             ┆ ---             │\n",
       "│ f64        ┆ str                             ┆ str             │\n",
       "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
       "│ -17.828762 ┆ CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC… ┆ CA99_AA28_AA61  │\n",
       "│ -17.288765 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA124_AA28_AA61 │\n",
       "│ -17.248438 ┆ COc1cc(C(=O)N[C@H](CC2CCCCC2)C… ┆ CA95_AA28_AA61  │\n",
       "│ -17.240562 ┆ CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC… ┆ CA116_AA28_AA61 │\n",
       "│ -17.236963 ┆ CC(C)c1ccc(C(=O)N[C@H](CC2CCCC… ┆ CA30_AA28_AA61  │\n",
       "│ …          ┆ …                               ┆ …               │\n",
       "│ -15.926538 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA92_AA45_AA61  │\n",
       "│ -15.92254  ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA64_AA32_AA61  │\n",
       "│ -15.910948 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA84_AA32_AA61  │\n",
       "│ -15.901495 ┆ CC1(C)Oc2ccc(C[C@H](NC(=O)CNC(… ┆ CA0_AA22_AA0    │\n",
       "│ -15.901007 ┆ CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@… ┆ CA115_AA28_AA0  │\n",
       "└────────────┴─────────────────────────────────┴─────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine warmup and search results\n",
    "all_results_preset = pl.concat([warmup_results_preset,search_results_preset])\n",
    "\n",
    "# Display top 100 compounds (lowest scores = best for docking)\n",
    "top_100_preset = all_results_preset.sort(\"score\").head(100)\n",
    "print(\"\\nTop 100 compounds found:\")\n",
    "display(top_100_preset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "results_df_preset.to_csv(\"./tmp/ts_results_preset.csv\", index=False)\n",
    "print(\"Results saved to ./tmp/ts_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f2e3b",
   "metadata": {},
   "source": [
    "# Testing Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673e62c",
   "metadata": {},
   "source": [
    "*TACTICS.thompson_sampling.ts_main does not exist. Tried TACTICS.thompson_sampling.main, but this does not contain parse_input_dict(), so the script breaks after the third code block.*\n",
    "\n",
    "*Using the legacy TACTICS.thompson_sampling.legacy.ts_main also doesn't work as sampler_type is not defined.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a7c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remco/.conda/envs/tactics/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/evaluators.py:16: UserWarning: Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or FredEvaluator\n",
      "  warnings.warn(f\"Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or \"\n"
     ]
    }
   ],
   "source": [
    "from TACTICS.thompson_sampling.main import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545da7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_file = \"\"\"{\n",
    "\"reagent_file_list\": [\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    \"reaction_smarts\": \"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    \"num_warmup_trials\": 10,\n",
    "    \"num_ts_iterations\": 5000,\n",
    "    \"search_strategy\": \"greedy_minimize_dt\",\n",
    "    \"processes\": 1,\n",
    "    \"percent_of_library\": 0.1,\n",
    "    \"scaling\": -1,\n",
    "    \"temperature\": 1,\n",
    "    \"evaluator_class_name\": \"LookupEvaluator\",\n",
    "    \"evaluator_arg\": {\"ref_filename\" : \"../examples/docking_scores/product_scores.csv\"},\n",
    "    \"log_filename\": \"./tmp/ts_logs.txt\",\n",
    "    \"results_filename\": \"./tmp/ts_results.csv\"\n",
    "}\"\"\"\n",
    "input_dict = json.loads(input_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea732595",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_input_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mparse_input_dict\u001b[49m(input_dict)\n",
      "\u001b[31mNameError\u001b[39m: name 'parse_input_dict' is not defined"
     ]
    }
   ],
   "source": [
    "parse_input_dict(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff828aa",
   "metadata": {},
   "source": [
    "*_______ Unable to continue further _______*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_std_df = run_ts(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44155171",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_std_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c658e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.sort(\"Scores\", descending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19dd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the TS dataframe so that it is compatible with the get_top_building_blocks function\n",
    "ts_df_mod = ts_std_df.copy()\n",
    "ts_df_mod = ts_df_mod.drop(\"SMILES\",axis=1)\n",
    "ts_df_mod.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "top_5000_building_blocks_ts_df = get_top_building_blocks(ts_df_mod, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overlap between the enriched building blocks from the TS and the top 5000 building blocks from brute force docking\n",
    "overlap_ts = check_overlap(top_5000_building_blocks_ts_df, top_5000_building_blocks)\n",
    "visualize_overlapping_blocks(overlap_ts, combined_smiles_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26100d1",
   "metadata": {},
   "source": [
    "### Check Consistency of the TS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_df_list.append(run_ts(input_dict, hide_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d011bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_std_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_molecules = 5000  # The top 1% of products\n",
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f2c62",
   "metadata": {},
   "source": [
    "## Boltzmann Sampling \n",
    "Utilizes Boltzmann sampling instead of standard greedy sampling to find new compounds to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5de806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "input_dict_boltzmann = copy.copy(input_dict)\n",
    "input_dict_boltzmann[\"search_strategy\"] = \"boltzmann_minimize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_boltzmann_df = run_ts(input_dict_boltzmann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34728219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the TS dataframe so that it is compatible with the get_top_building_blocks function\n",
    "ts_Boltzmann_df_mod = ts_boltzmann_df.copy()\n",
    "ts_Boltzmann_df_mod = ts_Boltzmann_df_mod.drop(\"SMILES\",axis=1)\n",
    "ts_Boltzmann_df_mod.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "top_5000_building_blocks_ts_Boltzmann_df = get_top_building_blocks(ts_Boltzmann_df_mod, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aceed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overlap between the enriched building blocks from the TS and the top 5000 building blocks from brute force docking\n",
    "overlap_ts_Boltzmann = check_overlap(top_5000_building_blocks_ts_Boltzmann_df, top_5000_building_blocks)\n",
    "visualize_overlapping_blocks(overlap_ts_Boltzmann, combined_smiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b23e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 runs of Boltzmann Sampling\n",
    "ts_boltzmann_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_boltzmann_df_list.append(run_ts(input_dict_boltzmann, hide_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff127895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_boltzmann_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effa03b",
   "metadata": {},
   "source": [
    "#### Run these cells to generate the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes \n",
    "docking_df = prod_scores_df.to_pandas() # Convert the polars dataframe to a pandas dataframe\n",
    "docking_df.rename(columns={\"Product_Code\":\"Name\", \"Scores\":\"score\"},inplace=True)\n",
    "docking_df[\"method\"] = \"ref\"\n",
    "docking_df[\"cycle\"] = \"ref\"\n",
    "ref_df = docking_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ef3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the TS dataframes\n",
    "# We can substitute the regular TS with enhanced TS here\n",
    "ts_graph_df_list = []\n",
    "ts_enhanced_df_list_graph = []\n",
    "ts_boltzmann_df_list_graph = []\n",
    "for i in range(0,10):\n",
    "    ts_df_temp = ts_df_list[i].copy()\n",
    "    ts_df_temp[\"cycle\"] = i\n",
    "    ts_df_temp[\"method\"] = \"TS\"\n",
    "    ts_df_temp.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_graph_df_list.append(ts_df_temp)\n",
    "    ts_enhanced_temp_df = ts_enhanced_df_list[i].copy()\n",
    "    ts_enhanced_temp_df[\"cycle\"] = i\n",
    "    ts_enhanced_temp_df[\"method\"] = \"TS_enhanced\"\n",
    "    ts_enhanced_temp_df.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_enhanced_df_list_graph.append(ts_enhanced_temp_df)\n",
    "    ts_boltzmann_temp_df = ts_boltzmann_df_list[i].copy()\n",
    "    ts_boltzmann_temp_df[\"cycle\"] = i\n",
    "    ts_boltzmann_temp_df[\"method\"] = \"TS_Boltzmann\"\n",
    "    ts_boltzmann_temp_df.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_boltzmann_df_list_graph.append(ts_boltzmann_temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6075f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes\n",
    "ts_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_graph_df_list])\n",
    "ts_enhanced_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_enhanced_df_list_graph])\n",
    "ts_boltzmann_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_boltzmann_df_list_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ffd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create concatenated data points only for TS, TS_enhanced and TS_Boltzmann\n",
    "concat_data = pd.DataFrame({\n",
    "    'cycle': ['concat'] * (len(ts_combo_df) + len(ts_enhanced_combo_df) + len(ts_boltzmann_combo_df)),\n",
    "    'score': pd.concat([ts_combo_df['score'], ts_enhanced_combo_df['score'], ts_boltzmann_combo_df['score']]),\n",
    "    'method': pd.concat([ts_combo_df['method'], ts_enhanced_combo_df['method'], ts_boltzmann_combo_df['method']])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8140b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([ts_combo_df, ts_enhanced_combo_df, ts_boltzmann_combo_df, concat_data, ref_df])\n",
    "combined_df.reset_index(drop=True,inplace=True)\n",
    "combined_df.method = pd.Categorical(combined_df.method, categories=[\"ref\",\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a consistent color palette\n",
    "palette_colors = sns.color_palette(\"Set1\")[:4]\n",
    "\n",
    "# Top subplot (stripplot) with concatenated results\n",
    "ax1 = sns.stripplot(data=combined_df, x=\"cycle\", y=\"score\", hue=\"method\", dodge=True, palette=palette_colors)\n",
    "ax1.set_ylabel(\"Score\", fontsize=16)\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the numbers of hits found by each method in each cycle\n",
    "ref_products = ref_df[\"Name\"].to_list()\n",
    "plot_list = []\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS'])\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS_enhanced' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS_enhanced'])\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS_Boltzmann' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS_Boltzmann'])\n",
    "# Get Percentage of hits found by each method in each cycle\n",
    "plot_list.append([\"concat\",len(ts_enhanced_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS_enhanced\"])\n",
    "plot_list.append([\"concat\",len(ts_boltzmann_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS_Boltzmann\"])\n",
    "plot_list.append([\"concat\",len(ts_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS\"])\n",
    "plot_list.append([\"ref\",100,\"ref\"])\n",
    "plot_df = pd.DataFrame(plot_list, columns=[\"cycle\",\"found\",\"method\"])\n",
    "plot_df.method = pd.Categorical(plot_df.method, categories=[\"ref\",\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70444dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check if there is an actual difference between the standard and the enhanced TS\n",
    "from scipy import stats\n",
    "f_stat, p_value = stats.f_oneway(plot_df.loc[plot_df[\"method\"] == \"TS\",\"found\"], \n",
    "                                 plot_df.loc[plot_df[\"method\"] == \"TS_enhanced\",\"found\"], \n",
    "                                 plot_df.loc[plot_df[\"method\"] == \"TS_Boltzmann\",\"found\"])\n",
    "print(f\"F-statistic: {f_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "tukey = pairwise_tukeyhsd(endog=plot_df[\"found\"], groups=plot_df[\"method\"], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"cycle\",y=\"found\",hue=\"method\",data=plot_df, dodge=True)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger figure\n",
    "plt.figure(figsize=(15, 8))  # Increase these numbers to make plot bigger (width, height)\n",
    "\n",
    "# Create the barplot with wider bars\n",
    "ax = sns.barplot(x=\"cycle\", y=\"found\", hue=\"method\", data=plot_df, dodge=True, width=0.8, palette=\"Set1\")  # width controls bar width\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1)\n",
    "\n",
    "# Add value labels manually with larger font size\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                xy=(p.get_x() + p.get_width()/2, p.get_height()),\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=12)  # Increase font size of the numbers\n",
    "\n",
    "# Adjust figure margins\n",
    "plt.subplots_adjust(right=0.85, bottom=0.15)\n",
    "\n",
    "# Optional: Increase font size of axis labels and ticks\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.set_xlabel(ax.get_xlabel(), fontsize=14)\n",
    "ax.set_ylabel(ax.get_ylabel(), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 18), height_ratios=[2, 1])\n",
    "\n",
    "# Define a consistent color palette and category order\n",
    "palette_colors = sns.color_palette(\"Set1\")[:4]\n",
    "method_order = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\", \"ref\"]\n",
    "\n",
    "# Make sure both dataframes have the same category order\n",
    "combined_df.method = pd.Categorical(combined_df.method, categories=method_order, ordered=True)\n",
    "plot_df.method = pd.Categorical(plot_df.method, categories=method_order, ordered=True)\n",
    "\n",
    "# Top subplot (stripplot) with concatenated results\n",
    "sns.stripplot(data=combined_df, x=\"cycle\", y=\"score\", hue=\"method\", dodge=True, palette=palette_colors, ax=ax1)\n",
    "ax1.set_ylabel(\"Docking Score (Negative is Better)\", fontsize=16)\n",
    "ax1.set_xlabel(\"Cycle\", fontsize=16)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# Bottom subplot (barplot)\n",
    "sns.barplot(x=\"cycle\", y=\"found\", hue=\"method\", data=plot_df, dodge=True, width=0.8, palette=palette_colors, ax=ax2)\n",
    "# Remove the bottom legend\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "# Add value labels to bars, only for non-zero values\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:  # Only add label if the value is greater than 0\n",
    "        ax2.annotate(f'{int(height)}', \n",
    "                    xy=(p.get_x() + p.get_width()/2, height),\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=14)\n",
    "\n",
    "# Adjust font sizes for bottom plot\n",
    "ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax2.set_xlabel(\"Cycle\", fontsize=16)\n",
    "ax2.set_ylabel(\"Number of top 100 hits found\", fontsize=16)\n",
    "\n",
    "# Move the legend to the top of the figure and increase its font size\n",
    "legend = ax1.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1, fontsize=14)\n",
    "\n",
    "# Adjust layout with reduced spacing between plots\n",
    "plt.subplots_adjust(right=0.85, hspace=0.125)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ee38d",
   "metadata": {},
   "source": [
    "This can at first look misleading, but the it is important to remember that the more negative the `ChemGauss` score the better it is. Hence, points at the bottom of the plot are better to see than those at the top. The reference presents the best set of molecules as seen from brute-force docking, we see that the Boltzmann sampling does not appear to find most of the hits, hence the Boltzmann sampling is not a useful method to use to find hits for this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9565d9",
   "metadata": {},
   "source": [
    "## Enhanced Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac039a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "input_dict_enhanced_TS = copy.copy(input_dict)\n",
    "input_dict_enhanced_TS[\"search_strategy\"] = \"thermal_cycling\"\n",
    "input_dict_enhanced_TS[\"processes\"] = 1\n",
    "input_dict_enhanced_TS[\"percent_of_library\"] = 0.1\n",
    "input_dict_enhanced_TS[\"scaling\"] = -1\n",
    "input_dict_enhanced_TS[\"temperature\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df = run_ts(input_dict_enhanced_TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b35fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d55c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df = prod_scores_df.sort(\"Scores\", descending=False).head(100).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b97cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc69164",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_ts_enhanced_df = ts_enhanced_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(truth_df[\"Product_Code\"]) & set(top_100_ts_enhanced_df[\"Name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df = ts_enhanced_df.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28618b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df_slice = ts_enhanced_df. sort_values(by=\"Scores\", ascending=True).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4dbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 runs of Boltzmann Sampling\n",
    "ts_enhanced_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_enhanced_df_temp = run_ts(input_dict_enhanced_TS, hide_progress=True)\n",
    "    ts_enhanced_df_temp = ts_enhanced_df_temp.sort_values(by=\"score\", ascending=True).head(5000)\n",
    "    ts_enhanced_df_list.append(ts_enhanced_df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504eabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts_enhanced_df_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc48c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.sort([\"Scores\"], descending=False).head(100)\n",
    "prod_scores_df.head(100).select(pl.col(\"Scores\").min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ade9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.head(100).select(pl.col(\"Scores\").max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59277a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_list[0].sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_boltzmann_df_list[0].sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072cc13",
   "metadata": {},
   "source": [
    "### How much does the Enhanced TS recover using Docking as the Scoring Function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "prod_scores_df_pd = prod_scores_df.to_pandas()\n",
    "top_5k_truth = prod_scores_df_pd.sort_values(by=\"Scores\", ascending=True).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the an Instance of each of the TS methods\n",
    "# Re run this if the the dataframes need to be reset\n",
    "ts_std_df = ts_df_list[0].copy()\n",
    "ts_enhanced_df = ts_enhanced_df_list[0].copy()\n",
    "ts_boltzmann_df = ts_boltzmann_df_list[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01263c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dfs = [ts_std_df, ts_enhanced_df, ts_boltzmann_df]\n",
    "ts_types = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"]\n",
    "top_5k = {}\n",
    "for n, df in enumerate(ts_dfs):\n",
    "    df_temp = df.sort_values(by=\"score\", ascending=True).head(5000)\n",
    "    df_temp.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    df_temp.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "    top_5k[ts_types[n]] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cebee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5k[\"TS\"] = top_5k[\"TS\"][[\"Product_Code\"]].assign(standard=True)\n",
    "top_5k[\"TS_enhanced\"] = top_5k[\"TS_enhanced\"][[\"Product_Code\"]].assign(enhanced=True)\n",
    "top_5k[\"TS_Boltzmann\"] = top_5k[\"TS_Boltzmann\"][[\"Product_Code\"]].assign(boltzmann=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "df_top = pd.merge(pd.merge(pd.merge(top_5k_truth, top_5k[\"TS\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k[\"TS_enhanced\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k[\"TS_Boltzmann\"], how=\"left\", on=\"Product_Code\")\n",
    "df_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef756246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "    ax.plot(top_ns, [df_top.head(n)[col].sum() / n for n in top_ns], label=col, marker=\"o\")\n",
    "ax.set_xlabel(\"top N\")\n",
    "ax.set_ylabel(\"fraction_found\")\n",
    "ax.axhline(1, color=\"k\", linestyle=\"--\", zorder=0)\n",
    "ax.set_title(\"Frac of top N found\")\n",
    "ax.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123b173",
   "metadata": {},
   "source": [
    "It appears that the standard TS slightly underperforms the enhanced TS. The Boltzmann sampling's performance remains poor despite increasing the cutoff for the top n compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested in looking at the plot with error bars\n",
    "# Lets generate these error bars using the cycle data\n",
    "ts_comp = []\n",
    "ts_types = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"] # Types of TS to compare\n",
    "for n in range(0,10):\n",
    "    # Get the top 5000 compounds for each method\n",
    "    # Rename columns\n",
    "    ts_dfs_temp = [ts_df_list[n].copy(), ts_enhanced_df_list[n].copy(), ts_boltzmann_df_list[n].copy()]\n",
    "    ts_dfs_temp = [x.sort_values(by=\"score\", ascending=True).head(5000) for x in ts_dfs_temp]\n",
    "    ts_dfs_temp = [x.drop(columns=[\"SMILES\"]) for x in ts_dfs_temp]\n",
    "    ts_dfs_temp = [x.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"}) for x in ts_dfs_temp]\n",
    "    top_5k_temp = {}\n",
    "    for n, ts_type in enumerate(ts_types):\n",
    "        top_5k_temp[ts_type] = ts_dfs_temp[n] # Assign the appropriate dataframe to the dictionary\n",
    "        if n == 0: # Standard TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(standard=True)\n",
    "        elif n == 1: # Enhanced TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(enhanced=True)\n",
    "        else: # Boltzmann TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(boltzmann=True)\n",
    "    # Merge the dataframes\n",
    "    df_top = pd.merge(pd.merge(pd.merge(top_5k_truth, top_5k_temp[\"TS\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k_temp[\"TS_enhanced\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k_temp[\"TS_Boltzmann\"], how=\"left\", on=\"Product_Code\")\n",
    "    # Calculate the fraction of hits found for each method\n",
    "    ts_comp.append(df_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "top_ns_frac = pd.DataFrame(columns=[\"cycle\",\"top_n\", \"method\", \"frac_top_n\"])\n",
    "for cycle_id, ts_comp_df in enumerate(ts_comp):\n",
    "    for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "        for n in top_ns:\n",
    "            frac_top_ns = ts_comp_df.head(n)[col].sum() / n\n",
    "            row = {\"cycle\":cycle_id, \"top_n\":n, \"method\":col, \"frac_top_n\":frac_top_ns}\n",
    "            top_ns_frac = pd.concat([top_ns_frac, pd.DataFrame([row])], ignore_index=True)\n",
    "top_ns_frac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bab875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with mean, std and count of frac_top_n for each top_n and method\n",
    "grouped_stats = top_ns_frac.groupby(['top_n', 'method'])['frac_top_n'].agg(\n",
    "    mean='mean',\n",
    "    std='std',\n",
    "    count='count'\n",
    ").reset_index()\n",
    "\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6)) # set the size of the plot\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"tab10\", font_scale=1.2)\n",
    "\n",
    "# Ensure sub_category is sortable (e.g., categorical or ordered)\n",
    "grouped_stats['top_n'] = grouped_stats['top_n'].astype(str)\n",
    "\n",
    "# Line plot per category with error bars\n",
    "sns.lineplot(\n",
    "    data=grouped_stats,\n",
    "    x='top_n',\n",
    "    y='mean',\n",
    "    hue='method',  # color line by category\n",
    "    marker='o',\n",
    "    errorbar=None,\n",
    "    linewidth=2.5  # Disable built-in CI\n",
    ")\n",
    "\n",
    "# Add error bars manually using plt.errorbar\n",
    "for _, row in grouped_stats.iterrows():\n",
    "    if pd.notnull(row['std']):\n",
    "        plt.errorbar(\n",
    "            x=row['top_n'],\n",
    "            y=row['mean'],\n",
    "            yerr=row['std'],\n",
    "            fmt='none',\n",
    "            capsize=4,\n",
    "            ecolor='gray'\n",
    "        )\n",
    "\n",
    "plt.title(\"Mean top N fraction found for each method across 10 cycles\")\n",
    "plt.xlabel(\"top n compounds\")\n",
    "plt.ylabel(\"Mean fraction found\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "    for ts_comp_df in ts_comp:\n",
    "        ax.plot(top_ns, [ts_comp_df.head(n)[col].sum() / n for n in top_ns], label=col, marker=\"o\")\n",
    "ax.set_xlabel(\"top N\")\n",
    "ax.set_ylabel(\"fraction_found\")\n",
    "ax.axhline(1, color=\"k\", linestyle=\"--\", zorder=0)\n",
    "ax.set_title(\"Frac of top N found\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7937e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_enhanced_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c32df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_molecules = 5000  # The top 1% of products\n",
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TS_chem_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
