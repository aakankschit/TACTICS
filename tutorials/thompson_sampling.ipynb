{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae2f6bc",
   "metadata": {},
   "source": [
    "### This tutorial is currently non-operational. When non-legacy code is operational, these tutorials are to be adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec62088",
   "metadata": {},
   "source": [
    "I've split the Notebook in two sections. Thompson Sampling and Results Analysis. \n",
    "\n",
    "The files provided for the input are accessible with:\n",
    "```\n",
    "../examples/docking_scores/{file_name}\n",
    "../examples/input_files/{file_name}\n",
    "```\n",
    "\n",
    "output files should always be placed in (this ensures any file created is not uploaded to the GitHub repo accidently):\n",
    "```\n",
    "./tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5feb3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbcc166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remco/.conda/envs/tactics/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/evaluators.py:16: UserWarning: Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or FredEvaluator\n",
      "  warnings.warn(f\"Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or \"\n"
     ]
    }
   ],
   "source": [
    "# TACTICS Imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "notebook_dir = Path.cwd()\n",
    "src_path = notebook_dir.parent / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "from TACTICS.thompson_sampling import ThompsonSampler\n",
    "from TACTICS.thompson_sampling.config import ThompsonSamplingConfig\n",
    "from TACTICS.thompson_sampling.strategies.config import RouletteWheelConfig\n",
    "from TACTICS.thompson_sampling.warmup.config import StratifiedWarmupConfig\n",
    "from TACTICS.thompson_sampling.core.evaluator_config import LookupEvaluatorConfig\n",
    "from TACTICS.thompson_sampling.presets import get_preset\n",
    "from TACTICS.thompson_sampling.main import run_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c90d0",
   "metadata": {},
   "source": [
    "# TACTICS Fundamentals:\n",
    "The module consists of the a Unified Thompson Sampler that takes as input different configurations. To set up different configurations we can change the parameters of the `ThompsonSamplingConfig`. Every run consists of a configuration input into the `ThompsonSampler` class.\n",
    "\n",
    "### Configurations \n",
    "These are also used for different search and warm up strategies. These are set up using `pydantic` and provide a clear concise way to trouble shoot any issues with parameters that might be input. `pydantic` checks the user's input for each parameter and provides code hints (parameter ranges, types etc.). If the user enters a parameter that is not correct then it automatically provides an error message letting the user know where this is an issue. Its easy to keep track of different runs trough the configurations.\n",
    "\n",
    "### Presets \n",
    "These are pre-configured TS configurations for specific use cases. The user would not need to define the parameters for a given search strategy or warm-up, as this would all be defined with default parameters. All that would be required by the user would be the input files (reagents, reaction SMARTS and evaluator type). For example, the fast exploration configuration uses the Epsilon Greedy configuration with high $\\epsilon$ value for fast exploration.\n",
    "\n",
    "#### Wrapper Functions\n",
    "The package comes with a `run_TS` wrapper function that can be used with existing presets. This allows the user to just input the reaction SMARTS and the input files and the wrapper function will run both the warm-up and search cycles and return a a `polars` data frame of the compiled results. It will also return statistics on the search efficiency as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7848a5f",
   "metadata": {},
   "source": [
    "## Out-of-the-box Demonstration with Presets and Wrapper Function\n",
    "Here I am using the `run_ts` wrapper function that allows the user to user a preset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1dc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset_config = get_preset(\n",
    "    \"fast_exploration\",  # Good for LookupEvaluator (processes=1, batch_size=1)\n",
    "    reaction_smarts=\"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    reagent_file_list=[\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    evaluator_config=LookupEvaluatorConfig(\n",
    "        ref_filename=\"../examples/docking_scores/product_scores.csv\",\n",
    "        ref_colname=\"Scores\"\n",
    "    ),\n",
    "    mode=\"minimize\",      # For docking scores lower scores are better\n",
    "    num_iterations=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac912d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04:10:11:10,708 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:194 5.00e+05 possible products\n",
      "2025-11-04:10:11:10,709 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/main.py:100 Starting warmup phase...\n",
      "2025-11-04:10:11:10,709 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:292 Warmup strategy: StratifiedWarmup, num_trials=3, expected_evaluations=11922\n",
      "2025-11-04:10:11:10,820 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:305 Generated 11915 warmup combinations\n",
      "2025-11-04:10:11:14,769 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:330 Warmup score stats: cnt=11915, mean=-10.7007, std=1.6297, min=-16.8092, max=10.0000\n",
      "2025-11-04:10:11:14,804 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:361 Top score found during warmup: -16.809\n",
      "2025-11-04:10:11:14,814 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/main.py:104 Starting search phase...\n",
      "Search:   0%|          | 0/5000 [00:00<?, ?it/s]2025-11-04:10:11:14,816 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 0: Best score = -13.862\n",
      "Search:   2%|▏         | 89/5000 [00:00<00:05, 885.90it/s]2025-11-04:10:11:14,930 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 100: Best score = -17.016\n",
      "Search:   4%|▎         | 178/5000 [00:00<00:05, 857.13it/s]2025-11-04:10:11:15,50 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 200: Best score = -17.016\n",
      "Search:   5%|▌         | 264/5000 [00:00<00:05, 852.88it/s]2025-11-04:10:11:15,168 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 300: Best score = -17.016\n",
      "Search:   7%|▋         | 350/5000 [00:00<00:05, 844.12it/s]2025-11-04:10:11:15,288 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 400: Best score = -17.016\n",
      "Search:   9%|▊         | 435/5000 [00:00<00:05, 838.81it/s]2025-11-04:10:11:15,408 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 500: Best score = -17.016\n",
      "Search:  10%|█         | 519/5000 [00:00<00:05, 836.15it/s]2025-11-04:10:11:15,528 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 600: Best score = -17.016\n",
      "Search:  14%|█▎        | 687/5000 [00:00<00:05, 833.10it/s]2025-11-04:10:11:15,650 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 700: Best score = -17.248\n",
      "Search:  15%|█▌        | 771/5000 [00:00<00:05, 829.54it/s]2025-11-04:10:11:15,772 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 800: Best score = -17.248\n",
      "Search:  17%|█▋        | 854/5000 [00:01<00:05, 825.82it/s]2025-11-04:10:11:15,894 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 900: Best score = -17.248\n",
      "Search:  19%|█▊        | 937/5000 [00:01<00:04, 823.87it/s]2025-11-04:10:11:16,15 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1000: Best score = -17.248\n",
      "Search:  20%|██        | 1020/5000 [00:01<00:04, 824.99it/s]2025-11-04:10:11:16,135 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1100: Best score = -17.248\n",
      "Search:  24%|██▍       | 1189/5000 [00:01<00:04, 831.58it/s]2025-11-04:10:11:16,255 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1200: Best score = -17.248\n",
      "Search:  25%|██▌       | 1273/5000 [00:01<00:04, 831.70it/s]2025-11-04:10:11:16,375 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1300: Best score = -17.248\n",
      "Search:  27%|██▋       | 1357/5000 [00:01<00:04, 830.65it/s]2025-11-04:10:11:16,495 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1400: Best score = -17.248\n",
      "Search:  29%|██▉       | 1441/5000 [00:01<00:04, 831.51it/s]2025-11-04:10:11:16,617 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1500: Best score = -17.248\n",
      "Search:  30%|███       | 1525/5000 [00:01<00:04, 827.35it/s]2025-11-04:10:11:16,737 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1600: Best score = -17.248\n",
      "Search:  34%|███▍      | 1692/5000 [00:02<00:03, 831.08it/s]2025-11-04:10:11:16,857 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1700: Best score = -17.248\n",
      "Search:  36%|███▌      | 1776/5000 [00:02<00:03, 833.14it/s]2025-11-04:10:11:16,977 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1800: Best score = -17.248\n",
      "Search:  37%|███▋      | 1860/5000 [00:02<00:03, 829.39it/s]2025-11-04:10:11:17,98 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1900: Best score = -17.248\n",
      "Search:  39%|███▉      | 1944/5000 [00:02<00:03, 829.90it/s]2025-11-04:10:11:17,217 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2000: Best score = -17.248\n",
      "Search:  41%|████      | 2029/5000 [00:02<00:03, 833.35it/s]2025-11-04:10:11:17,341 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2100: Best score = -17.248\n",
      "Search:  44%|████▍     | 2197/5000 [00:02<00:03, 823.65it/s]2025-11-04:10:11:17,463 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2200: Best score = -17.248\n",
      "Search:  46%|████▌     | 2280/5000 [00:02<00:03, 821.24it/s]2025-11-04:10:11:17,585 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2300: Best score = -17.248\n",
      "Search:  47%|████▋     | 2363/5000 [00:02<00:03, 822.97it/s]2025-11-04:10:11:17,706 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2400: Best score = -17.248\n",
      "Search:  49%|████▉     | 2446/5000 [00:02<00:03, 824.90it/s]2025-11-04:10:11:17,826 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2500: Best score = -17.248\n",
      "Search:  51%|█████     | 2529/5000 [00:03<00:02, 826.10it/s]2025-11-04:10:11:17,947 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2600: Best score = -17.248\n",
      "Search:  54%|█████▍    | 2696/5000 [00:03<00:02, 826.16it/s]2025-11-04:10:11:18,69 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2700: Best score = -17.248\n",
      "Search:  56%|█████▌    | 2779/5000 [00:03<00:02, 823.08it/s]2025-11-04:10:11:18,191 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2800: Best score = -17.248\n",
      "Search:  57%|█████▋    | 2862/5000 [00:03<00:02, 822.32it/s]2025-11-04:10:11:18,313 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2900: Best score = -17.829\n",
      "Search:  59%|█████▉    | 2945/5000 [00:03<00:02, 821.73it/s]2025-11-04:10:11:18,434 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3000: Best score = -17.829\n",
      "Search:  61%|██████    | 3028/5000 [00:03<00:02, 822.54it/s]2025-11-04:10:11:18,556 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3100: Best score = -17.829\n",
      "Search:  64%|██████▍   | 3195/5000 [00:03<00:02, 824.72it/s]2025-11-04:10:11:18,677 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3200: Best score = -17.829\n",
      "Search:  66%|██████▌   | 3278/5000 [00:03<00:02, 822.22it/s]2025-11-04:10:11:18,800 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3300: Best score = -17.829\n",
      "Search:  67%|██████▋   | 3361/5000 [00:04<00:01, 824.18it/s]2025-11-04:10:11:18,920 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3400: Best score = -17.829\n",
      "Search:  69%|██████▉   | 3444/5000 [00:04<00:01, 819.93it/s]2025-11-04:10:11:19,43 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3500: Best score = -17.829\n",
      "Search:  71%|███████   | 3526/5000 [00:04<00:01, 818.75it/s]2025-11-04:10:11:19,164 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3600: Best score = -17.829\n",
      "Search:  74%|███████▍  | 3694/5000 [00:04<00:01, 826.79it/s]2025-11-04:10:11:19,284 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3700: Best score = -17.829\n",
      "Search:  76%|███████▌  | 3777/5000 [00:04<00:01, 827.48it/s]2025-11-04:10:11:19,405 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3800: Best score = -17.829\n",
      "Search:  77%|███████▋  | 3860/5000 [00:04<00:01, 827.47it/s]2025-11-04:10:11:19,526 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3900: Best score = -17.829\n",
      "Search:  79%|███████▉  | 3943/5000 [00:04<00:01, 822.49it/s]2025-11-04:10:11:19,652 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4000: Best score = -17.829\n",
      "Search:  81%|████████  | 4026/5000 [00:04<00:01, 796.35it/s]2025-11-04:10:11:19,786 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4100: Best score = -17.829\n",
      "Search:  84%|████████▍ | 4189/5000 [00:05<00:01, 632.14it/s]2025-11-04:10:11:20,40 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4200: Best score = -17.829\n",
      "Search:  85%|████████▌ | 4269/5000 [00:05<00:01, 673.26it/s]2025-11-04:10:11:20,165 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4300: Best score = -17.829\n",
      "Search:  87%|████████▋ | 4350/5000 [00:05<00:00, 708.17it/s]2025-11-04:10:11:20,288 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4400: Best score = -17.829\n",
      "Search:  89%|████████▊ | 4431/5000 [00:05<00:00, 733.52it/s]2025-11-04:10:11:20,412 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4500: Best score = -17.829\n",
      "Search:  92%|█████████▏| 4596/5000 [00:05<00:00, 776.50it/s]2025-11-04:10:11:20,534 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4600: Best score = -17.829\n",
      "Search:  94%|█████████▎| 4676/5000 [00:05<00:00, 782.23it/s]2025-11-04:10:11:20,659 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4700: Best score = -17.829\n",
      "Search:  95%|█████████▌| 4757/5000 [00:05<00:00, 789.51it/s]2025-11-04:10:11:20,782 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4800: Best score = -17.829\n",
      "Search:  97%|█████████▋| 4839/5000 [00:06<00:00, 795.63it/s]2025-11-04:10:11:20,906 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4900: Best score = -17.829\n",
      "Search: 100%|██████████| 5000/5000 [00:06<00:00, 804.94it/s]\n",
      "2025-11-04:10:11:21,32 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/main.py:111 16915 evaluations | 3.385% of total\n",
      "2025-11-04:10:11:21,35 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/main.py:117 Saved results to: results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 results (lowest scores):\n",
      "shape: (10, 3)\n",
      "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
      "│ score      ┆ SMILES                          ┆ Name            │\n",
      "│ ---        ┆ ---                             ┆ ---             │\n",
      "│ f64        ┆ str                             ┆ str             │\n",
      "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
      "│ -12.918939 ┆ NC(=O)C1(NC(=O)[C@H](Cc2c[nH]c… ┆ CA128_AA23_AA16 │\n",
      "│ -12.683392 ┆ NC(=O)[C@H](CC1CCCC1)NC(=O)[C@… ┆ CA117_AA45_AA44 │\n",
      "│ -13.985004 ┆ NC(=O)C1(NC(=O)[C@H](Cc2cn(C(c… ┆ CA96_AA57_AA13  │\n",
      "│ -14.237973 ┆ NC(=O)[C@H](Cc1c[nH]c2ccc(O)cc… ┆ CA104_AA22_AA23 │\n",
      "│ -15.539336 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA63_AA28_AA61  │\n",
      "│ -13.607769 ┆ CC(C)[C@H](C(N)=O)N(C)C(=O)[C@… ┆ CA122_AA23_AA8  │\n",
      "│ -13.426668 ┆ NC(=O)[C@H](Cc1ccccc1)NC(=O)[C… ┆ CA117_AA57_AA59 │\n",
      "│ -13.484984 ┆ NC(=O)[C@H](Cc1cn(C(c2ccccc2)(… ┆ CA128_AA28_AA57 │\n",
      "│ -14.538919 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA101_AA28_AA61 │\n",
      "│ -11.68157  ┆ NC(=O)[C@H](Cc1ccc(O)c(Cl)c1)N… ┆ CA11_AA45_AA21  │\n",
      "└────────────┴─────────────────────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# This gives the search results without the warm-up phase\n",
    "results_df = run_ts(preset_config)\n",
    "# If the user wants to see the warm-up results as well, they can use the `return_warmup` argument\n",
    "#results_df = run_ts(preset_config, return_warmup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1003b6",
   "metadata": {},
   "source": [
    "## Demonstrate Thompson Sampling with Nested Configuration\n",
    "This is a \"Do it yourself\" set up, where the user has a lot more control over the parameters that are used to run the Thompson sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d020832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU choose every single component and parameter\n",
    "config = ThompsonSamplingConfig(\n",
    "    reaction_smarts=\"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    reagent_file_list=[\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    num_ts_iterations=5000,\n",
    "    num_warmup_trials=10,\n",
    "    \n",
    "    # Manually configure strategy\n",
    "    strategy_config=RouletteWheelConfig(\n",
    "        mode=\"minimize\",\n",
    "        alpha=0.15,          # You control this\n",
    "        beta=0.12,           # You control this\n",
    "        scaling=2.0,         # You control this\n",
    "        alpha_increment=0.02,\n",
    "        beta_increment=0.003,\n",
    "        efficiency_threshold=0.2\n",
    "    ),\n",
    "    \n",
    "    # Manually configure warmup\n",
    "    warmup_config=StratifiedWarmupConfig(),\n",
    "    \n",
    "    # Manually configure evaluator\n",
    "    evaluator_config=LookupEvaluatorConfig(\n",
    "        ref_filename=\"../examples/docking_scores/product_scores.csv\",\n",
    "        ref_colname=\"Scores\"\n",
    "    ),\n",
    "    \n",
    "    # Manually configure performance\n",
    "    batch_size=1,\n",
    "    processes=1,\n",
    "    min_cpds_per_core=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c32a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04:10:13:57,510 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:194 5.00e+05 possible products\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler initialized with 5.00e+05 possible products\n"
     ]
    }
   ],
   "source": [
    "sampler = ThompsonSampler.from_config(config)\n",
    "\n",
    "# IMPORTANT: Set the reaction (required step)\n",
    "sampler.set_reaction(config.reaction_smarts)\n",
    "print(f\"Sampler initialized with {sampler.get_num_prods():.2e} possible products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af724c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04:10:14:18,6 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:292 Warmup strategy: StratifiedWarmup, num_trials=10, expected_evaluations=39740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting warmup phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04:10:14:18,243 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:305 Generated 39619 warmup combinations\n",
      "2025-11-04:10:14:31,485 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:330 Warmup score stats: cnt=39619, mean=-10.7072, std=1.6372, min=-16.6211, max=10.0000\n",
      "2025-11-04:10:14:31,590 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:361 Top score found during warmup: -16.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup complete: 39619 compounds evaluated\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting warmup phase...\")\n",
    "warmup_results = sampler.warm_up(num_warmup_trials=config.num_warmup_trials)\n",
    "print(f\"Warmup complete: {len(warmup_results)} compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d144531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Thompson Sampling search (5000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Search:   0%|          | 0/5000 [00:00<?, ?it/s]2025-11-04:10:15:09,290 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 0: Best score = -15.330\n",
      "Search:   1%|▏         | 67/5000 [00:00<00:07, 664.43it/s]2025-11-04:10:15:09,437 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 100: Best score = -17.248\n",
      "Search:   3%|▎         | 137/5000 [00:00<00:07, 684.54it/s]2025-11-04:10:15:09,579 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 200: Best score = -17.248\n",
      "Search:   6%|▌         | 279/5000 [00:00<00:06, 698.58it/s]2025-11-04:10:15:09,722 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 300: Best score = -17.248\n",
      "Search:   7%|▋         | 350/5000 [00:00<00:06, 699.38it/s]2025-11-04:10:15:09,864 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 400: Best score = -17.248\n",
      "Search:  10%|▉         | 493/5000 [00:00<00:06, 703.63it/s]2025-11-04:10:15:10,6 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 500: Best score = -17.248\n",
      "Search:  11%|█▏        | 564/5000 [00:00<00:06, 675.06it/s]2025-11-04:10:15:10,166 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 600: Best score = -17.248\n",
      "Search:  13%|█▎        | 632/5000 [00:00<00:06, 671.70it/s]2025-11-04:10:15:10,311 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 700: Best score = -17.248\n",
      "Search:  15%|█▌        | 772/5000 [00:01<00:06, 685.98it/s]2025-11-04:10:15:10,453 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 800: Best score = -17.248\n",
      "Search:  17%|█▋        | 843/5000 [00:01<00:06, 691.28it/s]2025-11-04:10:15:10,595 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 900: Best score = -17.248\n",
      "Search:  20%|█▉        | 984/5000 [00:01<00:05, 695.37it/s]2025-11-04:10:15:10,739 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1000: Best score = -17.248\n",
      "Search:  21%|██        | 1055/5000 [00:01<00:05, 697.02it/s]2025-11-04:10:15:10,881 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1100: Best score = -17.248\n",
      "Search:  24%|██▍       | 1197/5000 [00:01<00:05, 699.48it/s]2025-11-04:10:15:11,24 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1200: Best score = -17.248\n",
      "Search:  25%|██▌       | 1268/5000 [00:01<00:05, 699.88it/s]2025-11-04:10:15:11,167 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1300: Best score = -17.829\n",
      "Search:  27%|██▋       | 1338/5000 [00:01<00:05, 699.48it/s]2025-11-04:10:15:11,308 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1400: Best score = -17.829\n",
      "Search:  30%|██▉       | 1480/5000 [00:02<00:05, 702.33it/s]2025-11-04:10:15:11,452 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1500: Best score = -17.829\n",
      "Search:  31%|███       | 1551/5000 [00:02<00:04, 701.11it/s]2025-11-04:10:15:11,594 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1600: Best score = -17.829\n",
      "Search:  34%|███▍      | 1694/5000 [00:02<00:04, 703.03it/s]2025-11-04:10:15:11,737 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1700: Best score = -17.829\n",
      "Search:  35%|███▌      | 1765/5000 [00:02<00:04, 697.76it/s]2025-11-04:10:15:11,881 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1800: Best score = -17.829\n",
      "Search:  37%|███▋      | 1835/5000 [00:02<00:04, 697.57it/s]2025-11-04:10:15:12,26 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1900: Best score = -17.829\n",
      "Search:  40%|███▉      | 1975/5000 [00:02<00:04, 695.20it/s]2025-11-04:10:15:12,169 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2000: Best score = -17.829\n",
      "Search:  41%|████      | 2045/5000 [00:02<00:04, 695.60it/s]2025-11-04:10:15:12,312 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2100: Best score = -17.829\n",
      "Search:  44%|████▎     | 2186/5000 [00:03<00:04, 697.39it/s]2025-11-04:10:15:12,456 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2200: Best score = -17.829\n",
      "Search:  45%|████▌     | 2256/5000 [00:03<00:03, 697.37it/s]2025-11-04:10:15:12,600 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2300: Best score = -17.829\n",
      "Search:  48%|████▊     | 2397/5000 [00:03<00:03, 697.23it/s]2025-11-04:10:15:12,744 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2400: Best score = -17.829\n",
      "Search:  49%|████▉     | 2467/5000 [00:03<00:03, 695.36it/s]2025-11-04:10:15:12,887 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2500: Best score = -17.829\n",
      "Search:  51%|█████     | 2538/5000 [00:03<00:03, 697.53it/s]2025-11-04:10:15:13,30 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2600: Best score = -17.829\n",
      "Search:  54%|█████▎    | 2679/5000 [00:03<00:03, 697.26it/s]2025-11-04:10:15:13,174 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2700: Best score = -17.829\n",
      "Search:  55%|█████▍    | 2749/5000 [00:03<00:03, 695.36it/s]2025-11-04:10:15:13,318 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2800: Best score = -17.829\n",
      "Search:  58%|█████▊    | 2889/5000 [00:04<00:03, 694.01it/s]2025-11-04:10:15:13,464 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2900: Best score = -17.829\n",
      "Search:  59%|█████▉    | 2959/5000 [00:04<00:02, 692.61it/s]2025-11-04:10:15:13,608 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3000: Best score = -17.829\n",
      "Search:  62%|██████▏   | 3099/5000 [00:04<00:02, 691.80it/s]2025-11-04:10:15:13,754 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3100: Best score = -17.829\n",
      "Search:  63%|██████▎   | 3169/5000 [00:04<00:02, 691.43it/s]2025-11-04:10:15:13,897 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3200: Best score = -17.829\n",
      "Search:  65%|██████▍   | 3239/5000 [00:04<00:02, 693.41it/s]2025-11-04:10:15:14,42 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3300: Best score = -17.829\n",
      "Search:  68%|██████▊   | 3378/5000 [00:04<00:02, 687.68it/s]2025-11-04:10:15:14,190 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3400: Best score = -17.829\n",
      "Search:  69%|██████▉   | 3447/5000 [00:04<00:02, 683.34it/s]2025-11-04:10:15:14,337 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3500: Best score = -17.829\n",
      "Search:  72%|███████▏  | 3586/5000 [00:05<00:02, 685.98it/s]2025-11-04:10:15:14,482 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3600: Best score = -17.829\n",
      "Search:  73%|███████▎  | 3655/5000 [00:05<00:01, 684.87it/s]2025-11-04:10:15:14,628 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3700: Best score = -17.829\n",
      "Search:  76%|███████▌  | 3793/5000 [00:05<00:01, 684.29it/s]2025-11-04:10:15:14,776 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3800: Best score = -17.829\n",
      "Search:  77%|███████▋  | 3862/5000 [00:05<00:01, 683.76it/s]2025-11-04:10:15:14,920 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3900: Best score = -17.829\n",
      "Search:  79%|███████▊  | 3931/5000 [00:05<00:01, 685.24it/s]2025-11-04:10:15:15,66 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4000: Best score = -17.829\n",
      "Search:  81%|████████▏ | 4071/5000 [00:05<00:01, 687.54it/s]2025-11-04:10:15:15,214 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4100: Best score = -17.829\n",
      "Search:  83%|████████▎ | 4140/5000 [00:05<00:01, 672.77it/s]2025-11-04:10:15:15,363 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4200: Best score = -17.829\n",
      "Search:  86%|████████▌ | 4278/5000 [00:06<00:01, 680.20it/s]2025-11-04:10:15:15,509 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4300: Best score = -17.829\n",
      "Search:  87%|████████▋ | 4347/5000 [00:06<00:00, 681.20it/s]2025-11-04:10:15:15,657 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4400: Best score = -17.829\n",
      "Search:  90%|████████▉ | 4486/5000 [00:06<00:00, 683.60it/s]2025-11-04:10:15:15,802 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4500: Best score = -17.829\n",
      "Search:  91%|█████████ | 4555/5000 [00:06<00:00, 682.39it/s]2025-11-04:10:15:15,949 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4600: Best score = -17.829\n",
      "Search:  94%|█████████▍| 4694/5000 [00:06<00:00, 686.19it/s]2025-11-04:10:15:16,94 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4700: Best score = -17.829\n",
      "Search:  95%|█████████▌| 4763/5000 [00:06<00:00, 686.50it/s]2025-11-04:10:15:16,239 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4800: Best score = -17.829\n",
      "Search:  97%|█████████▋| 4832/5000 [00:06<00:00, 685.39it/s]2025-11-04:10:15:16,385 INFO     /home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4900: Best score = -17.829\n",
      "Search: 100%|██████████| 5000/5000 [00:07<00:00, 690.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search complete: 5000 total compounds evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting Thompson Sampling search ({config.num_ts_iterations} iterations)...\")\n",
    "search_results = sampler.search(num_cycles=config.num_ts_iterations)\n",
    "print(f\"Search complete: {len(search_results)} total compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcfc7a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (44_619, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score</th><th>SMILES</th><th>Name</th></tr><tr><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>-12.492468</td><td>&quot;C[C@H](NC(=O)C(NC(=O)c1cc(=O)[…</td><td>&quot;CA0_AA6_AA46&quot;</td></tr><tr><td>-12.484933</td><td>&quot;NC(=O)C1(NC(=O)C[C@H](Cc2ccc(F…</td><td>&quot;CA0_AA10_AA4&quot;</td></tr><tr><td>-10.130123</td><td>&quot;CC(OC(C)(C)C)[C@H](NC(=O)c1cc(…</td><td>&quot;CA0_AA49_AA29&quot;</td></tr><tr><td>-12.542726</td><td>&quot;CC(C)C[C@H](NC(=O)COC[C@H]1CCC…</td><td>&quot;CA0_AA19_AA53&quot;</td></tr><tr><td>-11.144154</td><td>&quot;CCCCC[C@H](NC(=O)c1cc(=O)[nH]c…</td><td>&quot;CA0_AA42_AA10&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-12.947633</td><td>&quot;C=C1CC(C(=O)N2CC3(CC3)C[C@H]2C…</td><td>&quot;CA68_AA32_AA0&quot;</td></tr><tr><td>-15.489283</td><td>&quot;NC(=O)c1ccc(NC(=O)[C@H](Cc2cn(…</td><td>&quot;CA96_AA57_AA36&quot;</td></tr><tr><td>-13.104688</td><td>&quot;CC(=O)N[C@H](CC1CCCCC1)C(=O)N[…</td><td>&quot;CA76_AA28_AA21&quot;</td></tr><tr><td>-12.460681</td><td>&quot;NC(=O)[C@H]1CC[C@@H](NC(=O)CN2…</td><td>&quot;CA122_AA29_AA27&quot;</td></tr><tr><td>-12.005634</td><td>&quot;NC(=O)CN1CCN(C(=O)C2(NC(=O)c3c…</td><td>&quot;CA128_AA4_AA29&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (44_619, 3)\n",
       "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
       "│ score      ┆ SMILES                          ┆ Name            │\n",
       "│ ---        ┆ ---                             ┆ ---             │\n",
       "│ f64        ┆ str                             ┆ str             │\n",
       "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
       "│ -12.492468 ┆ C[C@H](NC(=O)C(NC(=O)c1cc(=O)[… ┆ CA0_AA6_AA46    │\n",
       "│ -12.484933 ┆ NC(=O)C1(NC(=O)C[C@H](Cc2ccc(F… ┆ CA0_AA10_AA4    │\n",
       "│ -10.130123 ┆ CC(OC(C)(C)C)[C@H](NC(=O)c1cc(… ┆ CA0_AA49_AA29   │\n",
       "│ -12.542726 ┆ CC(C)C[C@H](NC(=O)COC[C@H]1CCC… ┆ CA0_AA19_AA53   │\n",
       "│ -11.144154 ┆ CCCCC[C@H](NC(=O)c1cc(=O)[nH]c… ┆ CA0_AA42_AA10   │\n",
       "│ …          ┆ …                               ┆ …               │\n",
       "│ -12.947633 ┆ C=C1CC(C(=O)N2CC3(CC3)C[C@H]2C… ┆ CA68_AA32_AA0   │\n",
       "│ -15.489283 ┆ NC(=O)c1ccc(NC(=O)[C@H](Cc2cn(… ┆ CA96_AA57_AA36  │\n",
       "│ -13.104688 ┆ CC(=O)N[C@H](CC1CCCCC1)C(=O)N[… ┆ CA76_AA28_AA21  │\n",
       "│ -12.460681 ┆ NC(=O)[C@H]1CC[C@@H](NC(=O)CN2… ┆ CA122_AA29_AA27 │\n",
       "│ -12.005634 ┆ NC(=O)CN1CCN(C(=O)C2(NC(=O)c3c… ┆ CA128_AA4_AA29  │\n",
       "└────────────┴─────────────────────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.concat([warmup_results,search_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a16b833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 compounds found:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score</th><th>SMILES</th><th>Name</th></tr><tr><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>-17.828762</td><td>&quot;CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC…</td><td>&quot;CA99_AA28_AA61&quot;</td></tr><tr><td>-17.288765</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA124_AA28_AA61&quot;</td></tr><tr><td>-17.248438</td><td>&quot;COc1cc(C(=O)N[C@H](CC2CCCCC2)C…</td><td>&quot;CA95_AA28_AA61&quot;</td></tr><tr><td>-17.240562</td><td>&quot;CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC…</td><td>&quot;CA116_AA28_AA61&quot;</td></tr><tr><td>-17.236963</td><td>&quot;CC(C)c1ccc(C(=O)N[C@H](CC2CCCC…</td><td>&quot;CA30_AA28_AA61&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-15.927516</td><td>&quot;CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@…</td><td>&quot;CA128_AA28_AA0&quot;</td></tr><tr><td>-15.926538</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA92_AA45_AA61&quot;</td></tr><tr><td>-15.926527</td><td>&quot;CN(C[C@H]1CC[C@H](C(N)=O)CC1)C…</td><td>&quot;CA11_AA23_AA1&quot;</td></tr><tr><td>-15.92254</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA64_AA32_AA61&quot;</td></tr><tr><td>-15.915207</td><td>&quot;C[C@H](NC(=O)c1ccc[nH]1)C(=O)N…</td><td>&quot;CA128_AA46_AA23&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 3)\n",
       "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
       "│ score      ┆ SMILES                          ┆ Name            │\n",
       "│ ---        ┆ ---                             ┆ ---             │\n",
       "│ f64        ┆ str                             ┆ str             │\n",
       "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
       "│ -17.828762 ┆ CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC… ┆ CA99_AA28_AA61  │\n",
       "│ -17.288765 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA124_AA28_AA61 │\n",
       "│ -17.248438 ┆ COc1cc(C(=O)N[C@H](CC2CCCCC2)C… ┆ CA95_AA28_AA61  │\n",
       "│ -17.240562 ┆ CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC… ┆ CA116_AA28_AA61 │\n",
       "│ -17.236963 ┆ CC(C)c1ccc(C(=O)N[C@H](CC2CCCC… ┆ CA30_AA28_AA61  │\n",
       "│ …          ┆ …                               ┆ …               │\n",
       "│ -15.927516 ┆ CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@… ┆ CA128_AA28_AA0  │\n",
       "│ -15.926538 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA92_AA45_AA61  │\n",
       "│ -15.926527 ┆ CN(C[C@H]1CC[C@H](C(N)=O)CC1)C… ┆ CA11_AA23_AA1   │\n",
       "│ -15.92254  ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA64_AA32_AA61  │\n",
       "│ -15.915207 ┆ C[C@H](NC(=O)c1ccc[nH]1)C(=O)N… ┆ CA128_AA46_AA23 │\n",
       "└────────────┴─────────────────────────────────┴─────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine warmup and search results\n",
    "all_results = pl.concat([warmup_results,search_results])\n",
    "\n",
    "# Display top 100 compounds (lowest scores = best for docking)\n",
    "top_100 = all_results.sort(\"score\").head(100)\n",
    "print(\"\\nTop 100 compounds found:\")\n",
    "display(top_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dd77f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./tmp/ts_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Results\n",
    "top_100.write_csv(\"./tmp/ts_results.csv\")\n",
    "print(\"Results saved to ./tmp/ts_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33fdb99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler closed successfully\n"
     ]
    }
   ],
   "source": [
    "# Close the Sampler\n",
    "# Mainly to be used if you want to deploy multi-processing\n",
    "sampler.close()\n",
    "print(\"Sampler closed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ed03f",
   "metadata": {},
   "source": [
    "## Demonstration with a Preset\n",
    "This is an easier method to run TS fast with a set of default parameters. But we are not going to use the wrapper function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70923f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:11:01,503 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:194 5.00e+05 possible products\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler initialized with 5.00e+05 possible products\n"
     ]
    }
   ],
   "source": [
    "sampler_preset = ThompsonSampler.from_config(preset_config)\n",
    "\n",
    "# IMPORTANT: Set the reaction (required step)\n",
    "sampler_preset.set_reaction(preset_config.reaction_smarts)\n",
    "print(f\"Sampler initialized with {sampler_preset.get_num_prods():.2e} possible products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df83c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:11:04,699 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:292 Warmup strategy: StratifiedWarmup, num_trials=3, expected_evaluations=11922\n",
      "2025-11-03:12:11:04,781 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:305 Generated 11906 warmup combinations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting warmup phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:11:07,273 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:330 Warmup score stats: cnt=11906, mean=-10.7135, std=1.6318, min=-16.8092, max=7.0512\n",
      "2025-11-03:12:11:07,294 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:361 Top score found during warmup: -16.809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup complete: 11906 compounds evaluated\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting warmup phase...\")\n",
    "warmup_results_preset = sampler_preset.warm_up(num_warmup_trials=preset_config.num_warmup_trials)\n",
    "print(f\"Warmup complete: {len(warmup_results_preset)} compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Thompson Sampling search (5000 iterations)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e471d8eaee4f428cb4da7eecfd6e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Search:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03:12:11:09,683 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 0: Best score = -13.984\n",
      "2025-11-03:12:11:09,754 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 100: Best score = -17.016\n",
      "2025-11-03:12:11:09,818 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 200: Best score = -17.248\n",
      "2025-11-03:12:11:09,884 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 300: Best score = -17.248\n",
      "2025-11-03:12:11:09,947 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 400: Best score = -17.248\n",
      "2025-11-03:12:11:10,11 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 500: Best score = -17.248\n",
      "2025-11-03:12:11:10,84 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 600: Best score = -17.248\n",
      "2025-11-03:12:11:10,151 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 700: Best score = -17.248\n",
      "2025-11-03:12:11:10,217 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 800: Best score = -17.248\n",
      "2025-11-03:12:11:10,283 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 900: Best score = -17.248\n",
      "2025-11-03:12:11:10,348 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1000: Best score = -17.248\n",
      "2025-11-03:12:11:10,415 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1100: Best score = -17.248\n",
      "2025-11-03:12:11:10,483 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1200: Best score = -17.248\n",
      "2025-11-03:12:11:10,553 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1300: Best score = -17.248\n",
      "2025-11-03:12:11:10,623 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1400: Best score = -17.248\n",
      "2025-11-03:12:11:10,691 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1500: Best score = -17.248\n",
      "2025-11-03:12:11:10,757 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1600: Best score = -17.248\n",
      "2025-11-03:12:11:10,821 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1700: Best score = -17.248\n",
      "2025-11-03:12:11:10,884 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1800: Best score = -17.248\n",
      "2025-11-03:12:11:10,948 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 1900: Best score = -17.248\n",
      "2025-11-03:12:11:11,16 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2000: Best score = -17.248\n",
      "2025-11-03:12:11:11,79 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2100: Best score = -17.248\n",
      "2025-11-03:12:11:11,144 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2200: Best score = -17.248\n",
      "2025-11-03:12:11:11,209 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2300: Best score = -17.248\n",
      "2025-11-03:12:11:11,270 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2400: Best score = -17.829\n",
      "2025-11-03:12:11:11,333 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2500: Best score = -17.829\n",
      "2025-11-03:12:11:11,395 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2600: Best score = -17.829\n",
      "2025-11-03:12:11:11,460 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2700: Best score = -17.829\n",
      "2025-11-03:12:11:11,523 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2800: Best score = -17.829\n",
      "2025-11-03:12:11:11,587 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 2900: Best score = -17.829\n",
      "2025-11-03:12:11:11,651 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3000: Best score = -17.829\n",
      "2025-11-03:12:11:11,715 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3100: Best score = -17.829\n",
      "2025-11-03:12:11:11,778 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3200: Best score = -17.829\n",
      "2025-11-03:12:11:11,842 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3300: Best score = -17.829\n",
      "2025-11-03:12:11:11,903 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3400: Best score = -17.829\n",
      "2025-11-03:12:11:11,966 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3500: Best score = -17.829\n",
      "2025-11-03:12:11:12,30 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3600: Best score = -17.829\n",
      "2025-11-03:12:11:12,91 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3700: Best score = -17.829\n",
      "2025-11-03:12:11:12,156 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3800: Best score = -17.829\n",
      "2025-11-03:12:11:12,221 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 3900: Best score = -17.829\n",
      "2025-11-03:12:11:12,283 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4000: Best score = -17.829\n",
      "2025-11-03:12:11:12,345 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4100: Best score = -17.829\n",
      "2025-11-03:12:11:12,405 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4200: Best score = -17.829\n",
      "2025-11-03:12:11:12,468 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4300: Best score = -17.829\n",
      "2025-11-03:12:11:12,531 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4400: Best score = -17.829\n",
      "2025-11-03:12:11:12,592 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4500: Best score = -17.829\n",
      "2025-11-03:12:11:12,655 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4600: Best score = -17.829\n",
      "2025-11-03:12:11:12,720 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4700: Best score = -17.829\n",
      "2025-11-03:12:11:12,781 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4800: Best score = -17.829\n",
      "2025-11-03:12:11:12,845 INFO     /Users/aakankschitnandkeolyar/Desktop/TACTICS/src/TACTICS/thompson_sampling/core/sampler.py:458 Iteration 4900: Best score = -17.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search complete: 5000 total compounds evaluated\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting Thompson Sampling search ({config.num_ts_iterations} iterations)...\")\n",
    "search_results_preset = sampler_preset.search(num_cycles=preset_config.num_ts_iterations)\n",
    "print(f\"Search complete: {len(search_results_preset)} total compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32e265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 compounds found:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score</th><th>SMILES</th><th>Name</th></tr><tr><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>-17.828762</td><td>&quot;CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC…</td><td>&quot;CA99_AA28_AA61&quot;</td></tr><tr><td>-17.288765</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA124_AA28_AA61&quot;</td></tr><tr><td>-17.248438</td><td>&quot;COc1cc(C(=O)N[C@H](CC2CCCCC2)C…</td><td>&quot;CA95_AA28_AA61&quot;</td></tr><tr><td>-17.240562</td><td>&quot;CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC…</td><td>&quot;CA116_AA28_AA61&quot;</td></tr><tr><td>-17.236963</td><td>&quot;CC(C)c1ccc(C(=O)N[C@H](CC2CCCC…</td><td>&quot;CA30_AA28_AA61&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-15.926538</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA92_AA45_AA61&quot;</td></tr><tr><td>-15.92254</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA64_AA32_AA61&quot;</td></tr><tr><td>-15.910948</td><td>&quot;CC(C)(C)OC(=O)n1cc(C[C@H](NC(=…</td><td>&quot;CA84_AA32_AA61&quot;</td></tr><tr><td>-15.901495</td><td>&quot;CC1(C)Oc2ccc(C[C@H](NC(=O)CNC(…</td><td>&quot;CA0_AA22_AA0&quot;</td></tr><tr><td>-15.901007</td><td>&quot;CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@…</td><td>&quot;CA115_AA28_AA0&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 3)\n",
       "┌────────────┬─────────────────────────────────┬─────────────────┐\n",
       "│ score      ┆ SMILES                          ┆ Name            │\n",
       "│ ---        ┆ ---                             ┆ ---             │\n",
       "│ f64        ┆ str                             ┆ str             │\n",
       "╞════════════╪═════════════════════════════════╪═════════════════╡\n",
       "│ -17.828762 ┆ CC(C)Oc1ccc(C(=O)N[C@H](CC2CCC… ┆ CA99_AA28_AA61  │\n",
       "│ -17.288765 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA124_AA28_AA61 │\n",
       "│ -17.248438 ┆ COc1cc(C(=O)N[C@H](CC2CCCCC2)C… ┆ CA95_AA28_AA61  │\n",
       "│ -17.240562 ┆ CC(=O)Oc1ccc(C(=O)N[C@H](CC2CC… ┆ CA116_AA28_AA61 │\n",
       "│ -17.236963 ┆ CC(C)c1ccc(C(=O)N[C@H](CC2CCCC… ┆ CA30_AA28_AA61  │\n",
       "│ …          ┆ …                               ┆ …               │\n",
       "│ -15.926538 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA92_AA45_AA61  │\n",
       "│ -15.92254  ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA64_AA32_AA61  │\n",
       "│ -15.910948 ┆ CC(C)(C)OC(=O)n1cc(C[C@H](NC(=… ┆ CA84_AA32_AA61  │\n",
       "│ -15.901495 ┆ CC1(C)Oc2ccc(C[C@H](NC(=O)CNC(… ┆ CA0_AA22_AA0    │\n",
       "│ -15.901007 ┆ CC1(C)Oc2ccc(C[C@H](NC(=O)[C@@… ┆ CA115_AA28_AA0  │\n",
       "└────────────┴─────────────────────────────────┴─────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine warmup and search results\n",
    "all_results_preset = pl.concat([warmup_results_preset,search_results_preset])\n",
    "\n",
    "# Display top 100 compounds (lowest scores = best for docking)\n",
    "top_100_preset = all_results_preset.sort(\"score\").head(100)\n",
    "print(\"\\nTop 100 compounds found:\")\n",
    "display(top_100_preset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "results_df_preset.to_csv(\"./tmp/ts_results_preset.csv\", index=False)\n",
    "print(\"Results saved to ./tmp/ts_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f2e3b",
   "metadata": {},
   "source": [
    "# Testing Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673e62c",
   "metadata": {},
   "source": [
    "*TACTICS.thompson_sampling.ts_main does not exist. Tried TACTICS.thompson_sampling.main, but this does not contain parse_input_dict(), so the script breaks after the third code block.*\n",
    "\n",
    "*Using the legacy TACTICS.thompson_sampling.legacy.ts_main also doesn't work as sampler_type is not defined.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remco/.conda/envs/tactics/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/evaluators.py:16: UserWarning: Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or FredEvaluator\n",
      "  warnings.warn(f\"Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or \"\n"
     ]
    }
   ],
   "source": [
    "from TACTICS.thompson_sampling.main import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545da7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_file = \"\"\"{\n",
    "\"reagent_file_list\": [\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    \"reaction_smarts\": \"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    \"num_warmup_trials\": 10,\n",
    "    \"num_ts_iterations\": 5000,\n",
    "    \"search_strategy\": \"greedy_minimize_dt\",\n",
    "    \"processes\": 1,\n",
    "    \"percent_of_library\": 0.1,\n",
    "    \"scaling\": -1,\n",
    "    \"temperature\": 1,\n",
    "    \"evaluator_class_name\": \"LookupEvaluator\",\n",
    "    \"evaluator_arg\": {\"ref_filename\" : \"../examples/docking_scores/product_scores.csv\"},\n",
    "    \"log_filename\": \"./tmp/ts_logs.txt\",\n",
    "    \"results_filename\": \"./tmp/ts_results.csv\"\n",
    "}\"\"\"\n",
    "input_dict = json.loads(input_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea732595",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_input_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mparse_input_dict\u001b[49m(input_dict)\n",
      "\u001b[31mNameError\u001b[39m: name 'parse_input_dict' is not defined"
     ]
    }
   ],
   "source": [
    "parse_input_dict(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff828aa",
   "metadata": {},
   "source": [
    "*_______ Unable to continue further _______*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_std_df = run_ts(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44155171",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_std_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c658e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.sort(\"Scores\", descending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19dd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the TS dataframe so that it is compatible with the get_top_building_blocks function\n",
    "ts_df_mod = ts_std_df.copy()\n",
    "ts_df_mod = ts_df_mod.drop(\"SMILES\",axis=1)\n",
    "ts_df_mod.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "top_5000_building_blocks_ts_df = get_top_building_blocks(ts_df_mod, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overlap between the enriched building blocks from the TS and the top 5000 building blocks from brute force docking\n",
    "overlap_ts = check_overlap(top_5000_building_blocks_ts_df, top_5000_building_blocks)\n",
    "visualize_overlapping_blocks(overlap_ts, combined_smiles_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26100d1",
   "metadata": {},
   "source": [
    "### Check Consistency of the TS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_df_list.append(run_ts(input_dict, hide_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d011bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_std_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_molecules = 5000  # The top 1% of products\n",
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f2c62",
   "metadata": {},
   "source": [
    "## Boltzmann Sampling \n",
    "Utilizes Boltzmann sampling instead of standard greedy sampling to find new compounds to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5de806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "input_dict_boltzmann = copy.copy(input_dict)\n",
    "input_dict_boltzmann[\"search_strategy\"] = \"boltzmann_minimize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_boltzmann_df = run_ts(input_dict_boltzmann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34728219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the TS dataframe so that it is compatible with the get_top_building_blocks function\n",
    "ts_Boltzmann_df_mod = ts_boltzmann_df.copy()\n",
    "ts_Boltzmann_df_mod = ts_Boltzmann_df_mod.drop(\"SMILES\",axis=1)\n",
    "ts_Boltzmann_df_mod.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "top_5000_building_blocks_ts_Boltzmann_df = get_top_building_blocks(ts_Boltzmann_df_mod, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aceed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overlap between the enriched building blocks from the TS and the top 5000 building blocks from brute force docking\n",
    "overlap_ts_Boltzmann = check_overlap(top_5000_building_blocks_ts_Boltzmann_df, top_5000_building_blocks)\n",
    "visualize_overlapping_blocks(overlap_ts_Boltzmann, combined_smiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b23e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 runs of Boltzmann Sampling\n",
    "ts_boltzmann_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_boltzmann_df_list.append(run_ts(input_dict_boltzmann, hide_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff127895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_boltzmann_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effa03b",
   "metadata": {},
   "source": [
    "#### Run these cells to generate the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes \n",
    "docking_df = prod_scores_df.to_pandas() # Convert the polars dataframe to a pandas dataframe\n",
    "docking_df.rename(columns={\"Product_Code\":\"Name\", \"Scores\":\"score\"},inplace=True)\n",
    "docking_df[\"method\"] = \"ref\"\n",
    "docking_df[\"cycle\"] = \"ref\"\n",
    "ref_df = docking_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ef3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the TS dataframes\n",
    "# We can substitute the regular TS with enhanced TS here\n",
    "ts_graph_df_list = []\n",
    "ts_enhanced_df_list_graph = []\n",
    "ts_boltzmann_df_list_graph = []\n",
    "for i in range(0,10):\n",
    "    ts_df_temp = ts_df_list[i].copy()\n",
    "    ts_df_temp[\"cycle\"] = i\n",
    "    ts_df_temp[\"method\"] = \"TS\"\n",
    "    ts_df_temp.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_graph_df_list.append(ts_df_temp)\n",
    "    ts_enhanced_temp_df = ts_enhanced_df_list[i].copy()\n",
    "    ts_enhanced_temp_df[\"cycle\"] = i\n",
    "    ts_enhanced_temp_df[\"method\"] = \"TS_enhanced\"\n",
    "    ts_enhanced_temp_df.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_enhanced_df_list_graph.append(ts_enhanced_temp_df)\n",
    "    ts_boltzmann_temp_df = ts_boltzmann_df_list[i].copy()\n",
    "    ts_boltzmann_temp_df[\"cycle\"] = i\n",
    "    ts_boltzmann_temp_df[\"method\"] = \"TS_Boltzmann\"\n",
    "    ts_boltzmann_temp_df.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_boltzmann_df_list_graph.append(ts_boltzmann_temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6075f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes\n",
    "ts_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_graph_df_list])\n",
    "ts_enhanced_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_enhanced_df_list_graph])\n",
    "ts_boltzmann_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_boltzmann_df_list_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ffd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create concatenated data points only for TS, TS_enhanced and TS_Boltzmann\n",
    "concat_data = pd.DataFrame({\n",
    "    'cycle': ['concat'] * (len(ts_combo_df) + len(ts_enhanced_combo_df) + len(ts_boltzmann_combo_df)),\n",
    "    'score': pd.concat([ts_combo_df['score'], ts_enhanced_combo_df['score'], ts_boltzmann_combo_df['score']]),\n",
    "    'method': pd.concat([ts_combo_df['method'], ts_enhanced_combo_df['method'], ts_boltzmann_combo_df['method']])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8140b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([ts_combo_df, ts_enhanced_combo_df, ts_boltzmann_combo_df, concat_data, ref_df])\n",
    "combined_df.reset_index(drop=True,inplace=True)\n",
    "combined_df.method = pd.Categorical(combined_df.method, categories=[\"ref\",\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a consistent color palette\n",
    "palette_colors = sns.color_palette(\"Set1\")[:4]\n",
    "\n",
    "# Top subplot (stripplot) with concatenated results\n",
    "ax1 = sns.stripplot(data=combined_df, x=\"cycle\", y=\"score\", hue=\"method\", dodge=True, palette=palette_colors)\n",
    "ax1.set_ylabel(\"Score\", fontsize=16)\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the numbers of hits found by each method in each cycle\n",
    "ref_products = ref_df[\"Name\"].to_list()\n",
    "plot_list = []\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS'])\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS_enhanced' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS_enhanced'])\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS_Boltzmann' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS_Boltzmann'])\n",
    "# Get Percentage of hits found by each method in each cycle\n",
    "plot_list.append([\"concat\",len(ts_enhanced_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS_enhanced\"])\n",
    "plot_list.append([\"concat\",len(ts_boltzmann_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS_Boltzmann\"])\n",
    "plot_list.append([\"concat\",len(ts_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS\"])\n",
    "plot_list.append([\"ref\",100,\"ref\"])\n",
    "plot_df = pd.DataFrame(plot_list, columns=[\"cycle\",\"found\",\"method\"])\n",
    "plot_df.method = pd.Categorical(plot_df.method, categories=[\"ref\",\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70444dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check if there is an actual difference between the standard and the enhanced TS\n",
    "from scipy import stats\n",
    "f_stat, p_value = stats.f_oneway(plot_df.loc[plot_df[\"method\"] == \"TS\",\"found\"], \n",
    "                                 plot_df.loc[plot_df[\"method\"] == \"TS_enhanced\",\"found\"], \n",
    "                                 plot_df.loc[plot_df[\"method\"] == \"TS_Boltzmann\",\"found\"])\n",
    "print(f\"F-statistic: {f_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "tukey = pairwise_tukeyhsd(endog=plot_df[\"found\"], groups=plot_df[\"method\"], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"cycle\",y=\"found\",hue=\"method\",data=plot_df, dodge=True)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger figure\n",
    "plt.figure(figsize=(15, 8))  # Increase these numbers to make plot bigger (width, height)\n",
    "\n",
    "# Create the barplot with wider bars\n",
    "ax = sns.barplot(x=\"cycle\", y=\"found\", hue=\"method\", data=plot_df, dodge=True, width=0.8, palette=\"Set1\")  # width controls bar width\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1)\n",
    "\n",
    "# Add value labels manually with larger font size\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                xy=(p.get_x() + p.get_width()/2, p.get_height()),\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=12)  # Increase font size of the numbers\n",
    "\n",
    "# Adjust figure margins\n",
    "plt.subplots_adjust(right=0.85, bottom=0.15)\n",
    "\n",
    "# Optional: Increase font size of axis labels and ticks\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.set_xlabel(ax.get_xlabel(), fontsize=14)\n",
    "ax.set_ylabel(ax.get_ylabel(), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 18), height_ratios=[2, 1])\n",
    "\n",
    "# Define a consistent color palette and category order\n",
    "palette_colors = sns.color_palette(\"Set1\")[:4]\n",
    "method_order = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\", \"ref\"]\n",
    "\n",
    "# Make sure both dataframes have the same category order\n",
    "combined_df.method = pd.Categorical(combined_df.method, categories=method_order, ordered=True)\n",
    "plot_df.method = pd.Categorical(plot_df.method, categories=method_order, ordered=True)\n",
    "\n",
    "# Top subplot (stripplot) with concatenated results\n",
    "sns.stripplot(data=combined_df, x=\"cycle\", y=\"score\", hue=\"method\", dodge=True, palette=palette_colors, ax=ax1)\n",
    "ax1.set_ylabel(\"Docking Score (Negative is Better)\", fontsize=16)\n",
    "ax1.set_xlabel(\"Cycle\", fontsize=16)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# Bottom subplot (barplot)\n",
    "sns.barplot(x=\"cycle\", y=\"found\", hue=\"method\", data=plot_df, dodge=True, width=0.8, palette=palette_colors, ax=ax2)\n",
    "# Remove the bottom legend\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "# Add value labels to bars, only for non-zero values\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:  # Only add label if the value is greater than 0\n",
    "        ax2.annotate(f'{int(height)}', \n",
    "                    xy=(p.get_x() + p.get_width()/2, height),\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=14)\n",
    "\n",
    "# Adjust font sizes for bottom plot\n",
    "ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax2.set_xlabel(\"Cycle\", fontsize=16)\n",
    "ax2.set_ylabel(\"Number of top 100 hits found\", fontsize=16)\n",
    "\n",
    "# Move the legend to the top of the figure and increase its font size\n",
    "legend = ax1.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1, fontsize=14)\n",
    "\n",
    "# Adjust layout with reduced spacing between plots\n",
    "plt.subplots_adjust(right=0.85, hspace=0.125)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ee38d",
   "metadata": {},
   "source": [
    "This can at first look misleading, but the it is important to remember that the more negative the `ChemGauss` score the better it is. Hence, points at the bottom of the plot are better to see than those at the top. The reference presents the best set of molecules as seen from brute-force docking, we see that the Boltzmann sampling does not appear to find most of the hits, hence the Boltzmann sampling is not a useful method to use to find hits for this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9565d9",
   "metadata": {},
   "source": [
    "## Enhanced Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac039a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "input_dict_enhanced_TS = copy.copy(input_dict)\n",
    "input_dict_enhanced_TS[\"search_strategy\"] = \"thermal_cycling\"\n",
    "input_dict_enhanced_TS[\"processes\"] = 1\n",
    "input_dict_enhanced_TS[\"percent_of_library\"] = 0.1\n",
    "input_dict_enhanced_TS[\"scaling\"] = -1\n",
    "input_dict_enhanced_TS[\"temperature\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df = run_ts(input_dict_enhanced_TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b35fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d55c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df = prod_scores_df.sort(\"Scores\", descending=False).head(100).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b97cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc69164",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_ts_enhanced_df = ts_enhanced_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(truth_df[\"Product_Code\"]) & set(top_100_ts_enhanced_df[\"Name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df = ts_enhanced_df.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28618b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df_slice = ts_enhanced_df. sort_values(by=\"Scores\", ascending=True).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4dbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 runs of Boltzmann Sampling\n",
    "ts_enhanced_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_enhanced_df_temp = run_ts(input_dict_enhanced_TS, hide_progress=True)\n",
    "    ts_enhanced_df_temp = ts_enhanced_df_temp.sort_values(by=\"score\", ascending=True).head(5000)\n",
    "    ts_enhanced_df_list.append(ts_enhanced_df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504eabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts_enhanced_df_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc48c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.sort([\"Scores\"], descending=False).head(100)\n",
    "prod_scores_df.head(100).select(pl.col(\"Scores\").min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ade9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.head(100).select(pl.col(\"Scores\").max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59277a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_list[0].sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_boltzmann_df_list[0].sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072cc13",
   "metadata": {},
   "source": [
    "### How much does the Enhanced TS recover using Docking as the Scoring Function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "prod_scores_df_pd = prod_scores_df.to_pandas()\n",
    "top_5k_truth = prod_scores_df_pd.sort_values(by=\"Scores\", ascending=True).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the an Instance of each of the TS methods\n",
    "# Re run this if the the dataframes need to be reset\n",
    "ts_std_df = ts_df_list[0].copy()\n",
    "ts_enhanced_df = ts_enhanced_df_list[0].copy()\n",
    "ts_boltzmann_df = ts_boltzmann_df_list[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01263c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dfs = [ts_std_df, ts_enhanced_df, ts_boltzmann_df]\n",
    "ts_types = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"]\n",
    "top_5k = {}\n",
    "for n, df in enumerate(ts_dfs):\n",
    "    df_temp = df.sort_values(by=\"score\", ascending=True).head(5000)\n",
    "    df_temp.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    df_temp.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "    top_5k[ts_types[n]] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cebee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5k[\"TS\"] = top_5k[\"TS\"][[\"Product_Code\"]].assign(standard=True)\n",
    "top_5k[\"TS_enhanced\"] = top_5k[\"TS_enhanced\"][[\"Product_Code\"]].assign(enhanced=True)\n",
    "top_5k[\"TS_Boltzmann\"] = top_5k[\"TS_Boltzmann\"][[\"Product_Code\"]].assign(boltzmann=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "df_top = pd.merge(pd.merge(pd.merge(top_5k_truth, top_5k[\"TS\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k[\"TS_enhanced\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k[\"TS_Boltzmann\"], how=\"left\", on=\"Product_Code\")\n",
    "df_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef756246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "    ax.plot(top_ns, [df_top.head(n)[col].sum() / n for n in top_ns], label=col, marker=\"o\")\n",
    "ax.set_xlabel(\"top N\")\n",
    "ax.set_ylabel(\"fraction_found\")\n",
    "ax.axhline(1, color=\"k\", linestyle=\"--\", zorder=0)\n",
    "ax.set_title(\"Frac of top N found\")\n",
    "ax.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123b173",
   "metadata": {},
   "source": [
    "It appears that the standard TS slightly underperforms the enhanced TS. The Boltzmann sampling's performance remains poor despite increasing the cutoff for the top n compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested in looking at the plot with error bars\n",
    "# Lets generate these error bars using the cycle data\n",
    "ts_comp = []\n",
    "ts_types = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"] # Types of TS to compare\n",
    "for n in range(0,10):\n",
    "    # Get the top 5000 compounds for each method\n",
    "    # Rename columns\n",
    "    ts_dfs_temp = [ts_df_list[n].copy(), ts_enhanced_df_list[n].copy(), ts_boltzmann_df_list[n].copy()]\n",
    "    ts_dfs_temp = [x.sort_values(by=\"score\", ascending=True).head(5000) for x in ts_dfs_temp]\n",
    "    ts_dfs_temp = [x.drop(columns=[\"SMILES\"]) for x in ts_dfs_temp]\n",
    "    ts_dfs_temp = [x.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"}) for x in ts_dfs_temp]\n",
    "    top_5k_temp = {}\n",
    "    for n, ts_type in enumerate(ts_types):\n",
    "        top_5k_temp[ts_type] = ts_dfs_temp[n] # Assign the appropriate dataframe to the dictionary\n",
    "        if n == 0: # Standard TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(standard=True)\n",
    "        elif n == 1: # Enhanced TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(enhanced=True)\n",
    "        else: # Boltzmann TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(boltzmann=True)\n",
    "    # Merge the dataframes\n",
    "    df_top = pd.merge(pd.merge(pd.merge(top_5k_truth, top_5k_temp[\"TS\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k_temp[\"TS_enhanced\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k_temp[\"TS_Boltzmann\"], how=\"left\", on=\"Product_Code\")\n",
    "    # Calculate the fraction of hits found for each method\n",
    "    ts_comp.append(df_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "top_ns_frac = pd.DataFrame(columns=[\"cycle\",\"top_n\", \"method\", \"frac_top_n\"])\n",
    "for cycle_id, ts_comp_df in enumerate(ts_comp):\n",
    "    for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "        for n in top_ns:\n",
    "            frac_top_ns = ts_comp_df.head(n)[col].sum() / n\n",
    "            row = {\"cycle\":cycle_id, \"top_n\":n, \"method\":col, \"frac_top_n\":frac_top_ns}\n",
    "            top_ns_frac = pd.concat([top_ns_frac, pd.DataFrame([row])], ignore_index=True)\n",
    "top_ns_frac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bab875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with mean, std and count of frac_top_n for each top_n and method\n",
    "grouped_stats = top_ns_frac.groupby(['top_n', 'method'])['frac_top_n'].agg(\n",
    "    mean='mean',\n",
    "    std='std',\n",
    "    count='count'\n",
    ").reset_index()\n",
    "\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6)) # set the size of the plot\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"tab10\", font_scale=1.2)\n",
    "\n",
    "# Ensure sub_category is sortable (e.g., categorical or ordered)\n",
    "grouped_stats['top_n'] = grouped_stats['top_n'].astype(str)\n",
    "\n",
    "# Line plot per category with error bars\n",
    "sns.lineplot(\n",
    "    data=grouped_stats,\n",
    "    x='top_n',\n",
    "    y='mean',\n",
    "    hue='method',  # color line by category\n",
    "    marker='o',\n",
    "    errorbar=None,\n",
    "    linewidth=2.5  # Disable built-in CI\n",
    ")\n",
    "\n",
    "# Add error bars manually using plt.errorbar\n",
    "for _, row in grouped_stats.iterrows():\n",
    "    if pd.notnull(row['std']):\n",
    "        plt.errorbar(\n",
    "            x=row['top_n'],\n",
    "            y=row['mean'],\n",
    "            yerr=row['std'],\n",
    "            fmt='none',\n",
    "            capsize=4,\n",
    "            ecolor='gray'\n",
    "        )\n",
    "\n",
    "plt.title(\"Mean top N fraction found for each method across 10 cycles\")\n",
    "plt.xlabel(\"top n compounds\")\n",
    "plt.ylabel(\"Mean fraction found\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "    for ts_comp_df in ts_comp:\n",
    "        ax.plot(top_ns, [ts_comp_df.head(n)[col].sum() / n for n in top_ns], label=col, marker=\"o\")\n",
    "ax.set_xlabel(\"top N\")\n",
    "ax.set_ylabel(\"fraction_found\")\n",
    "ax.axhline(1, color=\"k\", linestyle=\"--\", zorder=0)\n",
    "ax.set_title(\"Frac of top N found\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7937e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_enhanced_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c32df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_molecules = 5000  # The top 1% of products\n",
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tactics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
