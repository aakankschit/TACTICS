{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae2f6bc",
   "metadata": {},
   "source": [
    "# !!! Non-operational !!!\n",
    "\n",
    "### This tutorial is currently non-operational. When non-legacy code is operational, these tutorials are to be adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec62088",
   "metadata": {},
   "source": [
    "I've split the Notebook in two sections. Thompson Sampling and Results Analysis. \n",
    "\n",
    "The files provided for the input are accessible with:\n",
    "```\n",
    "../examples/docking_scores/{file_name}\n",
    "../examples/input_files/{file_name}\n",
    "```\n",
    "\n",
    "output files should always be placed in (this ensures any file created is not uploaded to the GitHub repo accidently):\n",
    "```\n",
    "./tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a64ff4",
   "metadata": {},
   "source": [
    "I've tried going through the notebook using the data provided, but encountered issues as legacy code seems to be used to run these scripts. I've had a look, but as I don't know the changes from Legacy to Current, I'm unable to fix these issues. \n",
    "\n",
    "I've added comments in *italics*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f2e3b",
   "metadata": {},
   "source": [
    "# Testing Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673e62c",
   "metadata": {},
   "source": [
    "*TACTICS.thompson_sampling.ts_main does not exist. Tried TACTICS.thompson_sampling.main, but this does not contain parse_input_dict(), so the script breaks after the third code block.*\n",
    "\n",
    "*Using the legacy TACTICS.thompson_sampling.legacy.ts_main also doesn't work as sampler_type is not defined.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a7c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remco/.conda/envs/tactics/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/evaluators.py:16: UserWarning: Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or FredEvaluator\n",
      "  warnings.warn(f\"Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or \"\n"
     ]
    }
   ],
   "source": [
    "from TACTICS.thompson_sampling.main import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545da7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_file = \"\"\"{\n",
    "\"reagent_file_list\": [\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    \"reaction_smarts\": \"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    \"num_warmup_trials\": 10,\n",
    "    \"num_ts_iterations\": 5000,\n",
    "    \"search_strategy\": \"greedy_minimize_dt\",\n",
    "    \"processes\": 1,\n",
    "    \"percent_of_library\": 0.1,\n",
    "    \"scaling\": -1,\n",
    "    \"temperature\": 1,\n",
    "    \"evaluator_class_name\": \"LookupEvaluator\",\n",
    "    \"evaluator_arg\": {\"ref_filename\" : \"../examples/docking_scores/product_scores.csv\"},\n",
    "    \"log_filename\": \"./tmp/ts_logs.txt\",\n",
    "    \"results_filename\": \"./tmp/ts_results.csv\"\n",
    "}\"\"\"\n",
    "input_dict = json.loads(input_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea732595",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_input_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mparse_input_dict\u001b[49m(input_dict)\n",
      "\u001b[31mNameError\u001b[39m: name 'parse_input_dict' is not defined"
     ]
    }
   ],
   "source": [
    "parse_input_dict(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff828aa",
   "metadata": {},
   "source": [
    "*_______ Unable to continue further _______*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_std_df = run_ts(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44155171",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_std_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c658e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.sort(\"Scores\", descending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19dd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the TS dataframe so that it is compatible with the get_top_building_blocks function\n",
    "ts_df_mod = ts_std_df.copy()\n",
    "ts_df_mod = ts_df_mod.drop(\"SMILES\",axis=1)\n",
    "ts_df_mod.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "top_5000_building_blocks_ts_df = get_top_building_blocks(ts_df_mod, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overlap between the enriched building blocks from the TS and the top 5000 building blocks from brute force docking\n",
    "overlap_ts = check_overlap(top_5000_building_blocks_ts_df, top_5000_building_blocks)\n",
    "visualize_overlapping_blocks(overlap_ts, combined_smiles_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26100d1",
   "metadata": {},
   "source": [
    "### Check Consistency of the TS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_df_list.append(run_ts(input_dict, hide_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d011bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_std_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_molecules = 5000  # The top 1% of products\n",
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f2c62",
   "metadata": {},
   "source": [
    "## Boltzmann Sampling \n",
    "Utilizes Boltzmann sampling instead of standard greedy sampling to find new compounds to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5de806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "input_dict_boltzmann = copy.copy(input_dict)\n",
    "input_dict_boltzmann[\"search_strategy\"] = \"boltzmann_minimize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_boltzmann_df = run_ts(input_dict_boltzmann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34728219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the TS dataframe so that it is compatible with the get_top_building_blocks function\n",
    "ts_Boltzmann_df_mod = ts_boltzmann_df.copy()\n",
    "ts_Boltzmann_df_mod = ts_Boltzmann_df_mod.drop(\"SMILES\",axis=1)\n",
    "ts_Boltzmann_df_mod.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "top_5000_building_blocks_ts_Boltzmann_df = get_top_building_blocks(ts_Boltzmann_df_mod, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aceed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overlap between the enriched building blocks from the TS and the top 5000 building blocks from brute force docking\n",
    "overlap_ts_Boltzmann = check_overlap(top_5000_building_blocks_ts_Boltzmann_df, top_5000_building_blocks)\n",
    "visualize_overlapping_blocks(overlap_ts_Boltzmann, combined_smiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b23e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 runs of Boltzmann Sampling\n",
    "ts_boltzmann_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_boltzmann_df_list.append(run_ts(input_dict_boltzmann, hide_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff127895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_boltzmann_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effa03b",
   "metadata": {},
   "source": [
    "#### Run these cells to generate the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes \n",
    "docking_df = prod_scores_df.to_pandas() # Convert the polars dataframe to a pandas dataframe\n",
    "docking_df.rename(columns={\"Product_Code\":\"Name\", \"Scores\":\"score\"},inplace=True)\n",
    "docking_df[\"method\"] = \"ref\"\n",
    "docking_df[\"cycle\"] = \"ref\"\n",
    "ref_df = docking_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ef3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the TS dataframes\n",
    "# We can substitute the regular TS with enhanced TS here\n",
    "ts_graph_df_list = []\n",
    "ts_enhanced_df_list_graph = []\n",
    "ts_boltzmann_df_list_graph = []\n",
    "for i in range(0,10):\n",
    "    ts_df_temp = ts_df_list[i].copy()\n",
    "    ts_df_temp[\"cycle\"] = i\n",
    "    ts_df_temp[\"method\"] = \"TS\"\n",
    "    ts_df_temp.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_graph_df_list.append(ts_df_temp)\n",
    "    ts_enhanced_temp_df = ts_enhanced_df_list[i].copy()\n",
    "    ts_enhanced_temp_df[\"cycle\"] = i\n",
    "    ts_enhanced_temp_df[\"method\"] = \"TS_enhanced\"\n",
    "    ts_enhanced_temp_df.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_enhanced_df_list_graph.append(ts_enhanced_temp_df)\n",
    "    ts_boltzmann_temp_df = ts_boltzmann_df_list[i].copy()\n",
    "    ts_boltzmann_temp_df[\"cycle\"] = i\n",
    "    ts_boltzmann_temp_df[\"method\"] = \"TS_Boltzmann\"\n",
    "    ts_boltzmann_temp_df.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_boltzmann_df_list_graph.append(ts_boltzmann_temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6075f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes\n",
    "ts_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_graph_df_list])\n",
    "ts_enhanced_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_enhanced_df_list_graph])\n",
    "ts_boltzmann_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_boltzmann_df_list_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ffd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create concatenated data points only for TS, TS_enhanced and TS_Boltzmann\n",
    "concat_data = pd.DataFrame({\n",
    "    'cycle': ['concat'] * (len(ts_combo_df) + len(ts_enhanced_combo_df) + len(ts_boltzmann_combo_df)),\n",
    "    'score': pd.concat([ts_combo_df['score'], ts_enhanced_combo_df['score'], ts_boltzmann_combo_df['score']]),\n",
    "    'method': pd.concat([ts_combo_df['method'], ts_enhanced_combo_df['method'], ts_boltzmann_combo_df['method']])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8140b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([ts_combo_df, ts_enhanced_combo_df, ts_boltzmann_combo_df, concat_data, ref_df])\n",
    "combined_df.reset_index(drop=True,inplace=True)\n",
    "combined_df.method = pd.Categorical(combined_df.method, categories=[\"ref\",\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a consistent color palette\n",
    "palette_colors = sns.color_palette(\"Set1\")[:4]\n",
    "\n",
    "# Top subplot (stripplot) with concatenated results\n",
    "ax1 = sns.stripplot(data=combined_df, x=\"cycle\", y=\"score\", hue=\"method\", dodge=True, palette=palette_colors)\n",
    "ax1.set_ylabel(\"Score\", fontsize=16)\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the numbers of hits found by each method in each cycle\n",
    "ref_products = ref_df[\"Name\"].to_list()\n",
    "plot_list = []\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS'])\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS_enhanced' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS_enhanced'])\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS_Boltzmann' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS_Boltzmann'])\n",
    "# Get Percentage of hits found by each method in each cycle\n",
    "plot_list.append([\"concat\",len(ts_enhanced_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS_enhanced\"])\n",
    "plot_list.append([\"concat\",len(ts_boltzmann_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS_Boltzmann\"])\n",
    "plot_list.append([\"concat\",len(ts_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS\"])\n",
    "plot_list.append([\"ref\",100,\"ref\"])\n",
    "plot_df = pd.DataFrame(plot_list, columns=[\"cycle\",\"found\",\"method\"])\n",
    "plot_df.method = pd.Categorical(plot_df.method, categories=[\"ref\",\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70444dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check if there is an actual difference between the standard and the enhanced TS\n",
    "from scipy import stats\n",
    "f_stat, p_value = stats.f_oneway(plot_df.loc[plot_df[\"method\"] == \"TS\",\"found\"], \n",
    "                                 plot_df.loc[plot_df[\"method\"] == \"TS_enhanced\",\"found\"], \n",
    "                                 plot_df.loc[plot_df[\"method\"] == \"TS_Boltzmann\",\"found\"])\n",
    "print(f\"F-statistic: {f_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "tukey = pairwise_tukeyhsd(endog=plot_df[\"found\"], groups=plot_df[\"method\"], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"cycle\",y=\"found\",hue=\"method\",data=plot_df, dodge=True)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger figure\n",
    "plt.figure(figsize=(15, 8))  # Increase these numbers to make plot bigger (width, height)\n",
    "\n",
    "# Create the barplot with wider bars\n",
    "ax = sns.barplot(x=\"cycle\", y=\"found\", hue=\"method\", data=plot_df, dodge=True, width=0.8, palette=\"Set1\")  # width controls bar width\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1)\n",
    "\n",
    "# Add value labels manually with larger font size\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                xy=(p.get_x() + p.get_width()/2, p.get_height()),\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=12)  # Increase font size of the numbers\n",
    "\n",
    "# Adjust figure margins\n",
    "plt.subplots_adjust(right=0.85, bottom=0.15)\n",
    "\n",
    "# Optional: Increase font size of axis labels and ticks\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.set_xlabel(ax.get_xlabel(), fontsize=14)\n",
    "ax.set_ylabel(ax.get_ylabel(), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 18), height_ratios=[2, 1])\n",
    "\n",
    "# Define a consistent color palette and category order\n",
    "palette_colors = sns.color_palette(\"Set1\")[:4]\n",
    "method_order = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\", \"ref\"]\n",
    "\n",
    "# Make sure both dataframes have the same category order\n",
    "combined_df.method = pd.Categorical(combined_df.method, categories=method_order, ordered=True)\n",
    "plot_df.method = pd.Categorical(plot_df.method, categories=method_order, ordered=True)\n",
    "\n",
    "# Top subplot (stripplot) with concatenated results\n",
    "sns.stripplot(data=combined_df, x=\"cycle\", y=\"score\", hue=\"method\", dodge=True, palette=palette_colors, ax=ax1)\n",
    "ax1.set_ylabel(\"Docking Score (Negative is Better)\", fontsize=16)\n",
    "ax1.set_xlabel(\"Cycle\", fontsize=16)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# Bottom subplot (barplot)\n",
    "sns.barplot(x=\"cycle\", y=\"found\", hue=\"method\", data=plot_df, dodge=True, width=0.8, palette=palette_colors, ax=ax2)\n",
    "# Remove the bottom legend\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "# Add value labels to bars, only for non-zero values\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:  # Only add label if the value is greater than 0\n",
    "        ax2.annotate(f'{int(height)}', \n",
    "                    xy=(p.get_x() + p.get_width()/2, height),\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=14)\n",
    "\n",
    "# Adjust font sizes for bottom plot\n",
    "ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax2.set_xlabel(\"Cycle\", fontsize=16)\n",
    "ax2.set_ylabel(\"Number of top 100 hits found\", fontsize=16)\n",
    "\n",
    "# Move the legend to the top of the figure and increase its font size\n",
    "legend = ax1.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1, fontsize=14)\n",
    "\n",
    "# Adjust layout with reduced spacing between plots\n",
    "plt.subplots_adjust(right=0.85, hspace=0.125)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ee38d",
   "metadata": {},
   "source": [
    "This can at first look misleading, but the it is important to remember that the more negative the `ChemGauss` score the better it is. Hence, points at the bottom of the plot are better to see than those at the top. The reference presents the best set of molecules as seen from brute-force docking, we see that the Boltzmann sampling does not appear to find most of the hits, hence the Boltzmann sampling is not a useful method to use to find hits for this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9565d9",
   "metadata": {},
   "source": [
    "## Enhanced Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac039a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "input_dict_enhanced_TS = copy.copy(input_dict)\n",
    "input_dict_enhanced_TS[\"search_strategy\"] = \"thermal_cycling\"\n",
    "input_dict_enhanced_TS[\"processes\"] = 1\n",
    "input_dict_enhanced_TS[\"percent_of_library\"] = 0.1\n",
    "input_dict_enhanced_TS[\"scaling\"] = -1\n",
    "input_dict_enhanced_TS[\"temperature\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df = run_ts(input_dict_enhanced_TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b35fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d55c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df = prod_scores_df.sort(\"Scores\", descending=False).head(100).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b97cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc69164",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_ts_enhanced_df = ts_enhanced_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(truth_df[\"Product_Code\"]) & set(top_100_ts_enhanced_df[\"Name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df = ts_enhanced_df.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28618b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df_slice = ts_enhanced_df. sort_values(by=\"Scores\", ascending=True).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4dbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 runs of Boltzmann Sampling\n",
    "ts_enhanced_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_enhanced_df_temp = run_ts(input_dict_enhanced_TS, hide_progress=True)\n",
    "    ts_enhanced_df_temp = ts_enhanced_df_temp.sort_values(by=\"score\", ascending=True).head(5000)\n",
    "    ts_enhanced_df_list.append(ts_enhanced_df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504eabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts_enhanced_df_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc48c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.sort([\"Scores\"], descending=False).head(100)\n",
    "prod_scores_df.head(100).select(pl.col(\"Scores\").min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ade9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.head(100).select(pl.col(\"Scores\").max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59277a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_list[0].sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_boltzmann_df_list[0].sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072cc13",
   "metadata": {},
   "source": [
    "### How much does the Enhanced TS recover using Docking as the Scoring Function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "prod_scores_df_pd = prod_scores_df.to_pandas()\n",
    "top_5k_truth = prod_scores_df_pd.sort_values(by=\"Scores\", ascending=True).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the an Instance of each of the TS methods\n",
    "# Re run this if the the dataframes need to be reset\n",
    "ts_std_df = ts_df_list[0].copy()\n",
    "ts_enhanced_df = ts_enhanced_df_list[0].copy()\n",
    "ts_boltzmann_df = ts_boltzmann_df_list[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01263c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dfs = [ts_std_df, ts_enhanced_df, ts_boltzmann_df]\n",
    "ts_types = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"]\n",
    "top_5k = {}\n",
    "for n, df in enumerate(ts_dfs):\n",
    "    df_temp = df.sort_values(by=\"score\", ascending=True).head(5000)\n",
    "    df_temp.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    df_temp.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "    top_5k[ts_types[n]] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cebee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5k[\"TS\"] = top_5k[\"TS\"][[\"Product_Code\"]].assign(standard=True)\n",
    "top_5k[\"TS_enhanced\"] = top_5k[\"TS_enhanced\"][[\"Product_Code\"]].assign(enhanced=True)\n",
    "top_5k[\"TS_Boltzmann\"] = top_5k[\"TS_Boltzmann\"][[\"Product_Code\"]].assign(boltzmann=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "df_top = pd.merge(pd.merge(pd.merge(top_5k_truth, top_5k[\"TS\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k[\"TS_enhanced\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k[\"TS_Boltzmann\"], how=\"left\", on=\"Product_Code\")\n",
    "df_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef756246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "    ax.plot(top_ns, [df_top.head(n)[col].sum() / n for n in top_ns], label=col, marker=\"o\")\n",
    "ax.set_xlabel(\"top N\")\n",
    "ax.set_ylabel(\"fraction_found\")\n",
    "ax.axhline(1, color=\"k\", linestyle=\"--\", zorder=0)\n",
    "ax.set_title(\"Frac of top N found\")\n",
    "ax.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123b173",
   "metadata": {},
   "source": [
    "It appears that the standard TS slightly underperforms the enhanced TS. The Boltzmann sampling's performance remains poor despite increasing the cutoff for the top n compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested in looking at the plot with error bars\n",
    "# Lets generate these error bars using the cycle data\n",
    "ts_comp = []\n",
    "ts_types = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"] # Types of TS to compare\n",
    "for n in range(0,10):\n",
    "    # Get the top 5000 compounds for each method\n",
    "    # Rename columns\n",
    "    ts_dfs_temp = [ts_df_list[n].copy(), ts_enhanced_df_list[n].copy(), ts_boltzmann_df_list[n].copy()]\n",
    "    ts_dfs_temp = [x.sort_values(by=\"score\", ascending=True).head(5000) for x in ts_dfs_temp]\n",
    "    ts_dfs_temp = [x.drop(columns=[\"SMILES\"]) for x in ts_dfs_temp]\n",
    "    ts_dfs_temp = [x.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"}) for x in ts_dfs_temp]\n",
    "    top_5k_temp = {}\n",
    "    for n, ts_type in enumerate(ts_types):\n",
    "        top_5k_temp[ts_type] = ts_dfs_temp[n] # Assign the appropriate dataframe to the dictionary\n",
    "        if n == 0: # Standard TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(standard=True)\n",
    "        elif n == 1: # Enhanced TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(enhanced=True)\n",
    "        else: # Boltzmann TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(boltzmann=True)\n",
    "    # Merge the dataframes\n",
    "    df_top = pd.merge(pd.merge(pd.merge(top_5k_truth, top_5k_temp[\"TS\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k_temp[\"TS_enhanced\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k_temp[\"TS_Boltzmann\"], how=\"left\", on=\"Product_Code\")\n",
    "    # Calculate the fraction of hits found for each method\n",
    "    ts_comp.append(df_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "top_ns_frac = pd.DataFrame(columns=[\"cycle\",\"top_n\", \"method\", \"frac_top_n\"])\n",
    "for cycle_id, ts_comp_df in enumerate(ts_comp):\n",
    "    for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "        for n in top_ns:\n",
    "            frac_top_ns = ts_comp_df.head(n)[col].sum() / n\n",
    "            row = {\"cycle\":cycle_id, \"top_n\":n, \"method\":col, \"frac_top_n\":frac_top_ns}\n",
    "            top_ns_frac = pd.concat([top_ns_frac, pd.DataFrame([row])], ignore_index=True)\n",
    "top_ns_frac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bab875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with mean, std and count of frac_top_n for each top_n and method\n",
    "grouped_stats = top_ns_frac.groupby(['top_n', 'method'])['frac_top_n'].agg(\n",
    "    mean='mean',\n",
    "    std='std',\n",
    "    count='count'\n",
    ").reset_index()\n",
    "\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6)) # set the size of the plot\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"tab10\", font_scale=1.2)\n",
    "\n",
    "# Ensure sub_category is sortable (e.g., categorical or ordered)\n",
    "grouped_stats['top_n'] = grouped_stats['top_n'].astype(str)\n",
    "\n",
    "# Line plot per category with error bars\n",
    "sns.lineplot(\n",
    "    data=grouped_stats,\n",
    "    x='top_n',\n",
    "    y='mean',\n",
    "    hue='method',  # color line by category\n",
    "    marker='o',\n",
    "    errorbar=None,\n",
    "    linewidth=2.5  # Disable built-in CI\n",
    ")\n",
    "\n",
    "# Add error bars manually using plt.errorbar\n",
    "for _, row in grouped_stats.iterrows():\n",
    "    if pd.notnull(row['std']):\n",
    "        plt.errorbar(\n",
    "            x=row['top_n'],\n",
    "            y=row['mean'],\n",
    "            yerr=row['std'],\n",
    "            fmt='none',\n",
    "            capsize=4,\n",
    "            ecolor='gray'\n",
    "        )\n",
    "\n",
    "plt.title(\"Mean top N fraction found for each method across 10 cycles\")\n",
    "plt.xlabel(\"top n compounds\")\n",
    "plt.ylabel(\"Mean fraction found\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "    for ts_comp_df in ts_comp:\n",
    "        ax.plot(top_ns, [ts_comp_df.head(n)[col].sum() / n for n in top_ns], label=col, marker=\"o\")\n",
    "ax.set_xlabel(\"top N\")\n",
    "ax.set_ylabel(\"fraction_found\")\n",
    "ax.axhline(1, color=\"k\", linestyle=\"--\", zorder=0)\n",
    "ax.set_title(\"Frac of top N found\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7937e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_enhanced_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c32df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_molecules = 5000  # The top 1% of products\n",
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tactics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
