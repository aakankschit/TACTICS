{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae2f6bc",
   "metadata": {},
   "source": [
    "### This tutorial is currently non-operational. When non-legacy code is operational, these tutorials are to be adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec62088",
   "metadata": {},
   "source": [
    "I've split the Notebook in two sections. Thompson Sampling and Results Analysis. \n",
    "\n",
    "The files provided for the input are accessible with:\n",
    "```\n",
    "../examples/docking_scores/{file_name}\n",
    "../examples/input_files/{file_name}\n",
    "```\n",
    "\n",
    "output files should always be placed in (this ensures any file created is not uploaded to the GitHub repo accidently):\n",
    "```\n",
    "./tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TACTICS Imports\n",
    "from TACTICS.thompson_sampling import ThompsonSampler\n",
    "from TACTICS.thompson_sampling.config import ThompsonSamplingConfig\n",
    "from TACTICS.thompson_sampling.strategies.config import RouletteWheelConfig\n",
    "from TACTICS.thompson_sampling.warmup.config import StratifiedWarmupConfig\n",
    "from TACTICS.thompson_sampling.core.evaluator_config import LookupEvaluatorConfig\n",
    "from TACTICS.thompson_sampling.presets import get_preset\n",
    "from TACTICS.thompson_sampling.main import run_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58192ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"./tmp\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c90d0",
   "metadata": {},
   "source": [
    "# TACTICS Fundamentals:\n",
    "The module consists of the a Unified Thompson Sampler that takes as input different configurations. To set up different configurations we can change the parameters of the `ThompsonSamplingConfig`. Every run consists of a configuration input into the `ThompsonSampler` class.\n",
    "\n",
    "### Configurations \n",
    "These are also used for different search and warm up strategies. These are set up using `pydantic` and provide a clear concise way to trouble shoot any issues with parameters that might be input. `pydantic` checks the user's input for each parameter and provides code hints (parameter ranges, types etc.). If the user enters a parameter that is not correct then it automatically provides an error message letting the user know where this is an issue. Its easy to keep track of different runs trough the configurations.\n",
    "\n",
    "### Presets \n",
    "These are pre-configured TS configurations for specific use cases. The user would not need to define the parameters for a given search strategy or warm-up, as this would all be defined with default parameters. All that would be required by the user would be the input files (reagents, reaction SMARTS and evaluator type). For example, the fast exploration configuration uses the Epsilon Greedy configuration with high $\\epsilon$ value for fast exploration.\n",
    "\n",
    "#### Wrapper Functions\n",
    "The package comes with a `run_TS` wrapper function that can be used with existing presets. This allows the user to just input the reaction SMARTS and the input files and the wrapper function will run both the warm-up and search cycles and return a a `polars` data frame of the compiled results. It will also return statistics on the search efficiency as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7848a5f",
   "metadata": {},
   "source": [
    "## Out-of-the-box Demonstration with Presets and Wrapper Function\n",
    "Here I am using the `run_ts` wrapper function that allows the user to user a preset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1dc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset_config = get_preset(\n",
    "    \"fast_exploration\",  # Good for LookupEvaluator (processes=1, batch_size=1)\n",
    "    reaction_smarts=\"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    reagent_file_list=[\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    evaluator_config=LookupEvaluatorConfig(\n",
    "        ref_filename=\"../examples/docking_scores/product_scores.csv\",\n",
    "        ref_colname=\"Scores\"\n",
    "    ),\n",
    "    mode=\"minimize\",      # For docking scores lower scores are better\n",
    "    num_iterations=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac912d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives the search results without the warm-up phase\n",
    "results_df = run_ts(preset_config)\n",
    "# If the user wants to see the warm-up results as well, they can use the `return_warmup` argument\n",
    "#results_df = run_ts(preset_config, return_warmup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1003b6",
   "metadata": {},
   "source": [
    "## Demonstrate Thompson Sampling with Nested Configuration\n",
    "This is a \"Do it yourself\" set up, where the user has a lot more control over the parameters that are used to run the Thompson sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d020832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU choose every single component and parameter\n",
    "config = ThompsonSamplingConfig(\n",
    "    reaction_smarts=\"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    reagent_file_list=[\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    num_ts_iterations=5000,\n",
    "    num_warmup_trials=10,\n",
    "    \n",
    "    # Manually configure strategy\n",
    "    strategy_config=RouletteWheelConfig(\n",
    "        mode=\"minimize\",\n",
    "        alpha=0.15,          # You control this\n",
    "        beta=0.12,           # You control this\n",
    "        scaling=2.0,         # You control this\n",
    "        alpha_increment=0.02,\n",
    "        beta_increment=0.003,\n",
    "        efficiency_threshold=0.2\n",
    "    ),\n",
    "    \n",
    "    # Manually configure warmup\n",
    "    warmup_config=StratifiedWarmupConfig(),\n",
    "    \n",
    "    # Manually configure evaluator\n",
    "    evaluator_config=LookupEvaluatorConfig(\n",
    "        ref_filename=\"../examples/docking_scores/product_scores.csv\",\n",
    "        ref_colname=\"Scores\"\n",
    "    ),\n",
    "    \n",
    "    # Manually configure performance\n",
    "    batch_size=1,\n",
    "    processes=1,\n",
    "    min_cpds_per_core=10,\n",
    "\n",
    "    # Manually set output\n",
    "    results_filename=\"./tmp/results.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c32a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ThompsonSampler.from_config(config)\n",
    "\n",
    "# IMPORTANT: Set the reaction (required step)\n",
    "sampler.set_reaction(config.reaction_smarts)\n",
    "print(f\"Sampler initialized with {sampler.get_num_prods():.2e} possible products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af724c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting warmup phase...\")\n",
    "warmup_results = sampler.warm_up(num_warmup_trials=config.num_warmup_trials)\n",
    "print(f\"Warmup complete: {len(warmup_results)} compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d144531",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting Thompson Sampling search ({config.num_ts_iterations} iterations)...\")\n",
    "search_results = sampler.search(num_cycles=config.num_ts_iterations)\n",
    "print(f\"Search complete: {len(search_results)} total compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.concat([warmup_results,search_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine warmup and search results\n",
    "all_results = pl.concat([warmup_results,search_results])\n",
    "\n",
    "# Display top 100 compounds (lowest scores = best for docking)\n",
    "top_100 = all_results.sort(\"score\").head(100)\n",
    "print(\"\\nTop 100 compounds found:\")\n",
    "display(top_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd77f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "top_100.write_csv(\"./tmp/ts_results.csv\")\n",
    "print(\"Results saved to ./tmp/ts_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Sampler\n",
    "# Mainly to be used if you want to deploy multi-processing\n",
    "sampler.close()\n",
    "print(\"Sampler closed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ed03f",
   "metadata": {},
   "source": [
    "## Demonstration with a Preset\n",
    "This is an easier method to run TS fast with a set of default parameters. But we are not going to use the wrapper function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70923f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_preset = ThompsonSampler.from_config(preset_config)\n",
    "\n",
    "# IMPORTANT: Set the reaction (required step)\n",
    "sampler_preset.set_reaction(preset_config.reaction_smarts)\n",
    "print(f\"Sampler initialized with {sampler_preset.get_num_prods():.2e} possible products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df83c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting warmup phase...\")\n",
    "warmup_results_preset = sampler_preset.warm_up(num_warmup_trials=preset_config.num_warmup_trials)\n",
    "print(f\"Warmup complete: {len(warmup_results_preset)} compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting Thompson Sampling search ({config.num_ts_iterations} iterations)...\")\n",
    "search_results_preset = sampler_preset.search(num_cycles=preset_config.num_ts_iterations)\n",
    "print(f\"Search complete: {len(search_results_preset)} total compounds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine warmup and search results\n",
    "all_results_preset = pl.concat([warmup_results_preset,search_results_preset])\n",
    "\n",
    "# Display top 100 compounds (lowest scores = best for docking)\n",
    "top_100_preset = all_results_preset.sort(\"score\").head(100)\n",
    "print(\"\\nTop 100 compounds found:\")\n",
    "display(top_100_preset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "top_100_preset.write_csv(\"./tmp/ts_results_preset.csv\")\n",
    "print(\"Results saved to ./tmp/ts_results_preset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439956f",
   "metadata": {},
   "source": [
    "# Obsolete from this point onwards?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f2e3b",
   "metadata": {},
   "source": [
    "# Testing Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673e62c",
   "metadata": {},
   "source": [
    "*TACTICS.thompson_sampling.ts_main does not exist. Tried TACTICS.thompson_sampling.main, but this does not contain parse_input_dict(), so the script breaks after the third code block.*\n",
    "\n",
    "*Using the legacy TACTICS.thompson_sampling.legacy.ts_main also doesn't work as sampler_type is not defined.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TACTICS.thompson_sampling.main import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545da7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_file = \"\"\"{\n",
    "\"reagent_file_list\": [\n",
    "        \"../examples/input_files/acids.smi\",\n",
    "        \"../examples/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    \"reaction_smarts\": \"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    \"num_warmup_trials\": 10,\n",
    "    \"num_ts_iterations\": 5000,\n",
    "    \"search_strategy\": \"greedy_minimize_dt\",\n",
    "    \"processes\": 1,\n",
    "    \"percent_of_library\": 0.1,\n",
    "    \"scaling\": -1,\n",
    "    \"temperature\": 1,\n",
    "    \"evaluator_class_name\": \"LookupEvaluator\",\n",
    "    \"evaluator_arg\": {\"ref_filename\" : \"../examples/docking_scores/product_scores.csv\"},\n",
    "    \"log_filename\": \"./tmp/ts_logs.txt\",\n",
    "    \"results_filename\": \"./tmp/ts_results.csv\"\n",
    "}\"\"\"\n",
    "input_dict = json.loads(input_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea732595",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_input_dict(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff828aa",
   "metadata": {},
   "source": [
    "*_______ Unable to continue further _______*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_std_df = run_ts(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44155171",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_std_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c658e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.sort(\"Scores\", descending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19dd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the TS dataframe so that it is compatible with the get_top_building_blocks function\n",
    "ts_df_mod = ts_std_df.copy()\n",
    "ts_df_mod = ts_df_mod.drop(\"SMILES\",axis=1)\n",
    "ts_df_mod.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "top_5000_building_blocks_ts_df = get_top_building_blocks(ts_df_mod, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overlap between the enriched building blocks from the TS and the top 5000 building blocks from brute force docking\n",
    "overlap_ts = check_overlap(top_5000_building_blocks_ts_df, top_5000_building_blocks)\n",
    "visualize_overlapping_blocks(overlap_ts, combined_smiles_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26100d1",
   "metadata": {},
   "source": [
    "### Check Consistency of the TS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_df_list.append(run_ts(input_dict, hide_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d011bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_std_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_molecules = 5000  # The top 1% of products\n",
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f2c62",
   "metadata": {},
   "source": [
    "## Boltzmann Sampling \n",
    "Utilizes Boltzmann sampling instead of standard greedy sampling to find new compounds to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5de806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "input_dict_boltzmann = copy.copy(input_dict)\n",
    "input_dict_boltzmann[\"search_strategy\"] = \"boltzmann_minimize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_boltzmann_df = run_ts(input_dict_boltzmann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34728219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the TS dataframe so that it is compatible with the get_top_building_blocks function\n",
    "ts_Boltzmann_df_mod = ts_boltzmann_df.copy()\n",
    "ts_Boltzmann_df_mod = ts_Boltzmann_df_mod.drop(\"SMILES\",axis=1)\n",
    "ts_Boltzmann_df_mod.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "top_5000_building_blocks_ts_Boltzmann_df = get_top_building_blocks(ts_Boltzmann_df_mod, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aceed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overlap between the enriched building blocks from the TS and the top 5000 building blocks from brute force docking\n",
    "overlap_ts_Boltzmann = check_overlap(top_5000_building_blocks_ts_Boltzmann_df, top_5000_building_blocks)\n",
    "visualize_overlapping_blocks(overlap_ts_Boltzmann, combined_smiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b23e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 runs of Boltzmann Sampling\n",
    "ts_boltzmann_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_boltzmann_df_list.append(run_ts(input_dict_boltzmann, hide_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff127895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_boltzmann_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effa03b",
   "metadata": {},
   "source": [
    "#### Run these cells to generate the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes \n",
    "docking_df = prod_scores_df.to_pandas() # Convert the polars dataframe to a pandas dataframe\n",
    "docking_df.rename(columns={\"Product_Code\":\"Name\", \"Scores\":\"score\"},inplace=True)\n",
    "docking_df[\"method\"] = \"ref\"\n",
    "docking_df[\"cycle\"] = \"ref\"\n",
    "ref_df = docking_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ef3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the TS dataframes\n",
    "# We can substitute the regular TS with enhanced TS here\n",
    "ts_graph_df_list = []\n",
    "ts_enhanced_df_list_graph = []\n",
    "ts_boltzmann_df_list_graph = []\n",
    "for i in range(0,10):\n",
    "    ts_df_temp = ts_df_list[i].copy()\n",
    "    ts_df_temp[\"cycle\"] = i\n",
    "    ts_df_temp[\"method\"] = \"TS\"\n",
    "    ts_df_temp.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_graph_df_list.append(ts_df_temp)\n",
    "    ts_enhanced_temp_df = ts_enhanced_df_list[i].copy()\n",
    "    ts_enhanced_temp_df[\"cycle\"] = i\n",
    "    ts_enhanced_temp_df[\"method\"] = \"TS_enhanced\"\n",
    "    ts_enhanced_temp_df.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_enhanced_df_list_graph.append(ts_enhanced_temp_df)\n",
    "    ts_boltzmann_temp_df = ts_boltzmann_df_list[i].copy()\n",
    "    ts_boltzmann_temp_df[\"cycle\"] = i\n",
    "    ts_boltzmann_temp_df[\"method\"] = \"TS_Boltzmann\"\n",
    "    ts_boltzmann_temp_df.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    ts_boltzmann_df_list_graph.append(ts_boltzmann_temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6075f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes\n",
    "ts_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_graph_df_list])\n",
    "ts_enhanced_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_enhanced_df_list_graph])\n",
    "ts_boltzmann_combo_df = pd.concat([x.sort_values(by=\"score\", ascending=True).head(100) for x in ts_boltzmann_df_list_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ffd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create concatenated data points only for TS, TS_enhanced and TS_Boltzmann\n",
    "concat_data = pd.DataFrame({\n",
    "    'cycle': ['concat'] * (len(ts_combo_df) + len(ts_enhanced_combo_df) + len(ts_boltzmann_combo_df)),\n",
    "    'score': pd.concat([ts_combo_df['score'], ts_enhanced_combo_df['score'], ts_boltzmann_combo_df['score']]),\n",
    "    'method': pd.concat([ts_combo_df['method'], ts_enhanced_combo_df['method'], ts_boltzmann_combo_df['method']])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8140b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([ts_combo_df, ts_enhanced_combo_df, ts_boltzmann_combo_df, concat_data, ref_df])\n",
    "combined_df.reset_index(drop=True,inplace=True)\n",
    "combined_df.method = pd.Categorical(combined_df.method, categories=[\"ref\",\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a consistent color palette\n",
    "palette_colors = sns.color_palette(\"Set1\")[:4]\n",
    "\n",
    "# Top subplot (stripplot) with concatenated results\n",
    "ax1 = sns.stripplot(data=combined_df, x=\"cycle\", y=\"score\", hue=\"method\", dodge=True, palette=palette_colors)\n",
    "ax1.set_ylabel(\"Score\", fontsize=16)\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the numbers of hits found by each method in each cycle\n",
    "ref_products = ref_df[\"Name\"].to_list()\n",
    "plot_list = []\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS'])\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS_enhanced' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS_enhanced'])\n",
    "for cycle in range(0,10):\n",
    "    num_in_cycle = len(combined_df.query(\"cycle == @cycle and method == 'TS_Boltzmann' and Name in @ref_products\"))\n",
    "    plot_list.append([cycle+1,num_in_cycle,'TS_Boltzmann'])\n",
    "# Get Percentage of hits found by each method in each cycle\n",
    "plot_list.append([\"concat\",len(ts_enhanced_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS_enhanced\"])\n",
    "plot_list.append([\"concat\",len(ts_boltzmann_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS_Boltzmann\"])\n",
    "plot_list.append([\"concat\",len(ts_combo_df.query(\"Name in @ref_products\").drop_duplicates(subset=[\"Name\"])),\"TS\"])\n",
    "plot_list.append([\"ref\",100,\"ref\"])\n",
    "plot_df = pd.DataFrame(plot_list, columns=[\"cycle\",\"found\",\"method\"])\n",
    "plot_df.method = pd.Categorical(plot_df.method, categories=[\"ref\",\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70444dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check if there is an actual difference between the standard and the enhanced TS\n",
    "from scipy import stats\n",
    "f_stat, p_value = stats.f_oneway(plot_df.loc[plot_df[\"method\"] == \"TS\",\"found\"], \n",
    "                                 plot_df.loc[plot_df[\"method\"] == \"TS_enhanced\",\"found\"], \n",
    "                                 plot_df.loc[plot_df[\"method\"] == \"TS_Boltzmann\",\"found\"])\n",
    "print(f\"F-statistic: {f_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "tukey = pairwise_tukeyhsd(endog=plot_df[\"found\"], groups=plot_df[\"method\"], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"cycle\",y=\"found\",hue=\"method\",data=plot_df, dodge=True)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger figure\n",
    "plt.figure(figsize=(15, 8))  # Increase these numbers to make plot bigger (width, height)\n",
    "\n",
    "# Create the barplot with wider bars\n",
    "ax = sns.barplot(x=\"cycle\", y=\"found\", hue=\"method\", data=plot_df, dodge=True, width=0.8, palette=\"Set1\")  # width controls bar width\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1)\n",
    "\n",
    "# Add value labels manually with larger font size\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                xy=(p.get_x() + p.get_width()/2, p.get_height()),\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=12)  # Increase font size of the numbers\n",
    "\n",
    "# Adjust figure margins\n",
    "plt.subplots_adjust(right=0.85, bottom=0.15)\n",
    "\n",
    "# Optional: Increase font size of axis labels and ticks\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.set_xlabel(ax.get_xlabel(), fontsize=14)\n",
    "ax.set_ylabel(ax.get_ylabel(), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 18), height_ratios=[2, 1])\n",
    "\n",
    "# Define a consistent color palette and category order\n",
    "palette_colors = sns.color_palette(\"Set1\")[:4]\n",
    "method_order = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\", \"ref\"]\n",
    "\n",
    "# Make sure both dataframes have the same category order\n",
    "combined_df.method = pd.Categorical(combined_df.method, categories=method_order, ordered=True)\n",
    "plot_df.method = pd.Categorical(plot_df.method, categories=method_order, ordered=True)\n",
    "\n",
    "# Top subplot (stripplot) with concatenated results\n",
    "sns.stripplot(data=combined_df, x=\"cycle\", y=\"score\", hue=\"method\", dodge=True, palette=palette_colors, ax=ax1)\n",
    "ax1.set_ylabel(\"Docking Score (Negative is Better)\", fontsize=16)\n",
    "ax1.set_xlabel(\"Cycle\", fontsize=16)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# Bottom subplot (barplot)\n",
    "sns.barplot(x=\"cycle\", y=\"found\", hue=\"method\", data=plot_df, dodge=True, width=0.8, palette=palette_colors, ax=ax2)\n",
    "# Remove the bottom legend\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "# Add value labels to bars, only for non-zero values\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:  # Only add label if the value is greater than 0\n",
    "        ax2.annotate(f'{int(height)}', \n",
    "                    xy=(p.get_x() + p.get_width()/2, height),\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=14)\n",
    "\n",
    "# Adjust font sizes for bottom plot\n",
    "ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax2.set_xlabel(\"Cycle\", fontsize=16)\n",
    "ax2.set_ylabel(\"Number of top 100 hits found\", fontsize=16)\n",
    "\n",
    "# Move the legend to the top of the figure and increase its font size\n",
    "legend = ax1.legend(loc='upper left', bbox_to_anchor=(1.00, 0.75), ncol=1, fontsize=14)\n",
    "\n",
    "# Adjust layout with reduced spacing between plots\n",
    "plt.subplots_adjust(right=0.85, hspace=0.125)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ee38d",
   "metadata": {},
   "source": [
    "This can at first look misleading, but the it is important to remember that the more negative the `ChemGauss` score the better it is. Hence, points at the bottom of the plot are better to see than those at the top. The reference presents the best set of molecules as seen from brute-force docking, we see that the Boltzmann sampling does not appear to find most of the hits, hence the Boltzmann sampling is not a useful method to use to find hits for this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9565d9",
   "metadata": {},
   "source": [
    "## Enhanced Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac039a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "input_dict_enhanced_TS = copy.copy(input_dict)\n",
    "input_dict_enhanced_TS[\"search_strategy\"] = \"thermal_cycling\"\n",
    "input_dict_enhanced_TS[\"processes\"] = 1\n",
    "input_dict_enhanced_TS[\"percent_of_library\"] = 0.1\n",
    "input_dict_enhanced_TS[\"scaling\"] = -1\n",
    "input_dict_enhanced_TS[\"temperature\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df = run_ts(input_dict_enhanced_TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b35fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d55c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df = prod_scores_df.sort(\"Scores\", descending=False).head(100).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b97cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc69164",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_ts_enhanced_df = ts_enhanced_df.sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(truth_df[\"Product_Code\"]) & set(top_100_ts_enhanced_df[\"Name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df = ts_enhanced_df.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28618b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df_slice = ts_enhanced_df. sort_values(by=\"Scores\", ascending=True).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4dbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 runs of Boltzmann Sampling\n",
    "ts_enhanced_df_list = []\n",
    "for i in tqdm(range(0,10)):\n",
    "    ts_enhanced_df_temp = run_ts(input_dict_enhanced_TS, hide_progress=True)\n",
    "    ts_enhanced_df_temp = ts_enhanced_df_temp.sort_values(by=\"score\", ascending=True).head(5000)\n",
    "    ts_enhanced_df_list.append(ts_enhanced_df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504eabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts_enhanced_df_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc48c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_enhanced_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.sort([\"Scores\"], descending=False).head(100)\n",
    "prod_scores_df.head(100).select(pl.col(\"Scores\").min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ade9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_scores_df.head(100).select(pl.col(\"Scores\").max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59277a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_list[0].sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_boltzmann_df_list[0].sort_values(by=\"score\", ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072cc13",
   "metadata": {},
   "source": [
    "### How much does the Enhanced TS recover using Docking as the Scoring Function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "prod_scores_df_pd = prod_scores_df.to_pandas()\n",
    "top_5k_truth = prod_scores_df_pd.sort_values(by=\"Scores\", ascending=True).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the an Instance of each of the TS methods\n",
    "# Re run this if the the dataframes need to be reset\n",
    "ts_std_df = ts_df_list[0].copy()\n",
    "ts_enhanced_df = ts_enhanced_df_list[0].copy()\n",
    "ts_boltzmann_df = ts_boltzmann_df_list[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01263c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dfs = [ts_std_df, ts_enhanced_df, ts_boltzmann_df]\n",
    "ts_types = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"]\n",
    "top_5k = {}\n",
    "for n, df in enumerate(ts_dfs):\n",
    "    df_temp = df.sort_values(by=\"score\", ascending=True).head(5000)\n",
    "    df_temp.drop(columns=[\"SMILES\"],inplace=True)\n",
    "    df_temp.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"},inplace=True)\n",
    "    top_5k[ts_types[n]] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cebee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5k[\"TS\"] = top_5k[\"TS\"][[\"Product_Code\"]].assign(standard=True)\n",
    "top_5k[\"TS_enhanced\"] = top_5k[\"TS_enhanced\"][[\"Product_Code\"]].assign(enhanced=True)\n",
    "top_5k[\"TS_Boltzmann\"] = top_5k[\"TS_Boltzmann\"][[\"Product_Code\"]].assign(boltzmann=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "df_top = pd.merge(pd.merge(pd.merge(top_5k_truth, top_5k[\"TS\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k[\"TS_enhanced\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k[\"TS_Boltzmann\"], how=\"left\", on=\"Product_Code\")\n",
    "df_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef756246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "    ax.plot(top_ns, [df_top.head(n)[col].sum() / n for n in top_ns], label=col, marker=\"o\")\n",
    "ax.set_xlabel(\"top N\")\n",
    "ax.set_ylabel(\"fraction_found\")\n",
    "ax.axhline(1, color=\"k\", linestyle=\"--\", zorder=0)\n",
    "ax.set_title(\"Frac of top N found\")\n",
    "ax.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123b173",
   "metadata": {},
   "source": [
    "It appears that the standard TS slightly underperforms the enhanced TS. The Boltzmann sampling's performance remains poor despite increasing the cutoff for the top n compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested in looking at the plot with error bars\n",
    "# Lets generate these error bars using the cycle data\n",
    "ts_comp = []\n",
    "ts_types = [\"TS\", \"TS_enhanced\", \"TS_Boltzmann\"] # Types of TS to compare\n",
    "for n in range(0,10):\n",
    "    # Get the top 5000 compounds for each method\n",
    "    # Rename columns\n",
    "    ts_dfs_temp = [ts_df_list[n].copy(), ts_enhanced_df_list[n].copy(), ts_boltzmann_df_list[n].copy()]\n",
    "    ts_dfs_temp = [x.sort_values(by=\"score\", ascending=True).head(5000) for x in ts_dfs_temp]\n",
    "    ts_dfs_temp = [x.drop(columns=[\"SMILES\"]) for x in ts_dfs_temp]\n",
    "    ts_dfs_temp = [x.rename(columns={\"score\":\"Scores\", \"Name\":\"Product_Code\"}) for x in ts_dfs_temp]\n",
    "    top_5k_temp = {}\n",
    "    for n, ts_type in enumerate(ts_types):\n",
    "        top_5k_temp[ts_type] = ts_dfs_temp[n] # Assign the appropriate dataframe to the dictionary\n",
    "        if n == 0: # Standard TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(standard=True)\n",
    "        elif n == 1: # Enhanced TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(enhanced=True)\n",
    "        else: # Boltzmann TS\n",
    "            top_5k_temp[ts_type] = top_5k_temp[ts_type][[\"Product_Code\"]].assign(boltzmann=True)\n",
    "    # Merge the dataframes\n",
    "    df_top = pd.merge(pd.merge(pd.merge(top_5k_truth, top_5k_temp[\"TS\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k_temp[\"TS_enhanced\"], how=\"left\", on=\"Product_Code\"),\n",
    "                  top_5k_temp[\"TS_Boltzmann\"], how=\"left\", on=\"Product_Code\")\n",
    "    # Calculate the fraction of hits found for each method\n",
    "    ts_comp.append(df_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "top_ns_frac = pd.DataFrame(columns=[\"cycle\",\"top_n\", \"method\", \"frac_top_n\"])\n",
    "for cycle_id, ts_comp_df in enumerate(ts_comp):\n",
    "    for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "        for n in top_ns:\n",
    "            frac_top_ns = ts_comp_df.head(n)[col].sum() / n\n",
    "            row = {\"cycle\":cycle_id, \"top_n\":n, \"method\":col, \"frac_top_n\":frac_top_ns}\n",
    "            top_ns_frac = pd.concat([top_ns_frac, pd.DataFrame([row])], ignore_index=True)\n",
    "top_ns_frac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bab875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with mean, std and count of frac_top_n for each top_n and method\n",
    "grouped_stats = top_ns_frac.groupby(['top_n', 'method'])['frac_top_n'].agg(\n",
    "    mean='mean',\n",
    "    std='std',\n",
    "    count='count'\n",
    ").reset_index()\n",
    "\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6)) # set the size of the plot\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"tab10\", font_scale=1.2)\n",
    "\n",
    "# Ensure sub_category is sortable (e.g., categorical or ordered)\n",
    "grouped_stats['top_n'] = grouped_stats['top_n'].astype(str)\n",
    "\n",
    "# Line plot per category with error bars\n",
    "sns.lineplot(\n",
    "    data=grouped_stats,\n",
    "    x='top_n',\n",
    "    y='mean',\n",
    "    hue='method',  # color line by category\n",
    "    marker='o',\n",
    "    errorbar=None,\n",
    "    linewidth=2.5  # Disable built-in CI\n",
    ")\n",
    "\n",
    "# Add error bars manually using plt.errorbar\n",
    "for _, row in grouped_stats.iterrows():\n",
    "    if pd.notnull(row['std']):\n",
    "        plt.errorbar(\n",
    "            x=row['top_n'],\n",
    "            y=row['mean'],\n",
    "            yerr=row['std'],\n",
    "            fmt='none',\n",
    "            capsize=4,\n",
    "            ecolor='gray'\n",
    "        )\n",
    "\n",
    "plt.title(\"Mean top N fraction found for each method across 10 cycles\")\n",
    "plt.xlabel(\"top n compounds\")\n",
    "plt.ylabel(\"Mean fraction found\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "top_ns = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "for col in [\"standard\", \"enhanced\", \"boltzmann\"]:\n",
    "    for ts_comp_df in ts_comp:\n",
    "        ax.plot(top_ns, [ts_comp_df.head(n)[col].sum() / n for n in top_ns], label=col, marker=\"o\")\n",
    "ax.set_xlabel(\"top N\")\n",
    "ax.set_ylabel(\"fraction_found\")\n",
    "ax.axhline(1, color=\"k\", linestyle=\"--\", zorder=0)\n",
    "ax.set_title(\"Frac of top N found\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7937e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = ts_enhanced_df[\"Name\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c32df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_molecules = 5000  # The top 1% of products\n",
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tactics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
