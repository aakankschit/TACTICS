{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! Non-operational !!!\n",
    "\n",
    "### This tutorial is currently non-operational. When non-legacy code is operational, these tutorials are to be adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've split the Notebook in two sections. Thompson Sampling and Results Analysis. \n",
    "\n",
    "The files provided for the input are accessible with:\n",
    "```\n",
    "../examples/docking_scores/{file_name}\n",
    "../examples/input_files/{file_name}\n",
    "```\n",
    "\n",
    "output files should always be placed in (this ensures any file created is not uploaded to the GitHub repo accidently):\n",
    "```\n",
    "./tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've tried going through the notebook using the data provided, but encountered issues not all files seem to be available. \n",
    "\n",
    "I've added comments in *italics*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of the Results of Docking for Thrombin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remco/.conda/envs/tactics/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/remco/apps/TACTICS/src/TACTICS/thompson_sampling/core/evaluators.py:16: UserWarning: Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or FredEvaluator\n",
      "  warnings.warn(f\"Openeye packages not available in this environment; do not attempt to use ROCSEvaluator or \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from IPython.display import display\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Add the root directory of your project to the Python path\n",
    "project_root = './tmp'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "# Import functionalities from enumeration_utils.py\n",
    "from TACTICS.library_enumeration.enumeration_utils import find_reactants_from_product_code\n",
    "# Import functionalities from library_analysis_utils.py\n",
    "from TACTICS.library_analysis.library_analysis_utils import compile_product_scores, compile_product_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_smi_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a .smi file and create a dictionary with building block codes as keys and SMILES as items.\n",
    "    \n",
    "    :param file_path: The path to the .smi file.\n",
    "    :return: A dictionary with building block codes as keys and SMILES as items.\n",
    "    \"\"\"\n",
    "    building_block_dict = {}\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            smiles, code = line.strip().split()\n",
    "            building_block_dict[code] = smiles\n",
    "    \n",
    "    return building_block_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the scores and dictionary of product codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No Linear_amide folder present*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../examples/Linear_amide'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generate Dictionary to map product codes to product SMILES\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#prod_SMILES_dir = \"/Users/aakankschitnandkeolyar/Desktop/TS_Chem_Space/Thrombin/Linear_amide\" -> to be placed in:\u001b[39;00m\n\u001b[32m      3\u001b[39m prod_SMILES_dir = \u001b[33m\"\u001b[39m\u001b[33m../examples/Linear_amide\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m prod_smiles_dict = \u001b[43mcompile_product_smiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprod_SMILES_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/apps/TACTICS/src/TACTICS/library_analysis/library_analysis_utils.py:42\u001b[39m, in \u001b[36mcompile_product_smiles\u001b[39m\u001b[34m(directory)\u001b[39m\n\u001b[32m     39\u001b[39m product_dict = {}\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Iterate over all files in the directory\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mproducts\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m filename \u001b[38;5;129;01mand\u001b[39;00m filename.endswith(\u001b[33m\"\u001b[39m\u001b[33m.smi\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     44\u001b[39m         file_path = os.path.join(directory, filename)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../examples/Linear_amide'"
     ]
    }
   ],
   "source": [
    "# Generate Dictionary to map product codes to product SMILES\n",
    "#prod_SMILES_dir = \"/Users/aakankschitnandkeolyar/Desktop/TS_Chem_Space/Thrombin/Linear_amide\" -> to be placed in:\n",
    "prod_SMILES_dir = \"../examples/Linear_amide\"\n",
    "prod_smiles_dict = compile_product_smiles(prod_SMILES_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*_______ Unable to continue further _______*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data from Brute force docking\n",
    "prod_scores_dir = \"/Users/aakankschitnandkeolyar/Desktop/TS_Chem_Space/Thrombin/Linear_amide/docking_scores\"\n",
    "prod_scores_df = compile_product_scores(prod_scores_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Dictionary to map product codes to product SMILES (protected products)\n",
    "prod_SMILES_dir_prot = \"/Users/aakankschitnandkeolyar/Desktop/TS_Chem_Space/Thrombin/Linear_amide/protected_prods\"\n",
    "prod_smiles_dict_prot = compile_product_smiles(prod_SMILES_dir_prot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prod_scores_dir = \"/Users/aakankschitnandkeolyar/Desktop/TS_Chem_Space/Thrombin/Linear_amide/docking_scores\"\n",
    "prod_scores_df = compile_product_scores(prod_scores_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for SMILES strings by mapping Product_Code to SMILES using the dictionary\n",
    "prod_scores_df = prod_scores_df.with_columns(\n",
    "    pl.Series(\"SMILES\", [prod_smiles_dict_prot.get(code, None) for code in prod_scores_df[\"Product_Code\"].to_list()])\n",
    ")\n",
    "\n",
    "# Select only the SMILES strings and scores\n",
    "smiles_scores_df = prod_scores_df.select([\"SMILES\", \"Scores\"])\n",
    "\n",
    "# Write the SMILES strings and scores to a .csv file\n",
    "output_file = os.path.join(prod_scores_dir, \"smiles_scores.csv\")\n",
    "smiles_scores_df.write_csv(output_file)\n",
    "\n",
    "print(f\"SMILES strings and scores have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docking Success Rate\n",
    "Here I want to estimate what percentage of the library was successfully docked. Additionally, I would like to see if there was any common substructure amongst the compounds that failed to dock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the products that were not docked \n",
    "undocked_prods = set(prod_smiles_dict.keys()) - set(prod_scores_df[\"Product_Code\"])\n",
    "print(f\"Number of undocked products: {len(undocked_prods)}\")\n",
    "print(\"Undocked products:\")\n",
    "for prod in undocked_prods:\n",
    "    print(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Create a new DataFrame for undocked products with a score of +10\n",
    "undocked_df = pl.DataFrame({\n",
    "    \"Product_Code\": list(undocked_prods),\n",
    "    \"Scores\": [10.0] * len(undocked_prods)  # Assign a score of +10 to all undocked products\n",
    "})\n",
    "\n",
    "# Concatenate the undocked products DataFrame with the existing prod_scores_df\n",
    "prod_scores_df = pl.concat([prod_scores_df, undocked_df])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(f\"Updated prod_scores_df with undocked products:\")\n",
    "print(prod_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file path\n",
    "output_file = os.path.join(prod_scores_dir, \"product_scores.csv\")\n",
    "\n",
    "# Write the Polars DataFrame to a .csv file\n",
    "prod_scores_df.write_csv(output_file)\n",
    "\n",
    "print(f\"Product scores have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docking success rate\n",
    "# Total number of products in the library\n",
    "total_products = len(prod_smiles_dict)\n",
    "\n",
    "# Number of undocked products\n",
    "num_undocked = len(undocked_prods)\n",
    "\n",
    "# Number of successfully docked products\n",
    "num_docked = total_products - num_undocked\n",
    "\n",
    "# Calculate percentages\n",
    "percent_docked = (num_docked / total_products) * 100\n",
    "percent_undocked = (num_undocked / total_products) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f\"Percentage of compounds successfully docked: {percent_docked:.2f}%\")\n",
    "print(f\"Percentage of compounds that did not dock: {percent_undocked:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docking was successful, given nearly all of the compounds docked. Lets check to see if there were any building blocks that were common amongst the ones that failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of each building block in the undocked product codes\n",
    "building_block_counts = Counter()\n",
    "for prod in undocked_prods:\n",
    "    building_blocks = prod.split(\"_\")  # Split the product code by \"_\"\n",
    "    building_block_counts.update(building_blocks)\n",
    "\n",
    "# Print the occurrences neatly as a table\n",
    "print(f\"{'Building Block':<20}{'Occurrences':<10}\")\n",
    "print(\"-\" * 30)\n",
    "for block, count in building_block_counts.items():\n",
    "    print(f\"{block:<20}{count:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do some analysis on the hits\n",
    "I am screening for the top 1% of ligands. The ChemGauss score that `openeye` utilizes returns a more negative value for a ligand with greater binding affinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find the top 20 most commonly occurring products\n",
    "\n",
    "total_molecules = 5000  # The top 1% of products\n",
    "\n",
    "sorted_prod_scores_df = prod_scores_df.sort(\"Scores\", descending=False)\n",
    "top_products_df = sorted_prod_scores_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the products extract the building blocks\n",
    "# This is to count the occurrences of each building block in the top 1% of products\n",
    "top_building_blocks = []\n",
    "for code in top_products_df[\"Product_Code\"]:\n",
    "    building_blocks = code.split('_')\n",
    "    top_building_blocks.extend(building_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each building block\n",
    "building_block_counts = Counter(top_building_blocks)\n",
    "\n",
    "# Find the top 20 most commonly occurring building blocks\n",
    "top_20_common_building_blocks = building_block_counts.most_common(20)\n",
    "\n",
    "# Print the table header\n",
    "print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Print the building blocks and their frequencies\n",
    "for block, count in top_20_common_building_blocks:\n",
    "    print(f\"{block:<20}{count:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Building Blocks \n",
    " That were enriched in the top 20 building blocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acid_bb_dict = read_smi_file('/Users/aakankschitnandkeolyar/Desktop/PRISMS/tests/Data/Thrombin/input_files/amino_acids_deprotected.smi')\n",
    "acids_bb_dict = read_smi_file('/Users/aakankschitnandkeolyar/Desktop/PRISMS/tests/Data/Thrombin/input_files/acids.smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SMILES for the top 20 building blocks\n",
    "top_20_smiles = []\n",
    "labels=[]\n",
    "for block, _ in top_20_common_building_blocks:\n",
    "    if 'AA' in block:\n",
    "        top_20_smiles.append(amino_acid_bb_dict[block])\n",
    "    elif 'CA' in block:\n",
    "        top_20_smiles.append(acids_bb_dict[block])\n",
    "    labels.append(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDKit molecule objects\n",
    "molecules = [Chem.MolFromSmiles(smiles) for smiles in top_20_smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the molecules in a grid (5 molecules per row)\n",
    "Draw.MolsToGridImage(molecules, molsPerRow=5, subImgSize=(300, 300), legends=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now look at the top 20 building blocks in each position\n",
    "This will help in understanding the enrichment of building blocks in certain positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product codes as a list\n",
    "product_codes = top_products_df[\"Product_Code\"].to_list()\n",
    "\n",
    "# Initialize counters for each position\n",
    "position_counters = []\n",
    "\n",
    "# Iterate through the product codes\n",
    "for product_code in product_codes:\n",
    "    building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "    # Ensure the position_counters list is large enough to handle all positions\n",
    "    while len(position_counters) < len(building_blocks):\n",
    "        position_counters.append(Counter())\n",
    "    # Update the counters for each position\n",
    "    for i, block in enumerate(building_blocks):\n",
    "        position_counters[i][block] += 1\n",
    "\n",
    "# Find the top 20 building blocks for each position\n",
    "for i, counter in enumerate(position_counters):\n",
    "    print(f\"Top 20 building blocks for position {i + 1}:\")\n",
    "    print(f\"{'Building Block':<20}{'Frequency':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for block, count in counter.most_common(20):\n",
    "        print(f\"{block:<20}{count:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the top 20 building blocks for each position\n",
    "top_20_building_blocks_per_position = []\n",
    "for counter in position_counters:\n",
    "    top_20_blocks = [block for block, _ in counter.most_common(20)]\n",
    "    top_20_building_blocks_per_position.append(top_20_blocks)\n",
    "\n",
    "# Convert the list to a tuple\n",
    "top_20_building_blocks_tuple = tuple(top_20_building_blocks_per_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two dictionaries\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}\n",
    "\n",
    "# Iterate through each position's top 20 building blocks\n",
    "for i, counter in enumerate(position_counters):\n",
    "    # Get the top 20 building blocks for the current position\n",
    "    top_20_blocks = counter.most_common(20)\n",
    "    \n",
    "    # Create a list of RDKit molecules and their labels\n",
    "    mols = []\n",
    "    legends = []\n",
    "    for block, freq in top_20_blocks:\n",
    "        if block in combined_smiles_dict:  # Use the combined dictionary\n",
    "            smiles = combined_smiles_dict[block]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                mols.append(mol)\n",
    "                # Add building block name and frequency on the first line, fraction on the second line\n",
    "                legends.append(f\"{block} (Freq: {freq})\\nFraction: {round((freq / total_molecules) * 100, 2)}%\")\n",
    "    \n",
    "    # Visualize the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(\n",
    "        mols, legends=legends, molsPerRow=5, subImgSize=(300, 300)\n",
    "    )\n",
    "    \n",
    "    # Display the title and the image\n",
    "    print(f\"Top 20 Building Blocks for Position {i + 1}\")\n",
    "    display(img)  # Display the image in the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_building_blocks(top_products_df, top_n, Maximize=False):\n",
    "    \"\"\"\n",
    "    Extract the top 20 building blocks for each position from the top N products.\n",
    "    \n",
    "    :param Maximize: Sort the building blocks in descending order. If larger values are better scores.\n",
    "    :param top_products_df: Polars DataFrame containing product codes.\n",
    "    :param top_n: Number of top products to consider.\n",
    "    :return: A tuple of lists containing the top 20 building blocks for each position.\n",
    "    \"\"\"\n",
    "    # Get the top N products\n",
    "    if isinstance(top_products_df, pd.DataFrame):\n",
    "        top_products_df = top_products_df.sort_values(by=\"Scores\", ascending=Maximize)\n",
    "    elif isinstance(top_products_df, pl.DataFrame):\n",
    "        top_products_df = top_products_df.sort(\"Scores\", descending=Maximize)\n",
    "    else:\n",
    "        raise TypeError(\"Input must be either a pandas DataFrame or a polars DataFrame\")\n",
    "\n",
    "    top_n_df = top_products_df.head(top_n)\n",
    "    \n",
    "    # Extract the product codes as a list\n",
    "    product_codes = top_n_df[\"Product_Code\"].to_list()\n",
    "\n",
    "    # Initialize counters for each position\n",
    "    position_counters = []\n",
    "\n",
    "    # Iterate through the product codes\n",
    "    for product_code in product_codes:\n",
    "        building_blocks = product_code.split(\"_\")  # Split the product code by \"_\"\n",
    "        # Ensure the position_counters list is large enough to handle all positions\n",
    "        while len(position_counters) < len(building_blocks):\n",
    "            position_counters.append(Counter())\n",
    "        # Update the counters for each position\n",
    "        for i, block in enumerate(building_blocks):\n",
    "            position_counters[i][block] += 1\n",
    "\n",
    "    # Collect the top 20 building blocks for each position\n",
    "    top_20_building_blocks = []\n",
    "    for counter in position_counters:\n",
    "        top_20_building_blocks.append([block for block, _ in counter.most_common(20)])\n",
    "    \n",
    "    return tuple(top_20_building_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check overlap for each position and print the total overlap\n",
    "def check_overlap(top_20_smaller, top_20_5000):\n",
    "    overlap_results = []\n",
    "    total_overlap = 0  # To track the total number of overlapping compounds across all positions\n",
    "\n",
    "    for position, smaller_list in enumerate(top_20_smaller):\n",
    "        # Get the corresponding list from the top 5000\n",
    "        larger_list = top_20_5000[position]\n",
    "        # Find the intersection\n",
    "        overlap = set(smaller_list).intersection(set(larger_list))\n",
    "        overlap_results.append((position + 1, len(overlap), overlap))  # Position is 1-based\n",
    "        total_overlap += len(overlap)  # Add the count of overlaps for this position\n",
    "\n",
    "        # Print the overlap for the current position\n",
    "        print(f\"Position {position + 1}: {len(overlap)} building blocks overlap\")\n",
    "\n",
    "    # Print the total overlap\n",
    "    print(f\"Total number of overlapping compounds across all positions: {total_overlap}\")\n",
    "    return overlap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_overlapping_blocks(overlap, combined_smiles_dict):\n",
    "    \"\"\"\n",
    "    Visualize the overlapping building blocks for each position.\n",
    "    \n",
    "    :param overlap: Overlap data for a specific cutoff (list of tuples with position, count, and blocks).\n",
    "    :param combined_smiles_dict: Dictionary mapping building block codes to SMILES strings.\n",
    "    \"\"\"\n",
    "    for position, count, blocks in overlap:\n",
    "        mols = []\n",
    "        legends = []\n",
    "        for block in blocks:\n",
    "            if block in combined_smiles_dict:\n",
    "                smiles = combined_smiles_dict[block]\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol:\n",
    "                    mols.append(mol)\n",
    "                    # Add only the building block name to the legend\n",
    "                    legends.append(f\"{block}\")\n",
    "        \n",
    "        # Visualize the molecules in a grid\n",
    "        img = Draw.MolsToGridImage(mols, legends=legends, molsPerRow=5, subImgSize=(300, 300))\n",
    "        \n",
    "        # Display the title and the image\n",
    "        print(f\"Overlapping Building Blocks for Position {position}\")\n",
    "        display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "top_200_building_blocks = get_top_building_blocks(prod_scores_df, 200)\n",
    "top_400_building_blocks = get_top_building_blocks(prod_scores_df, 400)\n",
    "top_800_building_blocks = get_top_building_blocks(prod_scores_df, 800)\n",
    "top_1000_building_blocks = get_top_building_blocks(prod_scores_df, 1000)\n",
    "top_5000_building_blocks = get_top_building_blocks(prod_scores_df, 5000)\n",
    "\n",
    "# Print results for top 200 as an example\n",
    "for i, blocks in enumerate(top_200_building_blocks):\n",
    "    print(f\"Top 20 building blocks for position {i + 1} (Top 200 products):\")\n",
    "    print(blocks)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check overlaps for each cutoff\n",
    "overlap_200 = check_overlap(top_200_building_blocks, top_5000_building_blocks)\n",
    "overlap_400 = check_overlap(top_400_building_blocks, top_5000_building_blocks)\n",
    "overlap_800 = check_overlap(top_800_building_blocks, top_5000_building_blocks)\n",
    "overlap_1000 = check_overlap(top_1000_building_blocks, top_5000_building_blocks)\n",
    "\n",
    "# Print results\n",
    "for cutoff, overlap in zip([200, 400, 800, 1000], [overlap_200, overlap_400, overlap_800, overlap_1000]):\n",
    "    print(f\"Comparing enriched building blocks from the top {cutoff} compounds with the top 5000 compounds:\")\n",
    "    for position, count, blocks in overlap:\n",
    "        print(f\"  Position {position}: {count} building blocks overlap\")\n",
    "        print(f\"    Overlapping building blocks: {', '.join(blocks)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "combined_smiles_dict = {**amino_acid_bb_dict, **acids_bb_dict}  # Combine dictionaries for SMILES lookup\n",
    "total_molecules_200 = 200\n",
    "total_molecules_400 = 400\n",
    "total_molecules_800 = 800\n",
    "total_molecules_1000 = 1000\n",
    "\n",
    "# Visualize overlaps for each cutoff\n",
    "print(\"Visualizing overlaps for top 200 compounds:\")\n",
    "visualize_overlapping_blocks(overlap_200, combined_smiles_dict)\n",
    "\n",
    "print(\"Visualizing overlaps for top 400 compounds:\")\n",
    "visualize_overlapping_blocks(overlap_400, combined_smiles_dict)\n",
    "\n",
    "print(\"Visualizing overlaps for top 800 compounds:\")\n",
    "visualize_overlapping_blocks(overlap_800, combined_smiles_dict)\n",
    "\n",
    "print(\"Visualizing overlaps for top 1000 compounds:\")\n",
    "visualize_overlapping_blocks(overlap_1000, combined_smiles_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tactics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
