{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a4a8a7",
   "metadata": {},
   "source": [
    "# Analysis of sEH DEL Data \n",
    "This was the data provided by Anagenex to develop Chris Zhang's workflow. It contains a list of experimentally validated binders. The goal here is to check if any of our search strategies are able to find the same experimentally validated binders with different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb52437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import polars as pl \n",
    "\n",
    "# Add src directory to path since TACTICS is in src/TACTICS\n",
    "tactics_root = Path.cwd().parent / 'src'\n",
    "sys.path.insert(0, str(tactics_root))\n",
    "\n",
    "from TACTICS.thompson_sampling import (\n",
    "    ThompsonSampler,\n",
    "    GreedySelection,\n",
    "    RouletteWheelSelection,\n",
    "    UCBSelection,\n",
    "    EpsilonGreedySelection,\n",
    "    BayesUCBSelection,\n",
    "    ROCSEvaluator,\n",
    "    StratifiedWarmup\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee9168",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446821bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv(\"./input_files/DEL_seH/total_compounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44e7fcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['structure',\n",
       " 'read_count',\n",
       " 'bb1',\n",
       " 'bb2',\n",
       " 'bb3',\n",
       " 'bb1_iso',\n",
       " 'bb2_iso',\n",
       " 'bb3_iso',\n",
       " 'binder']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d053d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.with_columns(\n",
    "    binder = (pl.col(\"read_count\") != 0).cast(pl.Int32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbcf6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of binders: 103136\n",
      " That is 0.010919584134177126% of the library\n"
     ]
    }
   ],
   "source": [
    "# Get the Number of Binders\n",
    "print(f\"The total number of binders: {data.filter(pl.col('binder') == 1).height}\")\n",
    "percent_binders = (sum(data[\"binder\"]==1)/(len(set(data[\"bb1\"]))*len(set(data[\"bb2\"]))*len(set(data[\"bb3\"]))))*100\n",
    "print(f\" That is {percent_binders}% of the library\")\n",
    "binders = data.filter(pl.col(\"binder\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22811265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique BB1: 562\n",
      "Unique BB2: 167\n",
      "Unique BB3: 932\n"
     ]
    }
   ],
   "source": [
    "# The number of unique building blocks among the binders\n",
    "# Extract unique building blocks for each position\n",
    "bb1_unique = binders[\"bb1_iso\"].unique().sort()\n",
    "bb2_unique = binders[\"bb2_iso\"].unique().sort()\n",
    "bb3_unique = binders[\"bb3_iso\"].unique().sort()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(\"./input_files/DEL_seH/unique_binder_bbs\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Write each to a separate CSV file\n",
    "pl.DataFrame({\"bb1_iso\": bb1_unique}).write_csv(output_dir / \"bb1_unique.csv\")\n",
    "pl.DataFrame({\"bb2_iso\": bb2_unique}).write_csv(output_dir / \"bb2_unique.csv\")\n",
    "pl.DataFrame({\"bb3_iso\": bb3_unique}).write_csv(output_dir / \"bb3_unique.csv\")\n",
    "\n",
    "print(f\"Unique BB1: {len(bb1_unique)}\")\n",
    "print(f\"Unique BB2: {len(bb2_unique)}\")\n",
    "print(f\"Unique BB3: {len(bb3_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a1eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010919584134177126"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(data[\"binder\"]==1)/(len(set(data[\"bb1\"]))*len(set(data[\"bb2\"]))*len(set(data[\"bb3\"]))))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b2714bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944504834"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data[\"bb1\"]))* len(set(data[\"bb2\"]))*len(set(data[\"bb3\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "453daf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb1_data = bb1_data.with_columns(pl.Series(\"bb_names\", [f\"HPA{i}\" for i in range(len(bb1_data))]))\n",
    "bb2_data = bb2_data.with_columns(pl.Series(\"bb_names\", [f\"CA{i}\" for i in range(len(bb2_data))]))\n",
    "bb3_data = bb3_data.with_columns(pl.Series(\"bb_names\", [f\"PA{i}\" for i in range(len(bb3_data))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TS_chem_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
