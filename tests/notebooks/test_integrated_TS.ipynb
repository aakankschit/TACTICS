{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Integrated Thompson Sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "from PRISMS.thompson_sampling.ts_main import run_ts\n",
    "from PRISMS.thompson_sampling.thompson_sampling import IntegratedThompsonSampler\n",
    "from PRISMS.thompson_sampling.evaluators import LookupEvaluator\n",
    "from PRISMS.thompson_sampling.baseline import random_baseline\n",
    "from PRISMS.library_analysis.visualization import TS_Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTEGRATED THOMPSON SAMPLER TEST WITH VISUALIZATION\n",
      "============================================================\n",
      "‚úÖ Configuration loaded successfully\n",
      "\n",
      "ÔøΩÔøΩ Running Integrated Thompson Sampler (2 cycles)...\n",
      "\n",
      "ÔøΩÔøΩ Running Integrated Thompson Sampler - Cycle 1\n",
      "  Running warm-up...\n",
      "‚ùå Error in cycle 1: unsupported operand type(s) for *: 'float' and 'NoneType'\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/var/folders/sn/gcrsw56j5k93g0p6gnkvvn7c0000gn/T/ipykernel_4359/247604726.py\", line 89, in <module>\n",
      "    sampler.warm_up_integrated(num_warmup_trials=input_dict.get(\"num_warmup_trials\", 3))\n",
      "  File \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/PRISMS/thompson_sampling/thompson_sampling.py\", line 153, in warm_up_integrated\n",
      "    batch_size = min(100, self.num_prods // num_warmup_trials)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/PRISMS/thompson_sampling/thompson_sampling.py\", line 48, in generate_unique_batch\n",
      "    means = np.array([r.posterior_mean if r.posterior_mean is not None else 0.0 for r in reagent_list])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'\n",
      "\n",
      "\n",
      "ÔøΩÔøΩ Running Integrated Thompson Sampler - Cycle 2\n",
      "  Running warm-up...\n",
      "‚ùå Error in cycle 2: unsupported operand type(s) for *: 'float' and 'NoneType'\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/var/folders/sn/gcrsw56j5k93g0p6gnkvvn7c0000gn/T/ipykernel_4359/247604726.py\", line 89, in <module>\n",
      "    sampler.warm_up_integrated(num_warmup_trials=input_dict.get(\"num_warmup_trials\", 3))\n",
      "  File \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/PRISMS/thompson_sampling/thompson_sampling.py\", line 153, in warm_up_integrated\n",
      "    batch_size = min(100, self.num_prods // num_warmup_trials)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/PRISMS/thompson_sampling/thompson_sampling.py\", line 48, in generate_unique_batch\n",
      "    means = np.array([r.posterior_mean if r.posterior_mean is not None else 0.0 for r in reagent_list])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'\n",
      "\n",
      "\n",
      "üîÑ Running Random Baseline (2 cycles)...\n",
      "\n",
      "üîÑ Running Random Baseline - Cycle 1\n",
      "5.00e+05 products\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82131ba1df52452f9ec34d868ae4e3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error in random cycle 1: <rdkit.Chem.rdchem.Mol object at 0x35a544900>\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/var/folders/sn/gcrsw56j5k93g0p6gnkvvn7c0000gn/T/ipykernel_4359/247604726.py\", line 136, in <module>\n",
      "    random_baseline(\n",
      "  File \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/PRISMS/thompson_sampling/baseline.py\", line 111, in random_baseline\n",
      "    product_smiles = Chem.MolToSmiles(product_mol)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/PRISMS/thompson_sampling/evaluators.py\", line 146, in evaluate\n",
      "    return self.ref_dict[product_name] # Changed to product code for easier lookup\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
      "KeyError: <rdkit.Chem.rdchem.Mol object at 0x35a544900>\n",
      "\n",
      "\n",
      "üîÑ Running Random Baseline - Cycle 2\n",
      "5.00e+05 products\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6407b59594024eadb5dc746c902e9f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error in random cycle 2: <rdkit.Chem.rdchem.Mol object at 0x3510dcc80>\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/var/folders/sn/gcrsw56j5k93g0p6gnkvvn7c0000gn/T/ipykernel_4359/247604726.py\", line 136, in <module>\n",
      "    random_baseline(\n",
      "  File \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/PRISMS/thompson_sampling/baseline.py\", line 111, in random_baseline\n",
      "    product_smiles = Chem.MolToSmiles(product_mol)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/PRISMS/thompson_sampling/evaluators.py\", line 146, in evaluate\n",
      "    return self.ref_dict[product_name] # Changed to product code for easier lookup\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
      "KeyError: <rdkit.Chem.rdchem.Mol object at 0x3510dcc80>\n",
      "\n",
      "\n",
      "üîÑ Creating visualization...\n",
      "‚ùå Error creating TS_Benchmarks: No valid integrated sampler results found\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/var/folders/sn/gcrsw56j5k93g0p6gnkvvn7c0000gn/T/ipykernel_4359/247604726.py\", line 179, in <module>\n",
      "    raise ValueError(\"No valid integrated sampler results found\")\n",
      "ValueError: No valid integrated sampler results found\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Block for Integrated Thompson Sampler with TS_Benchmarks Visualization\n",
    "# This version includes all the fixes and can be run in a Jupyter notebook\n",
    "\n",
    "import json\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import traceback\n",
    "import sys\n",
    "# Add the root directory of your project to the Python path\n",
    "project_root = '/Users/aakankschitnandkeolyar/Desktop/PRISMS'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "# Import the required modules\n",
    "from PRISMS.thompson_sampling.thompson_sampling import IntegratedThompsonSampler\n",
    "from PRISMS.thompson_sampling.evaluators import LookupEvaluator\n",
    "from PRISMS.thompson_sampling.baseline import random_baseline\n",
    "from PRISMS.library_analysis.visualization import TS_Benchmarks\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INTEGRATED THOMPSON SAMPLER TEST WITH VISUALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Load your JSON config\n",
    "input_json_file = '''{\n",
    "    \"reagent_file_list\": [\n",
    "        \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/tests/Data/Thrombin/input_files/acids.smi\",\n",
    "        \"/Users/aakankschitnandkeolyar/Desktop/PRISMS/tests/Data/Thrombin/input_files/coupled_aa_sub.smi\"\n",
    "    ],\n",
    "    \"reaction_smarts\": \"[#6:1](=[O:2])[OH].[#7X3;H1,H2;!$(N[!#6]);!$(N[#6]=[O]);!$(N[#6]~[!#6;!#16]):3]>>[#6:1](=[O:2])[#7:3]\",\n",
    "    \"num_warmup_trials\": 3,\n",
    "    \"num_ts_iterations\": 200,\n",
    "    \"sampler_type\": \"integrated\",\n",
    "    \"ts_mode\": \"minimize\",\n",
    "    \"evaluator_class_name\": \"LookupEvaluator\",\n",
    "    \"evaluator_arg\": {\n",
    "        \"ref_filename\": \"/Users/aakankschitnandkeolyar/Desktop/TS_Chem_Space/Thrombin/Linear_amide/docking_scores/product_scores.csv\",\n",
    "        \"ref_colname\": \"Score\"\n",
    "    },\n",
    "    \"log_filename\": \"ts_logs.txt\",\n",
    "    \"results_filename\": \"ts_results_integrated.csv\",\n",
    "    \"processes\": 1,\n",
    "    \"scaling\": 1.0,\n",
    "    \"percent_of_library\": 0.05,\n",
    "    \"search_stop\": 50,\n",
    "    \"min_cpds_per_core\": 5\n",
    "}'''\n",
    "\n",
    "try:\n",
    "    input_dict = json.loads(input_json_file)\n",
    "    input_dict[\"evaluator_class\"] = LookupEvaluator(input_dict[\"evaluator_arg\"])\n",
    "    print(\"‚úÖ Configuration loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading configuration: {str(e)}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    raise\n",
    "\n",
    "# 2. Run Integrated Thompson Sampler (multiple cycles for benchmarking)\n",
    "n_cycles = 2  # Reduced for testing\n",
    "integrated_results = []\n",
    "\n",
    "print(f\"\\nÔøΩÔøΩ Running Integrated Thompson Sampler ({n_cycles} cycles)...\")\n",
    "for cycle in range(1, n_cycles + 1):\n",
    "    try:\n",
    "        # Set a unique output file for this cycle\n",
    "        cycle_results_file = f\"ts_results_integrated_cycle{cycle}.csv\"\n",
    "        print(f\"\\nÔøΩÔøΩ Running Integrated Thompson Sampler - Cycle {cycle}\")\n",
    "        \n",
    "        # Create sampler instance\n",
    "        sampler = IntegratedThompsonSampler(\n",
    "            processes=input_dict.get(\"processes\", 1),\n",
    "            scaling=input_dict.get(\"scaling\", 1.0),\n",
    "            percent_lib=input_dict.get(\"percent_of_library\", 0.1),\n",
    "            search_stop=input_dict.get(\"search_stop\", 100),\n",
    "            min_cpds_per_core=input_dict.get(\"min_cpds_per_core\", 10),\n",
    "            log_filename=input_dict.get(\"log_filename\")\n",
    "        )\n",
    "        \n",
    "        # Configure sampler\n",
    "        sampler.set_hide_progress(True)\n",
    "        sampler.set_evaluator(input_dict[\"evaluator_class\"])\n",
    "        sampler.read_reagents(input_dict[\"reagent_file_list\"])\n",
    "        sampler.set_reaction(input_dict[\"reaction_smarts\"])\n",
    "        \n",
    "        # Run warm-up\n",
    "        print(f\"  Running warm-up...\")\n",
    "        sampler.warm_up_integrated(num_warmup_trials=input_dict.get(\"num_warmup_trials\", 3))\n",
    "        \n",
    "        # Run search\n",
    "        print(f\"  Running search...\")\n",
    "        sampler.search_integrated(\n",
    "            min_cpds_per_core=input_dict.get(\"min_cpds_per_core\", 10),\n",
    "            percent_of_library=input_dict.get(\"percent_of_library\", 0.1),\n",
    "            stop=input_dict.get(\"search_stop\", 100),\n",
    "            results_filename=cycle_results_file\n",
    "        )\n",
    "        \n",
    "        # Load and validate results\n",
    "        if os.path.exists(cycle_results_file):\n",
    "            df = pl.read_csv(cycle_results_file)\n",
    "            print(f\"  ‚úÖ Cycle {cycle} completed successfully: {len(df)} compounds\")\n",
    "            print(f\"  Columns: {df.columns}\")\n",
    "            \n",
    "            # Ensure score column exists and is numeric\n",
    "            if \"score\" in df.columns:\n",
    "                df = df.with_columns(pl.col(\"score\").cast(pl.Float64))\n",
    "            elif \"Score\" in df.columns:\n",
    "                df = df.rename({\"Score\": \"score\"})\n",
    "                df = df.with_columns(pl.col(\"score\").cast(pl.Float64))\n",
    "            else:\n",
    "                print(f\"  Warning: No score column found in {cycle_results_file}\")\n",
    "                print(f\"  Available columns: {df.columns}\")\n",
    "            \n",
    "            integrated_results.append(df)\n",
    "        else:\n",
    "            print(f\"  ‚ùå Results file not found: {cycle_results_file}\")\n",
    "            integrated_results.append(None)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in cycle {cycle}: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        integrated_results.append(None)\n",
    "\n",
    "# 3. Run Random Baseline (multiple cycles for benchmarking)\n",
    "random_results = []\n",
    "\n",
    "print(f\"\\nüîÑ Running Random Baseline ({n_cycles} cycles)...\")\n",
    "for cycle in range(1, n_cycles + 1):\n",
    "    try:\n",
    "        random_file = f\"random_results_cycle{cycle}.csv\"\n",
    "        print(f\"\\nüîÑ Running Random Baseline - Cycle {cycle}\")\n",
    "        \n",
    "        # Run random baseline\n",
    "        random_baseline(\n",
    "            input_dict,\n",
    "            num_trials=100,  # Adjust as needed\n",
    "            outfile_name=random_file,\n",
    "            num_to_save=100,\n",
    "            ascending_output=True\n",
    "        )\n",
    "        \n",
    "        # Load and validate results\n",
    "        if os.path.exists(random_file):\n",
    "            df = pl.read_csv(random_file)\n",
    "            print(f\"  ‚úÖ Random cycle {cycle} completed successfully: {len(df)} compounds\")\n",
    "            print(f\"  Columns: {df.columns}\")\n",
    "            \n",
    "            # Ensure score column exists and is numeric\n",
    "            if \"score\" in df.columns:\n",
    "                df = df.with_columns(pl.col(\"score\").cast(pl.Float64))\n",
    "            elif \"Score\" in df.columns:\n",
    "                df = df.rename({\"Score\": \"score\"})\n",
    "                df = df.with_columns(pl.col(\"score\").cast(pl.Float64))\n",
    "            else:\n",
    "                print(f\"  Warning: No score column found in {random_file}\")\n",
    "                print(f\"  Available columns: {df.columns}\")\n",
    "            \n",
    "            random_results.append(df)\n",
    "        else:\n",
    "            print(f\"  ‚ùå Results file not found: {random_file}\")\n",
    "            random_results.append(None)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in random cycle {cycle}: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        random_results.append(None)\n",
    "\n",
    "# 4. Create visualization\n",
    "print(f\"\\nüîÑ Creating visualization...\")\n",
    "\n",
    "try:\n",
    "    # Filter out None results\n",
    "    valid_integrated = [df for df in integrated_results if df is not None]\n",
    "    valid_random = [df for df in random_results if df is not None]\n",
    "    \n",
    "    if not valid_integrated:\n",
    "        raise ValueError(\"No valid integrated sampler results found\")\n",
    "    if not valid_random:\n",
    "        raise ValueError(\"No valid random baseline results found\")\n",
    "    \n",
    "    print(f\"\\nüìä Preparing visualization data:\")\n",
    "    print(f\"  - Valid integrated cycles: {len(valid_integrated)}\")\n",
    "    print(f\"  - Valid random cycles: {len(valid_random)}\")\n",
    "    \n",
    "    # Prepare data for TS_Benchmarks\n",
    "    methods_list = [\"IntegratedTS\", \"Random\"]\n",
    "    TS_runs_data = {\n",
    "        \"IntegratedTS\": valid_integrated,\n",
    "        \"Random\": valid_random\n",
    "    }\n",
    "    \n",
    "    # Create TS_Benchmarks instance\n",
    "    print(f\"\\nüîÑ Creating TS_Benchmarks visualization...\")\n",
    "    bench = TS_Benchmarks(\n",
    "        no_of_cycles=min(len(valid_integrated), len(valid_random)),\n",
    "        methods_list=methods_list,\n",
    "        TS_runs_data=TS_runs_data,\n",
    "        reference_data=None,  # Not needed for strip plot\n",
    "        top_n=100,\n",
    "        sort_type=\"minimize\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ TS_Benchmarks created successfully\")\n",
    "    \n",
    "    # 5. Generate strip plot\n",
    "    print(f\"\\nüìä Generating strip plot...\")\n",
    "    try:\n",
    "        chart = bench.stripplot_TS_results(show_plot=True)\n",
    "        print(\"‚úÖ Strip plot generated successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating strip plot: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating TS_Benchmarks: {str(e)}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"TEST COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TS_chem_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
